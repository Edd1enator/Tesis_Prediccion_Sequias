{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Edd1enator/Tesis_Prediccion_Sequias/blob/main/ModeloKaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lF_U_TEGVEXF",
      "metadata": {
        "id": "lF_U_TEGVEXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "184e70fe-e68f-4394-d16e-133f0a278a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hSelecting previously unselected package python3-numpy.\n",
            "(Reading database ... 121235 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-numpy_1%3a1.21.5-1ubuntu22.04.1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Selecting previously unselected package python3-gdal.\n",
            "Preparing to unpack .../python3-gdal_3.8.4+dfsg-1~jammy0_amd64.deb ...\n",
            "Unpacking python3-gdal (3.8.4+dfsg-1~jammy0) ...\n",
            "Selecting previously unselected package gdal-bin.\n",
            "Preparing to unpack .../gdal-bin_3.8.4+dfsg-1~jammy0_amd64.deb ...\n",
            "Unpacking gdal-bin (3.8.4+dfsg-1~jammy0) ...\n",
            "Setting up python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Setting up python3-gdal (3.8.4+dfsg-1~jammy0) ...\n",
            "Setting up gdal-bin (3.8.4+dfsg-1~jammy0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio geopandas tensorflow scikit-image tqdm matplotlib -q\n",
        "!apt install gdal-bin python3-gdal -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23837fdc",
      "metadata": {
        "id": "23837fdc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow import keras\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "from numpy import random\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import warnings\n",
        "\n",
        "np.set_printoptions(linewidth=130)\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "onptUn61C-Zp",
      "metadata": {
        "id": "onptUn61C-Zp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b7a81b-693a-40ca-defd-5a61a569dcec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurando GPUs...\n"
          ]
        }
      ],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    print(\"Configurando GPUs...\")\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)\n",
        "else:\n",
        "    print(\"No se detectaron GPUs, usando CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DUjLA3udVSs-",
      "metadata": {
        "id": "DUjLA3udVSs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d4a9e34-dbdb-4362-bccd-d5ee3d3b35b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU detectada: 1 dispositivos\n",
            "Configuración de GPU optimizada\n",
            "Versión de TensorFlow: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            print(f\"GPU detectada: {len(gpus)} dispositivos\")\n",
        "            print(\"Configuración de GPU optimizada\")\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Error configurando GPU: {e}\")\n",
        "    else:\n",
        "        print(\"No se detectó GPU\")\n",
        "\n",
        "    print(f\"Versión de TensorFlow: {tf.__version__}\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Error en la configuración de aceleración\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t4wLV7DwDiFn",
      "metadata": {
        "id": "t4wLV7DwDiFn"
      },
      "outputs": [],
      "source": [
        "base_path = \"/content/drive/MyDrive/Tesis/DataKaggle\"\n",
        "\n",
        "train_path = os.path.join(base_path, \"train_timeseries\")\n",
        "test_path = os.path.join(base_path, \"test_timeseries\")\n",
        "validation_path = os.path.join(base_path, \"validation_timeseries\")\n",
        "soil_data_path = os.path.join(base_path, \"soil_data.csv\")\n",
        "\n",
        "OUTPUT_DIR = \"/content/output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0181b893",
      "metadata": {
        "id": "0181b893"
      },
      "outputs": [],
      "source": [
        "# Configurar rutas según tu estructura de carpetas\n",
        "# base_path = \"/Users/eddiegiron/Desktop/archive\"\n",
        "\n",
        "# train_path = os.path.join(base_path, \"train_timeseries\")\n",
        "# test_path = os.path.join(base_path, \"test_timeseries\")\n",
        "# validation_path = os.path.join(base_path, \"validation_timeseries\")\n",
        "# soil_data_path = os.path.join(base_path, \"soil_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f_AplvsTZygX",
      "metadata": {
        "id": "f_AplvsTZygX"
      },
      "outputs": [],
      "source": [
        "batch_size = 1024\n",
        "epochs = 50\n",
        "random_state = 38\n",
        "k_folds = 2\n",
        "LEARNING_RATE = 3e-4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae_scores = []\n",
        "r2_scores = []\n",
        "models = []"
      ],
      "metadata": {
        "id": "hukoRQjg_-dI"
      },
      "id": "hukoRQjg_-dI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E6HpykRoDjiv",
      "metadata": {
        "id": "E6HpykRoDjiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00565c87-f74e-463f-a04e-bfcbab46aad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a6575bf",
      "metadata": {
        "id": "8a6575bf"
      },
      "outputs": [],
      "source": [
        "# Función de carga de datos\n",
        "def carga_data(folder_path):\n",
        "    all_files = []\n",
        "\n",
        "    if os.path.exists(folder_path):\n",
        "        for file in os.listdir(folder_path):\n",
        "            if file.endswith('.csv'):\n",
        "                file_path = os.path.join(folder_path, file)\n",
        "                df = pd.read_csv(file_path)\n",
        "                df['source_file'] = file\n",
        "                all_files.append(df)\n",
        "\n",
        "        if all_files:\n",
        "            return pd.concat(all_files, ignore_index=True)\n",
        "        else:\n",
        "            print(f\"No se encontraron archivos CSV en {folder_path}\")\n",
        "            return pd.DataFrame()\n",
        "    else:\n",
        "        print(f\"La carpeta {folder_path} no existe\")\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ed46836",
      "metadata": {
        "id": "2ed46836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4811796e-007f-411c-db52-7fe7b0a32caa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando datos de entrenamiento...\n",
            "Cargando datos de prueba...\n",
            "Cargando datos de validación...\n",
            "Cargando datos del suelo...\n"
          ]
        }
      ],
      "source": [
        "# Carga de datos para entorno\n",
        "print(\"Cargando datos de entrenamiento...\")\n",
        "train_data = carga_data(train_path)\n",
        "\n",
        "print(\"Cargando datos de prueba...\")\n",
        "test_data = carga_data(test_path)\n",
        "\n",
        "print(\"Cargando datos de validación...\")\n",
        "validation_data = carga_data(validation_path)\n",
        "\n",
        "print(\"Cargando datos del suelo...\")\n",
        "soil_data = pd.read_csv(soil_data_path) if os.path.exists(soil_data_path) else pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10e9aebd",
      "metadata": {
        "id": "10e9aebd"
      },
      "outputs": [],
      "source": [
        "# Limpieza de datos nulos en fips y date\n",
        "train_data = train_data.dropna(subset=['fips', 'date'])\n",
        "test_data = test_data.dropna(subset=['fips', 'date'])\n",
        "validation_data = validation_data.dropna(subset=['fips', 'date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4565b334",
      "metadata": {
        "id": "4565b334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2eb7f6-5e1a-4e5d-adf3-f3efb2858541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ESTRUCTURA DE LOS DATOS ===\n",
            "Train data shape: (19300680, 22)\n",
            "Test data shape: (2271948, 22)\n",
            "Validation data shape: (2268840, 22)\n",
            "Soil data shape: (3109, 32)\n",
            "\n",
            "Columnas en train_data:\n",
            "['fips', 'date', 'PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET', 'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX', 'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN', 'WS50M_RANGE', 'score', 'source_file']\n",
            "\n",
            "Primeras filas de train_data:\n",
            "   fips        date  PRECTOT      PS   QV2M    T2M  T2MDEW  T2MWET  T2M_MAX  \\\n",
            "0  1001  2000-01-01     0.22  100.51   9.65  14.74   13.51   13.51    20.96   \n",
            "1  1001  2000-01-02     0.20  100.55  10.42  16.69   14.71   14.71    22.80   \n",
            "2  1001  2000-01-03     3.65  100.15  11.76  18.49   16.52   16.52    22.73   \n",
            "3  1001  2000-01-04    15.95  100.29   6.42  11.40    6.09    6.10    18.09   \n",
            "4  1001  2000-01-05     0.00  101.15   2.95   3.86   -3.29   -3.20    10.82   \n",
            "\n",
            "   T2M_MIN  ...  WS10M  WS10M_MAX  WS10M_MIN  WS10M_RANGE  WS50M  WS50M_MAX  \\\n",
            "0    11.46  ...   2.20       2.94       1.49         1.46   4.85       6.04   \n",
            "1    12.61  ...   2.52       3.43       1.83         1.60   5.33       6.13   \n",
            "2    15.32  ...   4.03       5.33       2.66         2.67   7.53       9.52   \n",
            "3     2.16  ...   3.84       5.67       2.08         3.59   6.73       9.31   \n",
            "4    -2.66  ...   1.60       2.50       0.52         1.98   2.94       4.85   \n",
            "\n",
            "   WS50M_MIN  WS50M_RANGE  score           source_file  \n",
            "0       3.23         2.81    NaN  train_timeseries.csv  \n",
            "1       3.72         2.41    NaN  train_timeseries.csv  \n",
            "2       5.87         3.66    NaN  train_timeseries.csv  \n",
            "3       3.74         5.58    1.0  train_timeseries.csv  \n",
            "4       0.65         4.19    NaN  train_timeseries.csv  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "print(\"=== ESTRUCTURA DE LOS DATOS ===\")\n",
        "print(f\"Train data shape: {train_data.shape}\")\n",
        "print(f\"Test data shape: {test_data.shape}\")\n",
        "print(f\"Validation data shape: {validation_data.shape}\")\n",
        "print(f\"Soil data shape: {soil_data.shape}\")\n",
        "\n",
        "if not train_data.empty:\n",
        "    print(\"\\nColumnas en train_data:\")\n",
        "    print(train_data.columns.tolist())\n",
        "    print(\"\\nPrimeras filas de train_data:\")\n",
        "    print(train_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e130aa6e",
      "metadata": {
        "id": "e130aa6e"
      },
      "outputs": [],
      "source": [
        "def visualizar_dataset(df, name):\n",
        "    \"\"\"Analiza un dataset mostrando información básica\"\"\"\n",
        "    if df.empty:\n",
        "        print(f\"{name}: Dataset vacío\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n=== ANÁLISIS DE {name.upper()} ===\")\n",
        "    print(f\"Dimensiones: {df.shape}\")\n",
        "    print(f\"Columnas: {df.columns.tolist()}\")\n",
        "    print(f\"Tipos de datos:\")\n",
        "    print(df.dtypes)\n",
        "    print(f\"Valores nulos:\")\n",
        "    print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "158cbdf6",
      "metadata": {
        "id": "158cbdf6",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6a3e146-7dd5-4604-8c37-53c449b4f7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ANÁLISIS DE TRAIN_DATA ===\n",
            "Dimensiones: (19300680, 22)\n",
            "Columnas: ['fips', 'date', 'PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET', 'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX', 'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN', 'WS50M_RANGE', 'score', 'source_file']\n",
            "Tipos de datos:\n",
            "fips             int64\n",
            "date            object\n",
            "PRECTOT        float64\n",
            "PS             float64\n",
            "QV2M           float64\n",
            "T2M            float64\n",
            "T2MDEW         float64\n",
            "T2MWET         float64\n",
            "T2M_MAX        float64\n",
            "T2M_MIN        float64\n",
            "T2M_RANGE      float64\n",
            "TS             float64\n",
            "WS10M          float64\n",
            "WS10M_MAX      float64\n",
            "WS10M_MIN      float64\n",
            "WS10M_RANGE    float64\n",
            "WS50M          float64\n",
            "WS50M_MAX      float64\n",
            "WS50M_MIN      float64\n",
            "WS50M_RANGE    float64\n",
            "score          float64\n",
            "source_file     object\n",
            "dtype: object\n",
            "Valores nulos:\n",
            "fips                  0\n",
            "date                  0\n",
            "PRECTOT               0\n",
            "PS                    0\n",
            "QV2M                  0\n",
            "T2M                   0\n",
            "T2MDEW                0\n",
            "T2MWET                0\n",
            "T2M_MAX               0\n",
            "T2M_MIN               0\n",
            "T2M_RANGE             0\n",
            "TS                    0\n",
            "WS10M                 0\n",
            "WS10M_MAX             0\n",
            "WS10M_MIN             0\n",
            "WS10M_RANGE           0\n",
            "WS50M                 0\n",
            "WS50M_MAX             0\n",
            "WS50M_MIN             0\n",
            "WS50M_RANGE           0\n",
            "score          16543884\n",
            "source_file           0\n",
            "dtype: int64\n",
            "\n",
            "=== ANÁLISIS DE SOIL_DATA ===\n",
            "Dimensiones: (3109, 32)\n",
            "Columnas: ['fips', 'lat', 'lon', 'elevation', 'slope1', 'slope2', 'slope3', 'slope4', 'slope5', 'slope6', 'slope7', 'slope8', 'aspectN', 'aspectE', 'aspectS', 'aspectW', 'aspectUnknown', 'WAT_LAND', 'NVG_LAND', 'URB_LAND', 'GRS_LAND', 'FOR_LAND', 'CULTRF_LAND', 'CULTIR_LAND', 'CULT_LAND', 'SQ1', 'SQ2', 'SQ3', 'SQ4', 'SQ5', 'SQ6', 'SQ7']\n",
            "Tipos de datos:\n",
            "fips               int64\n",
            "lat              float64\n",
            "lon              float64\n",
            "elevation          int64\n",
            "slope1           float64\n",
            "slope2           float64\n",
            "slope3           float64\n",
            "slope4           float64\n",
            "slope5           float64\n",
            "slope6           float64\n",
            "slope7           float64\n",
            "slope8           float64\n",
            "aspectN          float64\n",
            "aspectE          float64\n",
            "aspectS          float64\n",
            "aspectW          float64\n",
            "aspectUnknown    float64\n",
            "WAT_LAND         float64\n",
            "NVG_LAND         float64\n",
            "URB_LAND         float64\n",
            "GRS_LAND         float64\n",
            "FOR_LAND         float64\n",
            "CULTRF_LAND      float64\n",
            "CULTIR_LAND      float64\n",
            "CULT_LAND        float64\n",
            "SQ1                int64\n",
            "SQ2                int64\n",
            "SQ3                int64\n",
            "SQ4                int64\n",
            "SQ5                int64\n",
            "SQ6                int64\n",
            "SQ7                int64\n",
            "dtype: object\n",
            "Valores nulos:\n",
            "fips             0\n",
            "lat              0\n",
            "lon              0\n",
            "elevation        0\n",
            "slope1           0\n",
            "slope2           0\n",
            "slope3           0\n",
            "slope4           0\n",
            "slope5           0\n",
            "slope6           0\n",
            "slope7           0\n",
            "slope8           0\n",
            "aspectN          0\n",
            "aspectE          0\n",
            "aspectS          0\n",
            "aspectW          0\n",
            "aspectUnknown    0\n",
            "WAT_LAND         0\n",
            "NVG_LAND         0\n",
            "URB_LAND         0\n",
            "GRS_LAND         0\n",
            "FOR_LAND         0\n",
            "CULTRF_LAND      0\n",
            "CULTIR_LAND      0\n",
            "CULT_LAND        0\n",
            "SQ1              0\n",
            "SQ2              0\n",
            "SQ3              0\n",
            "SQ4              0\n",
            "SQ5              0\n",
            "SQ6              0\n",
            "SQ7              0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "visualizar_dataset(train_data, \"train_data\")\n",
        "visualizar_dataset(soil_data, \"soil_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68b23274",
      "metadata": {
        "id": "68b23274"
      },
      "outputs": [],
      "source": [
        "def buscar_columna_objetivo(df):\n",
        "    \"\"\"Busca columnas relacionadas con sequía\"\"\"\n",
        "    drought_keywords = ['drought', 'sequia', 'dry', 'aridity', 'water_stress', 'index']\n",
        "    target_cols = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_lower = col.lower()\n",
        "        for keyword in drought_keywords:\n",
        "            if keyword in col_lower:\n",
        "                target_cols.append(col)\n",
        "                break\n",
        "    return target_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e77b58e1",
      "metadata": {
        "id": "e77b58e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587d0d5b-cb0d-41a3-9f24-cdd2fc1b792d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas objetivo potenciales: []\n",
            "Columnas numéricas disponibles: ['fips', 'PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET', 'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX', 'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN', 'WS50M_RANGE', 'score']\n",
            "Usando 'score' como columna objetivo por defecto\n"
          ]
        }
      ],
      "source": [
        "target_columns = buscar_columna_objetivo(train_data)\n",
        "print(\"Columnas objetivo potenciales:\", target_columns)\n",
        "\n",
        "if not target_columns and not train_data.empty:\n",
        "    numeric_cols = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    print(\"Columnas numéricas disponibles:\", numeric_cols)\n",
        "    if numeric_cols:\n",
        "        target_columns = [numeric_cols[-1]]\n",
        "        print(f\"Usando '{target_columns[0]}' como columna objetivo por defecto\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"✅ Configuración actualizada - Ahora puedes ver más registros\")\n",
        "\n",
        "# Probar de nuevo\n",
        "train_data.score.head(100)"
      ],
      "metadata": {
        "id": "Q8ySFibrwfG3",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8fa8cf0-b8c4-42ed-f229-ea4c0c0d4c1e"
      },
      "id": "Q8ySFibrwfG3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuración actualizada - Ahora puedes ver más registros\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        NaN\n",
              "1        NaN\n",
              "2        NaN\n",
              "3     1.0000\n",
              "4        NaN\n",
              "5        NaN\n",
              "6        NaN\n",
              "7        NaN\n",
              "8        NaN\n",
              "9        NaN\n",
              "10    2.0000\n",
              "11       NaN\n",
              "12       NaN\n",
              "13       NaN\n",
              "14       NaN\n",
              "15       NaN\n",
              "16       NaN\n",
              "17    2.0000\n",
              "18       NaN\n",
              "19       NaN\n",
              "20       NaN\n",
              "21       NaN\n",
              "22       NaN\n",
              "23       NaN\n",
              "24    2.0000\n",
              "25       NaN\n",
              "26       NaN\n",
              "27       NaN\n",
              "28       NaN\n",
              "29       NaN\n",
              "30       NaN\n",
              "31    1.0000\n",
              "32       NaN\n",
              "33       NaN\n",
              "34       NaN\n",
              "35       NaN\n",
              "36       NaN\n",
              "37       NaN\n",
              "38    1.0000\n",
              "39       NaN\n",
              "40       NaN\n",
              "41       NaN\n",
              "42       NaN\n",
              "43       NaN\n",
              "44       NaN\n",
              "45    1.0000\n",
              "46       NaN\n",
              "47       NaN\n",
              "48       NaN\n",
              "49       NaN\n",
              "50       NaN\n",
              "51       NaN\n",
              "52    1.0000\n",
              "53       NaN\n",
              "54       NaN\n",
              "55       NaN\n",
              "56       NaN\n",
              "57       NaN\n",
              "58       NaN\n",
              "59    1.0000\n",
              "60       NaN\n",
              "61       NaN\n",
              "62       NaN\n",
              "63       NaN\n",
              "64       NaN\n",
              "65       NaN\n",
              "66    1.0000\n",
              "67       NaN\n",
              "68       NaN\n",
              "69       NaN\n",
              "70       NaN\n",
              "71       NaN\n",
              "72       NaN\n",
              "73    1.4905\n",
              "74       NaN\n",
              "75       NaN\n",
              "76       NaN\n",
              "77       NaN\n",
              "78       NaN\n",
              "79       NaN\n",
              "80    1.5019\n",
              "81       NaN\n",
              "82       NaN\n",
              "83       NaN\n",
              "84       NaN\n",
              "85       NaN\n",
              "86       NaN\n",
              "87    1.2818\n",
              "88       NaN\n",
              "89       NaN\n",
              "90       NaN\n",
              "91       NaN\n",
              "92       NaN\n",
              "93       NaN\n",
              "94    1.0000\n",
              "95       NaN\n",
              "96       NaN\n",
              "97       NaN\n",
              "98       NaN\n",
              "99       NaN\n",
              "Name: score, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>1.4905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>1.5019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>1.2818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tUH4ZnYNyQm2",
      "metadata": {
        "id": "tUH4ZnYNyQm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1615c150-cf1f-4624-df7b-03e6b2587614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos cargados: (19300680, 22)\n",
            "date_col: date target_col: score\n"
          ]
        }
      ],
      "source": [
        "date_col = None\n",
        "for c in ['date','fecha','timestamp','time']:\n",
        "    if c in train_data.columns:\n",
        "        date_col = c\n",
        "        break\n",
        "if date_col is None:\n",
        "    raise ValueError(\"No encontré columna de fecha; asigna date_col manualmente.\")\n",
        "\n",
        "target_col = None\n",
        "for c in train_data.columns:\n",
        "    if 'score' in c.lower():\n",
        "        target_col = c\n",
        "        break\n",
        "if target_col is None:\n",
        "    raise ValueError(\"No encontré columna objetivo que contenga 'score' en su nombre.\")\n",
        "\n",
        "# normalizar fecha y ordenar\n",
        "train_data[date_col] = pd.to_datetime(train_data[date_col], errors='coerce').dt.normalize()\n",
        "train_data = train_data.dropna(subset=[date_col])\n",
        "train_data = train_data.sort_values([ 'fips', date_col ]).reset_index(drop=True)\n",
        "\n",
        "print(\"Datos cargados:\", train_data.shape)\n",
        "print(\"date_col:\", date_col, \"target_col:\", target_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5Obg1H9_aGtJ",
      "metadata": {
        "id": "5Obg1H9_aGtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "682a4753-cf65-4048-ef7e-44c1ecc5e6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weekly_df shape: (2759904, 21)\n",
            "   fips       date  score\n",
            "0  1001 2000-01-04    1.0\n",
            "1  1001 2000-01-11    2.0\n",
            "2  1001 2000-01-18    2.0\n",
            "3  1001 2000-01-25    2.0\n",
            "4  1001 2000-02-01    1.0\n",
            "5  1001 2000-02-08    1.0\n",
            "6  1001 2000-02-15    1.0\n",
            "7  1001 2000-02-22    1.0\n",
            "8  1001 2000-02-29    1.0\n",
            "9  1001 2000-03-07    1.0\n"
          ]
        }
      ],
      "source": [
        "weekly_list = []\n",
        "grouped = train_data.groupby('fips')\n",
        "\n",
        "for fid, g in grouped:\n",
        "    g = g.copy()\n",
        "    g[date_col] = pd.to_datetime(g[date_col], errors='coerce').dt.normalize()\n",
        "    g = g.set_index(date_col).sort_index()\n",
        "\n",
        "    numeric_cols = g.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    numeric_cols = [c for c in numeric_cols if c != target_col]\n",
        "\n",
        "    # construir series diarias promedio\n",
        "    daily = g[numeric_cols].resample('D').mean()\n",
        "\n",
        "    # agregar semanalmente con etiqueta el martes\n",
        "    weekly = daily.resample('W-TUE').mean()\n",
        "\n",
        "    score_s = g[[target_col]].dropna().groupby(level=0).first()\n",
        "\n",
        "    wk = weekly.join(score_s, how='left')\n",
        "\n",
        "    wk = wk.reset_index().rename(columns={'index': date_col})\n",
        "    wk['fips'] = fid\n",
        "    weekly_list.append(wk)\n",
        "\n",
        "weekly_df = pd.concat(weekly_list, ignore_index=True)\n",
        "weekly_df = weekly_df.rename(columns={date_col: 'date'})\n",
        "\n",
        "print(\"weekly_df shape:\", weekly_df.shape)\n",
        "print(weekly_df[[ 'fips', 'date', target_col ]].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P6Md37fO-QAK",
      "metadata": {
        "id": "P6Md37fO-QAK",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e2400a4-9bf2-4360-a501-e3f2ac608530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        date  fips   PRECTOT          PS      QV2M        T2M     T2MDEW     T2MWET    T2M_MAX    T2M_MIN  T2M_RANGE         TS     WS10M  WS10M_MAX  WS10M_MIN  WS10M_RANGE     WS50M  WS50M_MAX  WS50M_MIN  WS50M_RANGE  score\n",
            "0 2000-01-04  1001  5.005000  100.375000  9.562500  15.330000  12.707500  12.710000  21.145000  10.387500  10.752500  15.242500  3.147500   4.342500   2.015000     2.330000  6.110000   7.750000   4.140000     3.615000    1.0\n",
            "1 2000-01-11  1001  5.684286  100.665714  5.951429   9.192857   4.908571   4.934286  15.732857   3.071429  12.662857   8.558571  2.200000   3.305714   1.238571     2.065714  4.418571   6.588571   2.280000     4.307143    2.0\n",
            "2 2000-01-18  1001  0.832857  101.275714  6.692857  10.118571   6.711429   6.735714  16.931429   3.757143  13.177143   9.975714  2.352857   3.257143   1.490000     1.767143  4.870000   6.508571   2.812857     3.692857    2.0\n",
            "3 2000-01-25  1001  3.641429  100.187143  4.220000   4.458571  -0.224286  -0.132857  10.217143  -1.282857  11.498571   4.508571  2.932857   4.090000   1.814286     2.275714  5.270000   7.174286   3.575714     3.600000    2.0\n",
            "4 2000-02-01  1001  3.617143  100.992857  3.178571   0.764286  -2.791429  -2.714286   6.275714  -3.271429   9.547143   0.781429  2.362857   3.354286   1.318571     2.037143  4.372857   6.177143   2.580000     3.594286    1.0\n",
            "5 2000-02-08  1001  0.000000  101.054286  3.545714   4.377143  -1.231429  -1.180000  12.318571  -2.164286  14.480000   3.640000  2.075714   3.034286   1.051429     1.982857  3.812857   5.880000   1.654286     4.227143    1.0\n",
            "6 2000-02-15  1001  1.708571  100.215714  8.087143  13.325714  10.057143  10.061429  20.042857   6.375714  13.668571  12.987143  2.444286   3.491429   1.431429     2.061429  4.887143   7.050000   2.547143     4.504286    1.0\n",
            "7 2000-02-22  1001  0.917143  100.998571  7.101429  12.237143   7.655714   7.668571  19.608571   5.337143  14.271429  12.130000  2.418571   3.192857   1.682857     1.512857  4.714286   6.535714   3.157143     3.380000    1.0\n",
            "8 2000-02-29  1001  3.852857  100.828571  7.628571  14.057143   9.621429   9.625714  21.797143   7.042857  14.752857  14.005714  2.662857   3.820000   1.730000     2.091429  5.345714   6.948571   3.407143     3.541429    1.0\n",
            "9 2000-03-07  1001  1.347143  100.318571  7.094286  14.390000   8.392857   8.401429  22.034286   7.078571  14.955714  13.580000  2.137143   3.078571   1.241429     1.835714  4.095714   5.971429   2.384286     3.585714    1.0\n"
          ]
        }
      ],
      "source": [
        "print(weekly_df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def round_score_series(s):\n",
        "\n",
        "    # Variable para almacenar valores score con NaN\n",
        "    nan_mask = s.isna()\n",
        "\n",
        "    rounded = np.floor(s.values + 0.5).astype(int)\n",
        "    rounded = np.clip(rounded, 0, 5)\n",
        "\n",
        "    result = pd.Series(rounded, index=s.index, dtype=float)\n",
        "\n",
        "    # restaurar valores NaN\n",
        "    result[nan_mask] = np.nan\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "Y72F4jNeFH4r"
      },
      "id": "Y72F4jNeFH4r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_temp = []\n",
        "df_temp = weekly_df.copy()\n",
        "df_temp['score'] = round_score_series(df_temp['score'])\n",
        "print(df_temp)"
      ],
      "metadata": {
        "id": "LptJr-X7FQ0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f4389c-69d0-43ce-a814-c2d39af299c3"
      },
      "id": "LptJr-X7FQ0u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              date   fips   PRECTOT          PS      QV2M        T2M     T2MDEW     T2MWET    T2M_MAX    T2M_MIN  T2M_RANGE         TS     WS10M  WS10M_MAX  WS10M_MIN  WS10M_RANGE     WS50M  WS50M_MAX  WS50M_MIN  WS50M_RANGE  score\n",
            "0       2000-01-04   1001  5.005000  100.375000  9.562500  15.330000  12.707500  12.710000  21.145000  10.387500  10.752500  15.242500  3.147500   4.342500   2.015000     2.330000  6.110000   7.750000   4.140000     3.615000    1.0\n",
            "1       2000-01-11   1001  5.684286  100.665714  5.951429   9.192857   4.908571   4.934286  15.732857   3.071429  12.662857   8.558571  2.200000   3.305714   1.238571     2.065714  4.418571   6.588571   2.280000     4.307143    2.0\n",
            "2       2000-01-18   1001  0.832857  101.275714  6.692857  10.118571   6.711429   6.735714  16.931429   3.757143  13.177143   9.975714  2.352857   3.257143   1.490000     1.767143  4.870000   6.508571   2.812857     3.692857    2.0\n",
            "3       2000-01-25   1001  3.641429  100.187143  4.220000   4.458571  -0.224286  -0.132857  10.217143  -1.282857  11.498571   4.508571  2.932857   4.090000   1.814286     2.275714  5.270000   7.174286   3.575714     3.600000    2.0\n",
            "4       2000-02-01   1001  3.617143  100.992857  3.178571   0.764286  -2.791429  -2.714286   6.275714  -3.271429   9.547143   0.781429  2.362857   3.354286   1.318571     2.037143  4.372857   6.177143   2.580000     3.594286    1.0\n",
            "...            ...    ...       ...         ...       ...        ...        ...        ...        ...        ...        ...        ...       ...        ...        ...          ...       ...        ...        ...          ...    ...\n",
            "2759899 2016-12-06  56043  0.471429   82.668571  1.991429  -5.320000 -11.062857 -10.812857  -0.422857  -9.621429   9.200000  -5.887143  3.517143   5.534286   1.837143     3.694286  5.210000   7.768571   2.905714     4.862857    0.0\n",
            "2759900 2016-12-13  56043  0.350000   82.865714  1.884286  -7.621429 -12.220000 -11.961429  -2.532857 -11.791429   9.260000  -8.364286  3.370000   5.521429   1.435714     4.085714  5.080000   7.635714   2.311429     5.322857    0.0\n",
            "2759901 2016-12-20  56043  0.812857   82.752857  1.757143  -9.688571 -13.777143 -13.368571  -3.805714 -15.451429  11.642857 -10.667143  3.735714   5.688571   1.648571     4.038571  5.287143   7.750000   2.740000     5.008571    0.0\n",
            "2759902 2016-12-27  56043  0.751429   82.667143  2.022857  -6.534286 -11.001429 -10.767143   0.274286 -11.805714  12.081429  -8.218571  4.237143   6.014286   2.238571     3.775714  6.342857   8.890000   3.630000     5.258571    0.0\n",
            "2759903 2017-01-03  56043  0.420000   82.940000  1.845000  -6.792500 -11.695000 -11.505000   0.185000 -11.635000  11.820000  -8.787500  4.520000   7.120000   2.135000     4.987500  6.782500   9.985000   3.590000     6.395000    NaN\n",
            "\n",
            "[2759904 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"✅ Configuración actualizada - Ahora puedes ver más registros\")\n",
        "\n",
        "# Probar de nuevo\n",
        "df_temp.score.head(100)\n",
        "nulos_score = df_temp['score'].isna().sum()\n",
        "print(nulos_score)"
      ],
      "metadata": {
        "id": "jaVwZXLaFz74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04834b64-55d7-4d34-ea5e-bb8346d9c4c3"
      },
      "id": "jaVwZXLaFz74",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuración actualizada - Ahora puedes ver más registros\n",
            "3108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"✅ Configuración actualizada - Ahora puedes ver más registros\")\n",
        "\n",
        "# Probar de nuevo\n",
        "df_temp.score.tail(100)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JLfD-NVn__P-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9cb28322-1ea2-4c7a-b463-f57563e932fd"
      },
      "id": "JLfD-NVn__P-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuración actualizada - Ahora puedes ver más registros\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2759804    0.0\n",
              "2759805    0.0\n",
              "2759806    0.0\n",
              "2759807    0.0\n",
              "2759808    0.0\n",
              "2759809    0.0\n",
              "2759810    0.0\n",
              "2759811    0.0\n",
              "2759812    0.0\n",
              "2759813    0.0\n",
              "2759814    0.0\n",
              "2759815    0.0\n",
              "2759816    0.0\n",
              "2759817    0.0\n",
              "2759818    0.0\n",
              "2759819    0.0\n",
              "2759820    0.0\n",
              "2759821    0.0\n",
              "2759822    0.0\n",
              "2759823    0.0\n",
              "2759824    0.0\n",
              "2759825    0.0\n",
              "2759826    0.0\n",
              "2759827    0.0\n",
              "2759828    0.0\n",
              "2759829    0.0\n",
              "2759830    0.0\n",
              "2759831    0.0\n",
              "2759832    0.0\n",
              "2759833    0.0\n",
              "2759834    0.0\n",
              "2759835    0.0\n",
              "2759836    0.0\n",
              "2759837    0.0\n",
              "2759838    0.0\n",
              "2759839    0.0\n",
              "2759840    0.0\n",
              "2759841    0.0\n",
              "2759842    1.0\n",
              "2759843    1.0\n",
              "2759844    1.0\n",
              "2759845    1.0\n",
              "2759846    1.0\n",
              "2759847    1.0\n",
              "2759848    1.0\n",
              "2759849    1.0\n",
              "2759850    1.0\n",
              "2759851    1.0\n",
              "2759852    2.0\n",
              "2759853    2.0\n",
              "2759854    2.0\n",
              "2759855    2.0\n",
              "2759856    2.0\n",
              "2759857    2.0\n",
              "2759858    2.0\n",
              "2759859    2.0\n",
              "2759860    2.0\n",
              "2759861    2.0\n",
              "2759862    2.0\n",
              "2759863    2.0\n",
              "2759864    2.0\n",
              "2759865    2.0\n",
              "2759866    1.0\n",
              "2759867    1.0\n",
              "2759868    1.0\n",
              "2759869    1.0\n",
              "2759870    1.0\n",
              "2759871    1.0\n",
              "2759872    1.0\n",
              "2759873    1.0\n",
              "2759874    1.0\n",
              "2759875    1.0\n",
              "2759876    1.0\n",
              "2759877    1.0\n",
              "2759878    1.0\n",
              "2759879    1.0\n",
              "2759880    2.0\n",
              "2759881    2.0\n",
              "2759882    2.0\n",
              "2759883    2.0\n",
              "2759884    2.0\n",
              "2759885    2.0\n",
              "2759886    2.0\n",
              "2759887    1.0\n",
              "2759888    1.0\n",
              "2759889    1.0\n",
              "2759890    0.0\n",
              "2759891    0.0\n",
              "2759892    0.0\n",
              "2759893    0.0\n",
              "2759894    0.0\n",
              "2759895    0.0\n",
              "2759896    0.0\n",
              "2759897    0.0\n",
              "2759898    0.0\n",
              "2759899    0.0\n",
              "2759900    0.0\n",
              "2759901    0.0\n",
              "2759902    0.0\n",
              "2759903    NaN\n",
              "Name: score, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2759804</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759805</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759806</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759807</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759808</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759809</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759810</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759811</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759812</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759813</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759814</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759815</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759816</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759817</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759818</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759819</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759820</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759821</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759822</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759823</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759824</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759825</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759826</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759827</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759828</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759829</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759830</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759831</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759832</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759833</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759834</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759835</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759836</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759837</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759838</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759839</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759840</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759841</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759842</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759843</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759844</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759845</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759846</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759847</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759848</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759849</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759850</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759851</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759852</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759853</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759854</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759855</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759856</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759857</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759858</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759859</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759860</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759861</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759862</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759863</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759864</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759865</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759866</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759867</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759868</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759869</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759870</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759871</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759872</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759873</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759874</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759875</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759876</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759877</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759878</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759879</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759880</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759881</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759882</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759883</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759884</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759885</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759886</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759887</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759888</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759889</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759890</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759891</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759892</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759893</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759894</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759895</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759896</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759897</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759898</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759899</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759900</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759901</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759902</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759903</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68dfd35d",
      "metadata": {
        "id": "68dfd35d"
      },
      "outputs": [],
      "source": [
        "# Función de preprocesamiento\n",
        "def preprocess_data(df, target_col=None):\n",
        "    if df.empty:\n",
        "        return df, None, None\n",
        "\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    date_columns = ['date', 'fecha', 'time', 'timestamp']\n",
        "    for date_col in date_columns:\n",
        "        if date_col in df_processed.columns:\n",
        "            df_processed[date_col] = pd.to_datetime(df_processed[date_col], errors='coerce')\n",
        "            df_processed['year'] = df_processed[date_col].dt.year\n",
        "            df_processed['month'] = df_processed[date_col].dt.month\n",
        "            df_processed['day'] = df_processed[date_col].dt.day\n",
        "            break\n",
        "\n",
        "    # Manejo de valores nulos\n",
        "    numeric_cols = df_processed.select_dtypes(include=[np.number]).columns\n",
        "    for col in numeric_cols:\n",
        "        if df_processed[col].isnull().sum() > 0:\n",
        "            df_processed[col].fillna(df_processed[col].median(), inplace=True)\n",
        "\n",
        "    no_numeric_cols = df_processed.select_dtypes(exclude=[np.number]).columns\n",
        "    features_to_drop = [col for col in no_numeric_cols if col != target_col]\n",
        "    df_processed = df_processed.drop(columns=features_to_drop)\n",
        "\n",
        "    if target_col and target_col in df_processed.columns:\n",
        "        X = df_processed.drop(columns=[target_col])\n",
        "        y = df_processed[target_col]\n",
        "        return X, y, df_processed\n",
        "    else:\n",
        "        return df_processed, None, df_processed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6193169a",
      "metadata": {
        "id": "6193169a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f848c96-5703-4a79-8be3-8d3fda658b65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando 'score' como columna objetivo\n",
            "Preprocesando datos...\n"
          ]
        }
      ],
      "source": [
        "# Preprocesar datos\n",
        "\n",
        "columna_objetivo = buscar_columna_objetivo(df_temp)\n",
        "# columna_objetivo = buscar_columna_objetivo(train_data)\n",
        "columna_objetivo = columna_objetivo[0] if columna_objetivo else None\n",
        "\n",
        "if not columna_objetivo and not df_temp.empty:\n",
        "    numeric_cols = df_temp.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if numeric_cols:\n",
        "        columna_objetivo = numeric_cols[-1]\n",
        "        print(f\"Usando '{columna_objetivo}' como columna objetivo\")\n",
        "\n",
        "# if not columna_objetivo and not train_data.empty:\n",
        "#     numeric_cols = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "#     if numeric_cols:\n",
        "#         columna_objetivo = numeric_cols[-1]\n",
        "#         print(f\"Usando '{columna_objetivo}' como columna objetivo\")\n",
        "\n",
        "print(\"Preprocesando datos...\")\n",
        "X_train, y_train, train_processed = preprocess_data(df_temp, columna_objetivo)\n",
        "# X_train, y_train, train_processed = preprocess_data(train_data, columna_objetivo)\n",
        "X_test, y_test, test_processed = preprocess_data(test_data, columna_objetivo)\n",
        "X_val, y_val, val_processed = preprocess_data(validation_data, columna_objetivo)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_val)"
      ],
      "metadata": {
        "id": "_mPBK_mhwLHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e372185-d127-4fe3-ee73-4565bffe3869"
      },
      "id": "_mPBK_mhwLHJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0          0.0\n",
            "1          0.0\n",
            "2          2.0\n",
            "3          0.0\n",
            "4          0.0\n",
            "          ... \n",
            "2268835    0.0\n",
            "2268836    0.0\n",
            "2268837    0.0\n",
            "2268838    0.0\n",
            "2268839    0.0\n",
            "Name: score, Length: 2268840, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.Series(y_train).value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "id": "exGiClT6ocWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4876f6c9-cdc0-45c8-8000-fafec05a9398"
      },
      "id": "exGiClT6ocWj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score\n",
            "0.0    59.977340\n",
            "1.0    16.919610\n",
            "2.0    10.700698\n",
            "3.0     7.130828\n",
            "4.0     3.850279\n",
            "5.0     1.421245\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Porcentajes\n",
        "percentages = pd.Series(y_train).value_counts(normalize=True) * 100\n",
        "\n",
        "# Gráfico\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(percentages.index, percentages.values, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "\n",
        "for bar, percentage in zip(bars, percentages.values):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "             f'{percentage:.1f}%', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.xlabel('Nivel de Sequía (0-5)')\n",
        "plt.ylabel('Porcentaje (%)')\n",
        "plt.title('Distribución de Variable Objetivo')\n",
        "plt.xticks(range(0, 6))\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2iYXX5pWoQsp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "3be2ba8f-6fb5-4139-ac7c-c71d3ef4626f"
      },
      "id": "2iYXX5pWoQsp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAaNxJREFUeJzt3XlYVeXexvF7gzLE5MQgioqz5jxGzkqRU07lkAVaZqnVUSrLyjFT86RpOdYpcSzT0spODmFqlpKglvOIkqmII4OCCuv9o+N+2wEKwnKDfj/XxXVcz/OsZ/3W3suTN2uyGIZhCAAAAAAA5DsHexcAAAAAAMDditANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAORBWlqaJkyYoDVr1ti7FAAAUAARugEAOTJmzBhZLJY7sq3WrVurdevW1uUNGzbIYrFo+fLld2T7f2exWDRmzJhs+8PDw7V48WI1bdr0jtTTr18/VahQ4Y5sK79FRETIYrHo2LFjuV63devWqlWr1i3HHTt2TBaLRREREbkvMJ/cqOG999675Vgz/l4VhM8AAPD/CN0AcA+6EX5u/Li4uMjf318hISH64IMPlJSUlC/bOXnypMaMGaOdO3fmy3wFzRdffKGVK1fq+++/V7FixexdTq7VqVNH5cqVk2EY2Y5p1qyZfH19df369TtYWcGTkpKit99+W3Xq1NF9990nLy8vtWjRQgsWLLjp52emJUuWaNq0aXbZNgAg5wjdAHAPGzdunBYuXKjZs2frxRdflCQNHTpUtWvX1u+//24z9q233tKVK1dyNf/Jkyc1duzYXIfutWvXau3atblaxyxXrlzRW2+9landMAydOHFC33//vcqVK2eHyvKub9+++uOPP/TTTz9l2X/s2DFt2bJFvXr1UpEiRfK8vaeeekpXrlxR+fLl8zzXnRQfH6+mTZtqzJgxql27tqZNm6a3335bDg4OCgsLU58+fZSenn5bc9/O36sbsgvd5cuX15UrV/TUU0/d1rwAgPyV9/+CAgAKrfbt26tRo0bW5REjRmj9+vXq1KmTHn30Ue3bt0+urq6SpCJFiuRL8LqZy5cv67777pOTk5Op28kNFxeXLNstFovCw8PvcDX564knntCIESO0ZMkStWzZMlP/Z599JsMw1Ldv3zxtJyUlRW5ubnJ0dJSjo2Oe5rKHsLAw7du3TytWrNCjjz5qbX/ppZf06quv6r333lP9+vX12muv5XpuM/5e3bh6BQBQMHCmGwBgo23btho5cqSOHz+uRYsWWduzuvd03bp1at68uYoVKyZ3d3dVq1ZNb7zxhqS/7sNu3LixJKl///7WS9lv3Gd64x7dmJgYtWzZUvfdd5913X/e031Denq63njjDfn5+cnNzU2PPvqo/vjjD5sxFSpUUL9+/TKtm9WcqampGjNmjKpWrSoXFxeVLl1a3bt315EjR6xjsrqne8eOHWrfvr08PT3l7u6udu3aaevWrTZjblzC//PPPys8PFze3t5yc3NTt27dlJCQkKm+rKxcuVK1atWSi4uLatWqpRUrVmQ5LiMjQ9OmTdP9998vFxcX+fr66rnnntOFCxduOn9AQIBatmyp5cuX69q1a5n6lyxZokqVKqlp06Y6fvy4Bg8erGrVqsnV1VUlS5bU448/nun+7Bv7vXHjRg0ePFg+Pj4qW7asTd/f1/n666/VsWNH+fv7y9nZWZUqVdLbb7+d7ZnjmJgYPfjgg3J1dVVgYKDmzJlz0328Yf/+/XrsscdUokQJubi4qFGjRvrmm29uud7WrVu1Zs0a9evXzyZw3zBx4kRVqVJF7777bpZnrN9//32VL19erq6uatWqlXbv3m3Tn9093YsWLVLDhg3l6uqqEiVKqHfv3jbHeuvWrfXdd9/p+PHj1r9bN+71/+c93e+9954sFouOHz+eaTsjRoyQk5OTzbGybNky67ZLlSqlJ598Un/++ectPysAQNYI3QCATG5clnqzS7z37NmjTp06KS0tTePGjdOUKVP06KOP6ueff5Yk1ahRQ+PGjZMkDRw4UAsXLtTChQttzqieO3dO7du3V7169TRt2jS1adPmpnW98847+u677/Taa6/ppZde0rp16xQcHHxbl+emp6erU6dOGjt2rBo2bKgpU6boX//6ly5dupQpGP1zv1u0aKHffvtNw4cP18iRIxUbG6vWrVsrKioq0/gXX3xRv/32m0aPHq1Bgwbp22+/1QsvvHDL+tauXasePXrIYrFo4sSJ6tq1q/r376/o6OhMY5977jm9+uqratasmaZPn67+/ftr8eLFCgkJyTJM/13fvn117ty5TE9f37Vrl3bv3m09y71t2zb98ssv6t27tz744AM9//zzioyMVOvWrXX58uVM8w4ePFh79+7VqFGj9Prrr2e7/YiICLm7uys8PFzTp09Xw4YNs13nwoUL6tChgxo2bKjJkyerbNmyGjRokD799NOb7uOePXv0wAMPaN++fXr99dc1ZcoUubm5qWvXrtn+IuOGb7/9VpIUGhqaZX+RIkX0xBNP6MKFC9Zj/4YFCxbogw8+0JAhQzRixAjt3r1bbdu2VXx8/E23+c477yg0NFRVqlTR1KlTNXToUEVGRqply5a6ePGiJOnNN99UvXr1VKpUKevfrezu7+7Zs6csFou++OKLTH1ffPGFHn74YRUvXlzSX99Hz5495ejoqIkTJ+rZZ5/VV199pebNm1u3DQDIJQMAcM+ZN2+eIcnYtm1btmO8vLyM+vXrW5dHjx5t/P0/G++//74hyUhISMh2jm3bthmSjHnz5mXqa9WqlSHJmDNnTpZ9rVq1si7/+OOPhiSjTJkyRmJiorX9iy++MCQZ06dPt7aVL1/eCAsLu+Wcn376qSHJmDp1aqaxGRkZ1j9LMkaPHm1d7tq1q+Hk5GQcOXLE2nby5EnDw8PDaNmypbXtxmccHBxsM9+wYcMMR0dH4+LFi5m2+3f16tUzSpcubTNu7dq1hiSjfPny1raffvrJkGQsXrzYZv3Vq1dn2f5P58+fN5ydnY0+ffrYtL/++uuGJOPAgQOGYRjG5cuXM627ZcsWQ5KxYMGCTPvdvHlz4/r16zbjb/TFxsZa27Ka97nnnjPuu+8+IzU11dp243iZMmWKtS0tLc2oV6+e4ePjY1y9etUwDMOIjY3NdMy1a9fOqF27ts18GRkZxoMPPmhUqVLlZh+P0bVrV0OSceHChWzHfPXVV4Yk44MPPrCpwdXV1Thx4oR1XFRUlCHJGDZsmLXtn3+vjh07Zjg6OhrvvPOOzTZ27dplFClSxKa9Y8eONsfCDVl9BkFBQUbDhg1txv36668239/Vq1cNHx8fo1atWsaVK1es41atWmVIMkaNGpXtZwAAyB5nugEAWXJ3d7/pU8xvPK3766+/VkZGxm1tw9nZWf3798/x+NDQUHl4eFiXH3vsMZUuXVr//e9/c73tL7/8UqVKlbI+QO7vsnuFU3p6utauXauuXbuqYsWK1vbSpUvriSee0ObNm5WYmGizzsCBA23ma9GihdLT07O81PeGU6dOaefOnQoLC5OXl5e1/aGHHlLNmjVtxi5btkxeXl566KGHdPbsWetPw4YN5e7urh9//PGmn0Px4sXVoUMHffPNN0pJSZH010PiPv/8czVq1EhVq1aVJOu9/ZJ07do1nTt3TpUrV1axYsW0ffv2TPM+++yzObp/++/zJiUl6ezZs2rRooUuX76s/fv324wtUqSInnvuOeuyk5OTnnvuOZ05c0YxMTFZzn/+/HmtX79ePXv2tM5/9uxZnTt3TiEhITp06NBNL52+8Xfg78fdP93o++d337VrV5UpU8a63KRJEzVt2vSmx+tXX32ljIwM9ezZ0+b79PPzU5UqVW75fWanV69eiomJsbl1YunSpXJ2dlaXLl0kSdHR0Tpz5owGDx5sc094x44dVb16dX333Xe3tW0AuNcRugEAWUpOTr5p0OjVq5eaNWumAQMGyNfXV71799YXX3yRqwBepkyZXD00rUqVKjbLFotFlStXvq33Ph85ckTVqlXL1UOsEhISdPnyZVWrVi1TX40aNZSRkZHpHvN/Ptn8xmW8N7vf+kYg/+f+Ssq07UOHDunSpUvy8fGRt7e3zU9ycrLOnDlzy/3q27evUlJS9PXXX0uSfvnlFx07dszmAWpXrlzRqFGjFBAQIGdnZ5UqVUre3t66ePGiLl26lGnOwMDAW25X+uvS727dusnLy0uenp7y9vbWk08+KUmZ5vX395ebm5tN241fCmR3DBw+fFiGYWjkyJGZPp/Ro0dL0k0/oxt/B272C6jsgnlW31/VqlVverweOnRIhmGoSpUqmerdt29fjr7PrDz++ONycHDQ0qVLJf31i5Vly5ZZn00g/f9xl9XxXb169Zv+oggAkD2eXg4AyOTEiRO6dOmSKleunO0YV1dXbdq0ST/++KO+++47rV69WkuXLlXbtm21du3aXJ/lzC83O0ttjydnZ7dNI5/e7ZyRkSEfHx8tXrw4y35vb+9bztGpUyd5eXlpyZIleuKJJ7RkyRI5Ojqqd+/e1jEvvvii5s2bp6FDhyooKEheXl6yWCzq3bt3lr9oycl3e/HiRbVq1Uqenp4aN26cKlWqJBcXF23fvl2vvfbabV9B8Xc35njllVcUEhKS5ZibHec1atTQypUr9fvvv2f5hHdJ1tfr/fMqhNuRkZEhi8Wi77//Pstjx93d/bbm9ff3V4sWLfTFF1/ojTfe0NatWxUXF6d33303ryUDAG6B0A0AyGThwoWSlG1IucHBwUHt2rVTu3btNHXqVE2YMEFvvvmmfvzxRwUHB2cbgG/XoUOHbJYNw9Dhw4dVp04da1vx4sWzfODT8ePHbS4Jr1SpkqKionTt2jUVLVo0R9v39vbWfffdpwMHDmTq279/vxwcHBQQEJDDvcnejfdY/3N/JWXadqVKlfTDDz+oWbNmt/1LDGdnZz322GNasGCB4uPjtWzZMrVt21Z+fn7WMcuXL1dYWJimTJlibUtNTc3Tw7U2bNigc+fO6auvvrIJtLGxsVmOP3nypPX1YzccPHhQkqxP7v6nG9950aJFFRwcnOsaO3XqpIkTJ2rBggVZhu709HQtWbJExYsXV7NmzWz6svr+Dh48mG2t0l/fp2EYCgwMtJ7Fz05u/3716tVLgwcP1oEDB7R06VLdd9996ty5s7X/xnF34MABtW3b1mbdAwcOFLr3qwNAQcHl5QAAG+vXr9fbb7+twMDAm76f+fz585na6tWrJ0lKS0uTJGs4yq+nHi9YsMDmMt/ly5fr1KlTat++vbWtUqVK2rp1q65evWptW7VqVabLvnv06KGzZ89qxowZmbaT3VloR0dHPfzww/r6669tLhGOj4/XkiVL1Lx5c+ulunlRunRp1atXT/Pnz7e5xHrdunXau3evzdiePXsqPT1db7/9dqZ5rl+/nuPPvm/fvrp27Zqee+45JSQkZPruHR0dM30uH374Ybav9sqJG2dy/z7v1atXNWvWrCzHX79+XXPnzrUZO3fuXHl7e6thw4ZZruPj46PWrVtr7ty5OnXqVKb+W72+7cEHH1RwcLDmzZunVatWZep/8803dfDgQQ0fPjzTLz1Wrlxpc7/4r7/+qqioKJvj9Z+6d+8uR0dHjR07NtPnbRiGzp07Z112c3PL8tL+7PTo0UOOjo767LPPtGzZMnXq1MnmFxiNGjWSj4+P5syZY/07LEnff/+99u3bp44dO+Z4WwCA/8eZbgC4h33//ffav3+/rl+/rvj4eK1fv17r1q1T+fLl9c0339g8TOmfxo0bp02bNqljx44qX768zpw5o1mzZqls2bJq3ry5pL8CcLFixTRnzhx5eHjIzc1NTZs2zfH9vv9UokQJNW/eXP3791d8fLymTZumypUr69lnn7WOGTBggJYvX65HHnlEPXv21JEjR7Ro0SJVqlTJZq7Q0FAtWLBA4eHh+vXXX9WiRQulpKTohx9+0ODBg60Pl/qn8ePHW99PPnjwYBUpUkRz585VWlqaJk+efFv7lZWJEyeqY8eOat68uZ5++mmdP39eH374oe6//34lJydbx7Vq1UrPPfecJk6cqJ07d+rhhx9W0aJFdejQIS1btkzTp0/XY489dsvttWrVSmXLltXXX38tV1dXde/e3aa/U6dOWrhwoby8vFSzZk1t2bJFP/zwg0qWLHnb+/jggw+qePHiCgsL00svvSSLxaKFCxdm+0sPf39/vfvuuzp27JiqVq2qpUuXaufOnfroo49uerXCzJkz1bx5c9WuXVvPPvusKlasqPj4eG3ZskUnTpzQb7/9dtM6FyxYoHbt2qlLly564okn1KJFC6Wlpemrr77Shg0b1KtXL7366quZ1qtcubKaN2+uQYMGKS0tTdOmTVPJkiU1fPjwbLdVqVIljR8/XiNGjNCxY8fUtWtXeXh4KDY2VitWrNDAgQP1yiuvSJIaNmyopUuXKjw8XI0bN5a7u7vNmet/8vHxUZs2bTR16lQlJSWpV69eNv1FixbVu+++q/79+6tVq1bq06eP4uPjNX36dFWoUEHDhg276ecEAMiGXZ6ZDgCwqxuvbrrx4+TkZPj5+RkPPfSQMX36dJvXct3wz1cbRUZGGl26dDH8/f0NJycnw9/f3+jTp49x8OBBm/W+/vpro2bNmkaRIkVsXmPUqlUr4/7778+yvuxeGfbZZ58ZI0aMMHx8fAxXV1ejY8eOxvHjxzOtP2XKFKNMmTKGs7Oz0axZMyM6OjrTnIbx1+uq3nzzTSMwMNAoWrSo4efnZzz22GM2rwPTP14ZZhiGsX37diMkJMRwd3c37rvvPqNNmzbGL7/8kuVn/M/Xst3Ylx9//DHLff+7L7/80qhRo4bh7Oxs1KxZ0/jqq6+MsLCwLF8T9dFHHxkNGzY0XF1dDQ8PD6N27drG8OHDjZMnT95yOze8+uqrhiSjZ8+emfouXLhg9O/f3yhVqpTh7u5uhISEGPv378/0irabvY4uq1eG/fzzz8YDDzxguLq6Gv7+/sbw4cONNWvWZPqMbhwv0dHRRlBQkOHi4mKUL1/emDFjhs02snpdlmEYxpEjR4zQ0FDDz8/PKFq0qFGmTBmjU6dOxvLly3P02SQlJRljxowx7r//futn3KxZMyMiIsLmlXB/r+Hf//63MWXKFCMgIMBwdnY2WrRoYfz22282Y//59+qGL7/80mjevLnh5uZmuLm5GdWrVzeGDBlifYWbYRhGcnKy8cQTTxjFihWzeZVcdp+BYRjGxx9/bEgyPDw8bF4L9ndLly416tevbzg7OxslSpQw+vbta/PqMwBA7lgMI5+e5AIAAIBcGTlypCZOnKjr16/buxQAgEm4pxsAAMBOTp06pVKlStm7DACAibinGwAA4A47evSoVqxYYX2gGQDg7sWZbgAAgDts06ZNGjt2rFq1aqWpU6fauxwAgIm4pxsAAAAAAJNwphsAAAAAAJMQugEAAAAAMAmhGwAAAAAAk9z1Ty/PyMjQyZMn5eHhIYvFYu9yAAAAAAB3AcMwlJSUJH9/fzk4ZH8++64P3SdPnlRAQIC9ywAAAAAA3IX++OMPlS1bNtv+uz50e3h4SPrrg/D09LRzNQAAAACAu0FiYqICAgKsmTM7d33ovnFJuaenJ6EbAAAAAJCvbnUbMw9SAwAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6MYt/fnnn3ryySdVsmRJubq6qnbt2oqOjrb2G4ahUaNGqXTp0nJ1dVVwcLAOHTp0y3lnzpypChUqyMXFRU2bNtWvv/5q0x8eHq4SJUooICBAixcvtulbtmyZOnfunD87CAAAAAAmIXTjpi5cuKBmzZqpaNGi+v7777V3715NmTJFxYsXt46ZPHmyPvjgA82ZM0dRUVFyc3NTSEiIUlNTs5136dKlCg8P1+jRo7V9+3bVrVtXISEhOnPmjCTp22+/1ZIlS7R27VpNnjxZAwYM0NmzZyVJly5d0ptvvqmZM2eau/MAAAAAkEcWwzAMexdhpsTERHl5eenSpUu8Muw2vP766/r555/1008/ZdlvGIb8/f318ssv65VXXpH0Vyj29fVVRESEevfuneV6TZs2VePGjTVjxgxJUkZGhgICAvTiiy/q9ddf1+TJk7V9+3Z9/vnnkiRfX1+tWrVKjRs31nPPPafq1atr2LBhJuwxAAAAANxaTrMmZ7pxU998840aNWqkxx9/XD4+Pqpfv74+/vhja39sbKxOnz6t4OBga5uXl5eaNm2qLVu2ZDnn1atXFRMTY7OOg4ODgoODrevUrVtX0dHRunDhgmJiYnTlyhVVrlxZmzdv1vbt2/XSSy+ZtMcAAAAAkH8I3bipo0ePavbs2apSpYrWrFmjQYMG6aWXXtL8+fMlSadPn5b015nov/P19bX2/dPZs2eVnp5+03VCQkL05JNPqnHjxurXr5/mz58vNzc3DRo0SHPmzNHs2bNVrVo1NWvWTHv27Mnv3QYAAACAfFHE3gWgYMvIyFCjRo00YcIESVL9+vW1e/duzZkzR2FhYaZue8yYMRozZox1eezYsQoODlbRokU1fvx47dq1S6tWrVJoaKhiYmJMrQUAAAAAbgdnunFTpUuXVs2aNW3aatSoobi4OEmSn5+fJCk+Pt5mTHx8vLXvn0qVKiVHR8dcrbN//34tWrRIb7/9tjZs2KCWLVvK29tbPXv21Pbt25WUlHRb+wcAAAAAZiJ046aaNWumAwcO2LQdPHhQ5cuXlyQFBgbKz89PkZGR1v7ExERFRUUpKCgoyzmdnJzUsGFDm3UyMjIUGRmZ5TqGYei5557T1KlT5e7urvT0dF27dk2SrP+bnp6etx0FAAAAABMQunFTw4YN09atWzVhwgQdPnxYS5Ys0UcffaQhQ4ZIkiwWi4YOHarx48frm2++0a5duxQaGip/f3917drVOk+7du2sTyqX/noH98cff6z58+dr3759GjRokFJSUtS/f/9MNfznP/+Rt7e39b3czZo10/r167V161a9//77qlmzpooVK2bq5wAAAAAAt4N7unFTjRs31ooVKzRixAiNGzdOgYGBmjZtmvr27WsdM3z4cKWkpGjgwIG6ePGimjdvrtWrV8vFxcU65siRI9b3bEtSr169lJCQoFGjRun06dOqV6+eVq9enenhavHx8XrnnXf0yy+/WNuaNGmil19+WR07dpSPj4/1oW4AAAAAUNDwnm4AAAAAAHKJ93QDAAAAAGBndg/df/75p5588kmVLFlSrq6uql27tqKjo639hmFo1KhRKl26tFxdXRUcHKxDhw7ZsWIAAAAAAHLGrqH7woULatasmYoWLarvv/9ee/fu1ZQpU1S8eHHrmMmTJ+uDDz7QnDlzFBUVJTc3N4WEhCg1NdWOlQMAAAAAcGt2vaf79ddf188//6yffvopy37DMOTv76+XX35Zr7zyiiTp0qVL8vX1VUREhHr37n3LbXBPNwAAAAAgvxWKe7q/+eYbNWrUSI8//rh8fHxUv359ffzxx9b+2NhYnT59WsHBwdY2Ly8vNW3aVFu2bLFHyQAAAAAA5JhdXxl29OhRzZ49W+Hh4XrjjTe0bds2vfTSS3JyclJYWJhOnz4tSZleI+Xr62vt+6e0tDSlpaVZlxMTEyVJGRkZysjIMGlP8sfZs2et9aLw8/T0VKlSpexdBgAAAAAT5DRf2jV0Z2RkqFGjRpowYYIkqX79+tq9e7fmzJmjsLCw25pz4sSJGjt2bKb2hISEAn0f+KVLl/TBjFm6cvWqvUtBPnF1ctJLLwyWl5eXvUsBAAAAkM+SkpJyNM6uobt06dKqWbOmTVuNGjX05ZdfSpL8/PwkSfHx8SpdurR1THx8vOrVq5flnCNGjFB4eLh1OTExUQEBAfL29i7Q93QnJydr7+EjavXkcyrpV9be5SCPzp0+oY2L5srR0VE+Pj72LgcAAABAPnNxccnROLuG7mbNmunAgQM2bQcPHlT58uUlSYGBgfLz81NkZKQ1ZCcmJioqKkqDBg3Kck5nZ2c5OztnandwcJCDg93fkJYti8UiwzBUsnSA/MoH2rsc5NX/vk+LxVKgjzsAAAAAtyen/863a+geNmyYHnzwQU2YMEE9e/bUr7/+qo8++kgfffSRpL+C6NChQzV+/HhVqVJFgYGBGjlypPz9/dW1a1d7lg4AAAAAwC3ZNXQ3btxYK1as0IgRIzRu3DgFBgZq2rRp6tu3r3XM8OHDlZKSooEDB+rixYtq3ry5Vq9eneNT+QAAAAAA2ItdQ7ckderUSZ06dcq232KxaNy4cRo3btwdrAoAAAAAgLzjZlMAAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATGLX0D1mzBhZLBabn+rVq1v7U1NTNWTIEJUsWVLu7u7q0aOH4uPj7VgxAAAAAAA5Z/cz3ffff79OnTpl/dm8ebO1b9iwYfr222+1bNkybdy4USdPnlT37t3tWC0AAAAAADlXxO4FFCkiPz+/TO2XLl3SJ598oiVLlqht27aSpHnz5qlGjRraunWrHnjggTtdKgAAAAAAuWL3M92HDh2Sv7+/KlasqL59+youLk6SFBMTo2vXrik4ONg6tnr16ipXrpy2bNlir3IBAAAAAMgxu57pbtq0qSIiIlStWjWdOnVKY8eOVYsWLbR7926dPn1aTk5OKlasmM06vr6+On36dLZzpqWlKS0tzbqcmJgoScrIyFBGRoYp+5EfDMOQxWKRDEMyCm6dyKH/fZ+GYRTo4w4AAADA7cnpv/PtGrrbt29v/XOdOnXUtGlTlS9fXl988YVcXV1va86JEydq7NixmdoTEhKUmpp627WaLSkpSYHlAuSafkWWpPP2Lgd55Jp+RYHlApSUlKQzZ87YuxwAAAAA+SwpKSlH4+x+T/ffFStWTFWrVtXhw4f10EMP6erVq7p48aLN2e74+Pgs7wG/YcSIEQoPD7cuJyYmKiAgQN7e3vL09DSz/DxJTk5WbNwfqu/oKi+PEvYuB3l05XyiYuP+kIeHh3x8fOxdDgAAAIB85uLikqNxBSp0Jycn68iRI3rqqafUsGFDFS1aVJGRkerRo4ck6cCBA4qLi1NQUFC2czg7O8vZ2TlTu4ODgxwc7H4Le7ZuXIosi0WyFNw6kUP/+z4tFkuBPu4AAAAA3J6c/jvfrqH7lVdeUefOnVW+fHmdPHlSo0ePlqOjo/r06SMvLy8988wzCg8PV4kSJeTp6akXX3xRQUFBPLkcAAAAAFAo2DV0nzhxQn369NG5c+fk7e2t5s2ba+vWrfL29pYkvf/++3JwcFCPHj2UlpamkJAQzZo1y54lAwAAAACQY3YN3Z9//vlN+11cXDRz5kzNnDnzDlUEAAAAAED+4WZTAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExSYEL3pEmTZLFYNHToUGtbamqqhgwZopIlS8rd3V09evRQfHy8/YoEAAAAACAXCkTo3rZtm+bOnas6derYtA8bNkzffvutli1bpo0bN+rkyZPq3r27naoEAAAAACB37B66k5OT1bdvX3388ccqXry4tf3SpUv65JNPNHXqVLVt21YNGzbUvHnz9Msvv2jr1q12rBgAAAAAgJwpYu8ChgwZoo4dOyo4OFjjx4+3tsfExOjatWsKDg62tlWvXl3lypXTli1b9MADD2Q5X1pamtLS0qzLiYmJkqSMjAxlZGSYtBd5ZxiGLBaLZBiSUXDrRA797/s0DKNAH3cAAAAAbk9O/51v19D9+eefa/v27dq2bVumvtOnT8vJyUnFihWzaff19dXp06eznXPixIkaO3ZspvaEhASlpqbmuWazJCUlKbBcgFzTr8iSdN7e5SCPXNOvKLBcgJKSknTmzBl7lwMAAAAgnyUlJeVonN1C9x9//KF//etfWrdunVxcXPJt3hEjRig8PNy6nJiYqICAAHl7e8vT0zPftpPfkpOTFRv3h+o7usrLo4S9y0EeXTmfqNi4P+Th4SEfHx97lwMAAAAgn+U0x9otdMfExOjMmTNq0KCBtS09PV2bNm3SjBkztGbNGl29elUXL160OdsdHx8vPz+/bOd1dnaWs7NzpnYHBwc5ONj9FvZs3bgUWRaLZCm4dSKH/vd9WiyWAn3cAQAAALg9Of13vt1Cd7t27bRr1y6btv79+6t69ep67bXXFBAQoKJFiyoyMlI9evSQJB04cEBxcXEKCgqyR8kAAAAAAOSK3UK3h4eHatWqZdPm5uamkiVLWtufeeYZhYeHq0SJEvL09NSLL76ooKCgbB+iBgAAAABAQWL3p5ffzPvvvy8HBwf16NFDaWlpCgkJ0axZs+xdFgAAAAAAOVKgQveGDRtsll1cXDRz5kzNnDnTPgUBAAAAAJAHPOEJAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwSZHcrhAbG6uffvpJx48f1+XLl+Xt7a369esrKChILi4uZtQIAAAAAEChlOPQvXjxYk2fPl3R0dHy9fWVv7+/XF1ddf78eR05ckQuLi7q27evXnvtNZUvX97MmgEAAAAAKBRyFLrr168vJycn9evXT19++aUCAgJs+tPS0rRlyxZ9/vnnatSokWbNmqXHH3/clIIBAAAAACgschS6J02apJCQkGz7nZ2d1bp1a7Vu3VrvvPOOjh07ll/1AQAAAABQaOUodN8scP9TyZIlVbJkydsuCAAAAACAu0WuH6T2d9999502bNig9PR0NWvWTD169MivugAAAAAAKPRu+5VhI0eO1PDhw2WxWGQYhoYNG6YXX3wxP2sDAAAAAKBQy/GZ7ujoaDVq1Mi6vHTpUv32229ydXWVJPXr10+tW7fWhx9+mP9VAgAAAABQCOX4TPfzzz+voUOH6vLly5KkihUrasqUKTpw4IB27dql2bNnq2rVqqYVCgAAAABAYZPj0B0VFaXSpUurQYMG+vbbb/Xpp59qx44devDBB9WiRQudOHFCS5YsMbNWAAAAAAAKlRxfXu7o6KjXXntNjz/+uAYNGiQ3NzfNmDFD/v7+ZtYHAAAAAEChlesHqVWsWFFr1qxRt27d1LJlS82cOdOMugAAAAAAKPRyHLovXryo4cOHq3PnznrrrbfUrVs3RUVFadu2bXrggQe0a9cuM+sEAAAAAKDQyXHoDgsLU1RUlDp27KgDBw5o0KBBKlmypCIiIvTOO++oV69eeu2118ysFQAAAACAQiXH93SvX79eO3bsUOXKlfXss8+qcuXK1r527dpp+/btGjdunClFAgAAAABQGOX4THeVKlX00Ucf6eDBg5ozZ47Kly9v0+/i4qIJEybke4EAAAAAABRWOQ7dn376qdavX6/69etryZIlmj17tpl1AQAAAABQ6OX48vJ69eopOjrazFoAAAAAALir5OhMt2EYZtcBAAAAAMBdJ0eh+/7779fnn3+uq1ev3nTcoUOHNGjQIE2aNClfigMAAAAAoDDL0eXlH374oV577TUNHjxYDz30kBo1aiR/f3+5uLjowoUL2rt3rzZv3qw9e/bohRde0KBBg8yuGwAAAACAAi9Hobtdu3aKjo7W5s2btXTpUi1evFjHjx/XlStXVKpUKdWvX1+hoaHq27evihcvbnbNAAAAAAAUCjl+kJokNW/eXM2bNzerFgAAAAAA7io5fmUYAAAAAADIHUI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYJLbCt1HjhzRW2+9pT59+ujMmTOSpO+//1579uzJ1+IAAAAAACjMch26N27cqNq1aysqKkpfffWVkpOTJUm//fabRo8ene8FAgAAAABQWOU6dL/++usaP3681q1bJycnJ2t727ZttXXr1nwtDgAAAACAwizXoXvXrl3q1q1bpnYfHx+dPXs2X4oCAAAAAOBukOvQXaxYMZ06dSpT+44dO1SmTJl8KQoAAAAAgLtBrkN379699dprr+n06dOyWCzKyMjQzz//rFdeeUWhoaFm1AgAAAAAQKGU69A9YcIEVa9eXQEBAUpOTlbNmjXVsmVLPfjgg3rrrbfMqBEAAAAAgEKpSG5XcHJy0scff6yRI0dq9+7dSk5OVv369VWlShUz6gMAAAAAoNDKdei+oVy5cipXrlx+1gIAAAAAwF0lR6E7PDxcb7/9ttzc3BQeHn7Tse7u7rr//vv12GOPydHRMV+KBAAAAACgMMpR6N6xY4euXbtm/fPNpKWlafr06frvf/+r+fPn571CAAAAAAAKqRyF7h9//DHLP2cnOjpa7dq1u/2qAAAAAAC4C+T66eU5UadOHS1YsMCMqQEAAAAAKDRu60FqJ06c0DfffKO4uDhdvXrVpm/q1KlycnJSly5d8qVAAAAAAAAKq1yH7sjISD366KOqWLGi9u/fr1q1aunYsWMyDEMNGjQwo0YAAAAAAAqlXF9ePmLECL3yyivatWuXXFxc9OWXX+qPP/5Qq1at9Pjjj5tRIwAAAAAAhVKuQ/e+ffsUGhoqSSpSpIiuXLkid3d3jRs3Tu+++26+FwgAAAAAQGGV69Dt5uZmvY+7dOnSOnLkiLXv7Nmz+VcZAAAAAACFXK7v6X7ggQe0efNm1ahRQx06dNDLL7+sXbt26auvvtIDDzxgRo0AAAAAABRKuQ7dU6dOVXJysiRp7NixSk5O1tKlS1WlShVNnTo13wsEAAAAAKCwynXorlixovXPbm5umjNnTr4WBAAAAADA3SLX93RXrFhR586dy9R+8eJFm0AOAAAAAMC9Lteh+9ixY0pPT8/UnpaWpj///DNfigIAAAAA4G6Q48vLv/nmG+uf16xZIy8vL+tyenq6IiMjVaFChXwtDgAAAACAwizHobtr166SJIvForCwMJu+okWLqkKFCpoyZUq+FgcAAAAAQGGW49CdkZEhSQoMDNS2bdtUqlQp04oCAAAAAOBukOunl8fGxppRBwAAAAAAd51ch25JioyMVGRkpM6cOWM9A37Dp59+mi+FAQAAAABQ2OU6dI8dO1bjxo1To0aNVLp0aVksFjPqAgAAAACg0Mt16J4zZ44iIiL01FNP5Xnjs2fP1uzZs3Xs2DFJ0v33369Ro0apffv2kqTU1FS9/PLL+vzzz5WWlqaQkBDNmjVLvr6+ed42AAAAAABmy/V7uq9evaoHH3wwXzZetmxZTZo0STExMYqOjlbbtm3VpUsX7dmzR5I0bNgwffvtt1q2bJk2btyokydPqnv37vmybQAAAAAAzJbr0D1gwAAtWbIkXzbeuXNndejQQVWqVFHVqlX1zjvvyN3dXVu3btWlS5f0ySefaOrUqWrbtq0aNmyoefPm6ZdfftHWrVvzZfsAAAAAAJgp15eXp6am6qOPPtIPP/ygOnXqqGjRojb9U6dOva1C0tPTtWzZMqWkpCgoKEgxMTG6du2agoODrWOqV6+ucuXKacuWLXrggQeynCctLU1paWnW5cTEREl/vfLsnw99K0gMw/jr/njDkIyCWydy6H/fp2EYBfq4AwAAAHB7cvrv/FyH7t9//1316tWTJO3evdum73YeqrZr1y4FBQUpNTVV7u7uWrFihWrWrKmdO3fKyclJxYoVsxnv6+ur06dPZzvfxIkTNXbs2EztCQkJSk1NzXV9d0pSUpICywXINf2KLEnn7V0O8sg1/YoCywUoKSlJZ86csXc5AAAAAPJZUlJSjsblOnT/+OOPuS7mZqpVq6adO3fq0qVLWr58ucLCwrRx48bbnm/EiBEKDw+3LicmJiogIEDe3t7y9PTMj5JNkZycrNi4P1Tf0VVeHiXsXQ7y6Mr5RMXG/SEPDw/5+PjYuxwAAAAA+czFxSVH427rPd2SdPjwYR05ckQtW7aUq6vr/18enUtOTk6qXLmyJKlhw4batm2bpk+frl69eunq1au6ePGizdnu+Ph4+fn5ZTufs7OznJ2dM7U7ODjIwSHXt7DfMTcuRZbFIlkKbp3Iof99nxaLpUAfdwAAAABuT07/nZ/rNHDu3Dm1a9dOVatWVYcOHXTq1ClJ0jPPPKOXX345t9NlkpGRobS0NDVs2FBFixZVZGSkte/AgQOKi4tTUFBQnrcDAAAAAIDZch26hw0bpqJFiyouLk733Xeftb1Xr15avXp1ruYaMWKENm3apGPHjmnXrl0aMWKENmzYoL59+8rLy0vPPPOMwsPD9eOPPyomJkb9+/dXUFBQtg9RAwAAAACgIMn15eVr167VmjVrVLZsWZv2KlWq6Pjx47ma68yZMwoNDdWpU6fk5eWlOnXqaM2aNXrooYckSe+//74cHBzUo0cPpaWlKSQkRLNmzcptyQAAAAAA2EWuQ3dKSorNGe4bzp8/n+W91DfzySef3LTfxcVFM2fO1MyZM3M1LwAAAAAABUGuLy9v0aKFFixYYF22WCzKyMjQ5MmT1aZNm3wtDgAAAACAwizXZ7onT56sdu3aKTo6WlevXtXw4cO1Z88enT9/Xj///LMZNQIAAAAAUCjl+kx3rVq1dPDgQTVv3lxdunRRSkqKunfvrh07dqhSpUpm1AgAAAAAQKF0W+/p9vLy0ptvvpnftQAAAAAAcFfJ9ZnuefPmadmyZZnaly1bpvnz5+dLUQAAAAAA3A1yHbonTpyoUqVKZWr38fHRhAkT8qUoAAAAAADuBrkO3XFxcQoMDMzUXr58ecXFxeVLUQAAAAAA3A1yHbp9fHz0+++/Z2r/7bffVLJkyXwpCgAAAACAu0GuQ3efPn300ksv6ccff1R6errS09O1fv16/etf/1Lv3r3NqBEAAAAAgEIp108vf/vtt3Xs2DG1a9dORYr8tXpGRoZCQ0O5pxsAAAAAgL/JVeg2DEOnT59WRESExo8fr507d8rV1VW1a9dW+fLlzaoRAAAAAIBCKdehu3LlytqzZ4+qVKmiKlWqmFUXAAAAAACFXq7u6XZwcFCVKlV07tw5s+oBAAAAAOCukesHqU2aNEmvvvqqdu/ebUY9AAAAAADcNXL9ILXQ0FBdvnxZdevWlZOTk1xdXW36z58/n2/FAQAAAABQmOU6dE+bNs2EMgAAAAAAuPvkOnSHhYWZUQcAAAAAAHedXIduSUpPT9fKlSu1b98+SdL999+vRx99VI6OjvlaHAAAAAAAhVmuQ/fhw4fVoUMH/fnnn6pWrZokaeLEiQoICNB3332nSpUq5XuRAAAAAAAURrl+evlLL72kSpUq6Y8//tD27du1fft2xcXFKTAwUC+99JIZNQIAAAAAUCjl+kz3xo0btXXrVpUoUcLaVrJkSU2aNEnNmjXL1+IAAAAAACjMcn2m29nZWUlJSZnak5OT5eTklC9FAQAAAABwN8h16O7UqZMGDhyoqKgoGYYhwzC0detWPf/883r00UfNqBEAAAAAgEIp16H7gw8+UKVKlRQUFCQXFxe5uLioWbNmqly5sqZPn25GjQAAAAAAFEq5vqe7WLFi+vrrr3X48GHrK8Nq1KihypUr53txAAAAAAAUZjkO3RkZGfr3v/+tb775RlevXlW7du00evRoubq6mlkfAAAAAACFVo4vL3/nnXf0xhtvyN3dXWXKlNH06dM1ZMgQM2sDAAAAAKBQy3HoXrBggWbNmqU1a9Zo5cqV+vbbb7V48WJlZGSYWR8AAAAAAIVWjkN3XFycOnToYF0ODg6WxWLRyZMnTSkMAAAAAIDCLseh+/r163JxcbFpK1q0qK5du5bvRQEAAAAAcDfI8YPUDMNQv3795OzsbG1LTU3V888/Lzc3N2vbV199lb8VAgAAAABQSOU4dIeFhWVqe/LJJ/O1GAAAAAAA7iY5Dt3z5s0zsw4AAAAAAO46Ob6nGwAAAAAA5A6hGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJPYNXRPnDhRjRs3loeHh3x8fNS1a1cdOHDAZkxqaqqGDBmikiVLyt3dXT169FB8fLydKgYAAAAAIOfsGro3btyoIUOGaOvWrVq3bp2uXbumhx9+WCkpKdYxw4YN07fffqtly5Zp48aNOnnypLp3727HqgEAAAAAyJki9tz46tWrbZYjIiLk4+OjmJgYtWzZUpcuXdInn3yiJUuWqG3btpKkefPmqUaNGtq6daseeOABe5QNAAAAAECO2DV0/9OlS5ckSSVKlJAkxcTE6Nq1awoODraOqV69usqVK6ctW7ZkGbrT0tKUlpZmXU5MTJQkZWRkKCMjw8zy88QwDFksFskwJKPg1okc+t/3aRhGgT7uAAAAANyenP47v8CE7oyMDA0dOlTNmjVTrVq1JEmnT5+Wk5OTihUrZjPW19dXp0+fznKeiRMnauzYsZnaExISlJqamu9155ekpCQFlguQa/oVWZLO27sc5JFr+hUFlgtQUlKSzpw5Y+9yAAAAAOSzpKSkHI0rMKF7yJAh2r17tzZv3pyneUaMGKHw8HDrcmJiogICAuTt7S1PT8+8lmma5ORkxcb9ofqOrvLyKGHvcpBHV84nKjbuD+tDAgEAAADcXVxcXHI0rkCE7hdeeEGrVq3Spk2bVLZsWWu7n5+frl69qosXL9qc7Y6Pj5efn1+Wczk7O8vZ2TlTu4ODgxwcCu4b0m5ciiyLRbIU3DqRQ//7Pi0WS4E+7gAAAADcnpz+O9+uacAwDL3wwgtasWKF1q9fr8DAQJv+hg0bqmjRooqMjLS2HThwQHFxcQoKCrrT5QIAAAAAkCt2PdM9ZMgQLVmyRF9//bU8PDys92l7eXnJ1dVVXl5eeuaZZxQeHq4SJUrI09NTL774ooKCgnhyOQAAAACgwLNr6J49e7YkqXXr1jbt8+bNU79+/SRJ77//vhwcHNSjRw+lpaUpJCREs2bNusOVAgAAAACQe3YN3YZh3HKMi4uLZs6cqZkzZ96BigAAAAAAyD884QkAAAAAAJMQugGYatOmTercubP8/f1lsVi0cuXKTGP27dunRx99VF5eXnJzc1Pjxo0VFxeX7ZzXrl3TuHHjVKlSJbm4uKhu3bpavXq1zZjFixcrICBAxYsXt3mNoCQdO3ZMVatWVWJiYr7sIwAAAJAdQjcAU6WkpKhu3brZ3iJy5MgRNW/eXNWrV9eGDRv0+++/a+TIkTd97+Fbb72luXPn6sMPP9TevXv1/PPPq1u3btqxY4ck6ezZsxowYIDee+89rV27VosWLdKqVaus6w8ePFiTJk2Sp6dn/u4sAAAA8A8F4j3dAO5e7du3V/v27bPtf/PNN9WhQwdNnjzZ2lapUqWbzrlw4ULrepI0aNAg/fDDD5oyZYoWLVqko0ePysvLS7169ZIktWnTRvv27VOnTp302WefqWjRourevXs+7B0AAABwc5zpBmA3GRkZ+u6771S1alWFhITIx8dHTZs2zfIS9L9LS0vLdCbc1dVVmzdvliRVqVJFly9f1o4dO3T+/Hlt27ZNderU0YULFzRy5EjNmDHDrF0CAAAAbBC6AdjNmTNnlJycrEmTJumRRx7R2rVr1a1bN3Xv3l0bN27Mdr2QkBBNnTpVhw4dUkZGhtatW6evvvpKp06dkiQVL15c8+fPV2hoqJo0aaLQ0FCFhITolVde0QsvvKDY2FjVr19ftWrV0vLly+/U7gIAAOAexOXlAOwmIyNDktSlSxcNGzZMklSvXj398ssvmjNnjlq1apXletOnT9ezzz6r6tWry2KxqFKlSurfv78+/fRT65hu3bqpW7du1uWNGzfq999/14cffqjKlSvrs88+k5+fn5o0aaKWLVvKx8fHxD0FAADAvYoz3QDsplSpUipSpIhq1qxp016jRo2bPr3c29tbK1euVEpKio4fP679+/fL3d1dFStWzHJ8WlqaBg8erLlz5+rw4cO6fv26WrVqpWrVqqlq1aqKiorK1/0CAAAAbiB0A7AbJycnNW7cWAcOHLBpP3jwoMqXL3/L9V1cXFSmTBldv35dX375pbp06ZLluPHjx+uRRx5RgwYNlJ6eruvXr1v7rl27pvT09LztCAAAAJANLi8HYKrk5GQdPnzYuhwbG6udO3eqRIkSKleunF599VX16tVLLVu2VJs2bbR69Wp9++232rBhg3Wd0NBQlSlTRhMnTpQkRUVF6c8//1S9evX0559/asyYMcrIyNDw4cMzbX/v3r1aunSp9XVi1atXl4ODgz755BP5+flp//79aty4sbkfAgAAAO5ZhG4ApoqOjlabNm2sy+Hh4ZKksLAwRUREqFu3bpozZ44mTpyol156SdWqVdOXX36p5s2bW9eJi4uTg8P/X5iTmpqqt956S0ePHpW7u7s6dOighQsXqlixYjbbNgxDAwcO1NSpU+Xm5ibpr6ecR0REaMiQIUpLS9OMGTNUpkwZEz8BAAAA3MsI3QBM1bp1axmGcdMxTz/9tJ5++uls+/9+1luSWrVqpb17995y2xaLxfoasb/r1KmTOnXqdMv1AQAAgLzinm4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMwtPLgbtIQkKCEhMT7V0G8oGnp6e8vb3tXQYAAADyiNAN3CUSEhL09MDnlXQl1d6lIB94uLro04/mELwBAAAKOUI3cJdITExU0pVUtX5qkEqWLmvvcpAH506d0IaFs5WYmEjoBgAAKOQI3cBdpmTpsvIrH2jvMgAAAACIB6kBAAAAAGAaQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAq0TZs2qXPnzvL395fFYtHKlStt+g3D0KhRo1S6dGm5uroqODhYhw4duumcFSpUkMViyfQzZMgQ65jw8HCVKFFCAQEBWrx4sc36y5YtU+fOnfNtHwEAwN2L0A0AKNBSUlJUt25dzZw5M8v+yZMn64MPPtCcOXMUFRUlNzc3hYSEKDU1Nds5t23bplOnTll/1q1bJ0l6/PHHJUnffvutlixZorVr12ry5MkaMGCAzp49K0m6dOmS3nzzzWzrAQAA+Lsi9i4AAICbad++vdq3b59ln2EYmjZtmt566y116dJFkrRgwQL5+vpq5cqV6t27d5breXt72yxPmjRJlSpVUqtWrSRJ+/btU+vWrdWoUSM1atRIQ4cOVWxsrEqVKqXhw4dr0KBBKleuXD7uJQAAuFtxphsAUGjFxsbq9OnTCg4OtrZ5eXmpadOm2rJlS47muHr1qhYtWqSnn35aFotFklS3bl1FR0frwoULiomJ0ZUrV1S5cmVt3rxZ27dv10svvWTK/gAAgLsPoRsAUGidPn1akuTr62vT7uvra+27lZUrV+rixYvq16+ftS0kJERPPvmkGjdurH79+mn+/Plyc3PToEGDNGfOHM2ePVvVqlVTs2bNtGfPnnzbHwAAcPfh8nIAwD3tk08+Ufv27eXv72/TPmbMGI0ZM8a6PHbsWAUHB6to0aIaP368du3apVWrVik0NFQxMTF3uGoAAFBYcKYbAFBo+fn5SZLi4+Nt2uPj4619N3P8+HH98MMPGjBgwE3H7d+/X4sWLdLbb7+tDRs2qGXLlvL29lbPnj21fft2JSUl3f5OAACAuxqhGwBQaAUGBsrPz0+RkZHWtsTEREVFRSkoKOiW68+bN08+Pj7q2LFjtmMMw9Bzzz2nqVOnyt3dXenp6bp27ZokWf83PT09j3sCAADuVoRuAECBlpycrJ07d2rnzp2S/np42s6dOxUXFyeLxaKhQ4dq/Pjx+uabb7Rr1y6FhobK399fXbt2tc7Rrl07zZgxw2bejIwMzZs3T2FhYSpSJPu7rf7zn//I29vb+l7uZs2aaf369dq6davef/991axZU8WKFcvv3QYAAHcJ7ukGABRo0dHRatOmjXU5PDxckhQWFqaIiAgNHz5cKSkpGjhwoC5evKjmzZtr9erVcnFxsa5z5MgR63u2b/jhhx8UFxenp59+Otttx8fH65133tEvv/xibWvSpIlefvlldezYUT4+Ppo/f35+7SoAALgLEboBAAVa69atZRhGtv0Wi0Xjxo3TuHHjsh1z7NixTG0PP/zwTeeV/noKelbrjho1SqNGjbrpugAAABKXlwMAAAAAYBpCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASnl4OAJAkJSQkKDEx0d5lIJ94enrK29vb3mUAAHDPI3QDAJSQkKCnBz6vpCup9i4F+cTD1UWffjSH4A0AgJ3ZNXRv2rRJ//73vxUTE6NTp05pxYoV6tq1q7XfMAyNHj1aH3/8sS5evKhmzZpp9uzZqlKliv2KBoC7UGJiopKupKr1U4NUsnRZe5eDPDp36oQ2LJytxMREQjcAAHZm19CdkpKiunXr6umnn1b37t0z9U+ePFkffPCB5s+fr8DAQI0cOVIhISHau3evXFxc7FAxANzdSpYuK7/ygfYuAwAA4K5h19Ddvn17tW/fPss+wzA0bdo0vfXWW+rSpYskacGCBfL19dXKlSvVu3fvO1kqAAAAAAC5VmDv6Y6NjdXp06cVHBxsbfPy8lLTpk21ZcuWbEN3Wlqa0tLSrMs3HgqUkZGhjIwMc4vOA8MwZLFYJMOQjIJbJ3Lof9+nYRh37LjjGLqLcPwgr+xwDAEAcK/J6X9jC2zoPn36tCTJ19fXpt3X19fal5WJEydq7NixmdoTEhKUmlpwHxCUlJSkwHIBck2/IkvSeXuXgzxyTb+iwHIBSkpK0pkzZ+7INjmG7h4cP8grexxDAADca5KSknI0rsCG7ts1YsQIhYeHW5cTExMVEBAgb29veXp62rGym0tOTlZs3B+q7+gqL48S9i4HeXTlfKJi4/6Qh4eHfHx87sg2OYbuHhw/yCt7HEMAANxrcvqcsQIbuv38/CRJ8fHxKl26tLU9Pj5e9erVy3Y9Z2dnOTs7Z2p3cHCQg4NDvteZX25cBiiLRbIU3DqRQ//7Pi0Wyx077jiG7iIcP8grOxxDAADca3L639gC+1/iwMBA+fn5KTIy0tqWmJioqKgoBQUF2bEyAAAAAAByxq5nupOTk3X48GHrcmxsrHbu3KkSJUqoXLlyGjp0qMaPH68qVapYXxnm7+9v8y5vAAAAAAAKKruG7ujoaLVp08a6fONe7LCwMEVERGj48OFKSUnRwIEDdfHiRTVv3lyrV6/mHd0AAAAAgELBrpeXt27dWoZhZPqJiIiQ9Nc9huPGjdPp06eVmpqqH374QVWrVrVnyQAAoBCrUKGCLBZLpp8hQ4ZkOX7Pnj3q0aOHdb1p06ZlGrN48WIFBASoePHiNg9zlaRjx46patWq1leYAgDuPQX2nm4AAID8tm3bNp06dcr6s27dOknS448/nuX4y5cvq2LFipo0aZL1Ia9/d/bsWQ0YMEDvvfee1q5dq0WLFmnVqlXW/sGDB2vSpEkF+g0qAABzFdinlwMAAOQ3b29vm+VJkyapUqVKatWqVZbjGzdurMaNG0uSXn/99Uz9R48elZeXl3r16iVJatOmjfbt26dOnTrps88+U9GiRdW9e/d83gsAQGHCmW4AAHBPunr1qhYtWqSnn35aFovltuaoUqWKLl++rB07duj8+fPatm2b6tSpowsXLmjkyJGaMWNGPlcNAChsCN0AAOCetHLlSl28eFH9+vW77TmKFy+u+fPnKzQ0VE2aNFFoaKhCQkL0yiuv6IUXXlBsbKzq16+vWrVqafny5flXPACg0ODycgAAcE/65JNP1L59e/n7++dpnm7duqlbt27W5Y0bN+r333/Xhx9+qMqVK+uzzz6Tn5+fmjRpopYtW8rHxyevpQMAChHOdAMAgHvO8ePH9cMPP2jAgAH5Om9aWpoGDx6suXPn6vDhw7p+/bpatWqlatWqqWrVqoqKisrX7QEACj5CNwAAuOfMmzdPPj4+6tixY77OO378eD3yyCNq0KCB0tPTdf36dWvftWvXlJ6enq/bAwAUfFxeDgAA7ikZGRmaN2+ewsLCVKSI7T+FQkNDVaZMGU2cOFHSXw9b27t3r/XPf/75p3bu3Cl3d3dVrlzZZt29e/dq6dKl2rFjhySpevXqcnBw0CeffCI/Pz/t37/f+iR0AMC9g9ANAADuKT/88IPi4uL09NNPZ+qLi4uTg8P/Xwh48uRJ1a9f37r83nvv6b333lOrVq20YcMGa7thGBo4cKCmTp0qNzc3SZKrq6siIiI0ZMgQpaWlacaMGSpTpox5OwYAKJAI3QAA4J7y8MMPyzCMLPv+HqQlqUKFCtmO/TuLxaLNmzdnau/UqZM6dep0W3UCAO4O3NMNAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASXh6OQAAyBcJCQlKTEy0dxnIJ56envL29rZ3GQBQ6BG6AQBAniUkJOjpgc8r6UqqvUtBPvFwddGnH80heANAHhG6AQBAniUmJirpSqpaPzVIJUuXtXc5yKNzp05ow8LZSkxMJHQDQB4RugEAQL4pWbqs/MoH2rsMAAAKDB6kBgAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAOTQ7NmzVadOHXl6esrT01NBQUH6/vvvsx1/7do1jRs3TpUqVZKLi4vq1q2r1atX24xZvHixAgICVLx4cYWHh9v0HTt2TFWrVlViYqIp+wPAfIRuAAAAIIfKli2rSZMmKSYmRtHR0Wrbtq26dOmiPXv2ZDn+rbfe0ty5c/Xhhx9q7969ev7559WtWzft2LFDknT27FkNGDBA7733ntauXatFixZp1apV1vUHDx6sSZMmydPT847sH4D8R+gGAAAAcqhz587q0KGDqlSpoqpVq+qdd96Ru7u7tm7dmuX4hQsX6o033lCHDh1UsWJFDRo0SB06dNCUKVMkSUePHpWXl5d69eqlxo0bq02bNtq3b58k6bPPPlPRokXVvXv3O7Z/APIfoRsAAAC4Denp6fr888+VkpKioKCgLMekpaXJxcXFps3V1VWbN2+WJFWpUkWXL1/Wjh07dP78eW3btk116tTRhQsXNHLkSM2YMcP0/QBgLkI3AAAAkAu7du2Su7u7nJ2d9fzzz2vFihWqWbNmlmNDQkI0depUHTp0SBkZGVq3bp2++uornTp1SpJUvHhxzZ8/X6GhoWrSpIlCQ0MVEhKiV155RS+88IJiY2NVv3591apVS8uXL7+TuwkgnxSxdwEAAABAYVKtWjXt3LlTly5d0vLlyxUWFqaNGzdmGbynT5+uZ599VtWrV5fFYlGlSpXUv39/ffrpp9Yx3bp1U7du3azLGzdu1O+//64PP/xQlStX1meffSY/Pz81adJELVu2lI+Pzx3ZTwD5gzPdAAAAQC44OTmpcuXKatiwoSZOnKi6detq+vTpWY719vbWypUrlZKSouPHj2v//v1yd3dXxYoVsxyflpamwYMHa+7cuTp8+LCuX7+uVq1aqVq1aqpataqioqLM3DUAJiB0AwAAAHmQkZGhtLS0m45xcXFRmTJldP36dX355Zfq0qVLluPGjx+vRx55RA0aNFB6erquX79u7bt27ZrS09PztXYA5uPycgAAACCHRowYofbt26tcuXJKSkrSkiVLtGHDBq1Zs0aSFBoaqjJlymjixImSpKioKP3555+qV6+e/vzzT40ZM0YZGRkaPnx4prn37t2rpUuXWl8nVr16dTk4OOiTTz6Rn5+f9u/fr8aNG9+5nQWQLwjdAAAAQA6dOXNGoaGhOnXqlLy8vFSnTh2tWbNGDz30kCQpLi5ODg7/fzFpamqq3nrrLR09elTu7u7q0KGDFi5cqGLFitnMaxiGBg4cqKlTp8rNzU3SX085j4iI0JAhQ5SWlqYZM2aoTJkyd2xfAeQPQjcAAACQQ5988slN+zds2GCz3KpVK+3du/eW81osFutrxP6uU6dO6tSpU65qBFCwcE83AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJuHp5QAAACgQEhISlJiYaO8ykA88PT3l7e1t7zKAAoHQDQAAALtLSEjQ0wOfV9KVVHuXgnzg4eqiTz+aQ/AGROgGAABAAZCYmKikK6lq/dQglSxd1t7lIA/OnTqhDQtnKzExkdANiNANAACAAqRk6bLyKx9o7zIAIN/wIDUAAAAAuEM2bdqkzp07y9/fXxaLRStXrszxuj///LOKFCmievXq2bQvXrxYAQEBKl68uMLDw236jh07pqpVq/K8BDsidAMAAADAHZKSkqK6detq5syZuVrv4sWLCg0NVbt27Wzaz549qwEDBui9997T2rVrtWjRIq1atcraP3jwYE2aNEmenp75Uj9yj8vLAQAAAOAOad++vdq3b5/r9Z5//nk98cQTcnR0tDk7fvToUXl5ealXr16SpDZt2mjfvn3q1KmTPvvsMxUtWlTdu3fPr/JxGzjTDQAAAAAF2Lx583T06FGNHj06U1+VKlV0+fJl7dixQ+fPn9e2bdtUp04dXbhwQSNHjtSMGTPsUDH+jtANAAAAAAXUoUOH9Prrr2vRokUqUiTzhcrFixfX/PnzFRoaqiZNmig0NFQhISF65ZVX9MILLyg2Nlb169dXrVq1tHz5cjvsAbi8HAAAAAAKoPT0dD3xxBMaO3asqlatmu24bt26qVu3btbljRs36vfff9eHH36oypUr67PPPpOfn5+aNGmili1bysfH506Uj/8hdAMAAABAAZSUlKTo6Gjt2LFDL7zwgiQpIyNDhmGoSJEiWrt2rdq2bWuzTlpamgYPHqyFCxfq8OHDun79ulq1aiVJqlq1qqKiotS5c+c7vi/3MkI3AAAAABRAnp6e2rVrl03brFmztH79ei1fvlyBgZnfaT9+/Hg98sgjatCggXbs2KHr169b+65du6b09HTT64YtQjcAAAAA3CHJyck6fPiwdTk2NlY7d+5UiRIlVK5cOY0YMUJ//vmnFixYIAcHB9WqVctmfR8fH7m4uGRql6S9e/dq6dKl2rFjhySpevXqcnBw0CeffCI/Pz/t379fjRs3NncHkQmhGwAAAADukOjoaLVp08a6HB4eLkkKCwtTRESETp06pbi4uFzPaxiGBg4cqKlTp8rNzU2S5OrqqoiICA0ZMkRpaWmaMWOGypQpkz87ghwjdAMAAADAHdK6dWsZhpFtf0RExE3XHzNmjMaMGZOp3WKxaPPmzZnaO3XqpE6dOuW2TOQjXhkGAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASXh6OQAAAIBCLyEhQYmJifYuA/nE09NT3t7e9i4jXxC6AQAAABRqCQkJenrg80q6kmrvUpBPPFxd9OlHc+6K4E3oBgAAAFCoJSYmKulKqlo/NUglS5e1dznIo3OnTmjDwtlKTEwkdAMAAABAQVGydFn5lQ+0dxmADR6kBgAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJikUITumTNnqkKFCnJxcVHTpk3166+/2rskAAAAAABuqcCH7qVLlyo8PFyjR4/W9u3bVbduXYWEhOjMmTP2Lg0AAAAAgJsq8KF76tSpevbZZ9W/f3/VrFlTc+bM0X333adPP/3U3qUBAAAAAHBTBfo93VevXlVMTIxGjBhhbXNwcFBwcLC2bNmS5TppaWlKS0uzLl+6dEmSdPHiRWVkZJhbcB4kJiYqPf26Th45oCvJSfYuB3l0If6k0tOvKzExURcvXrwj2+QYuntw/CCvOIaQVxxDyAuOH+SVPY6h25GYmChJMgzjpuMsxq1G2NHJkydVpkwZ/fLLLwoKCrK2Dx8+XBs3blRUVFSmdcaMGaOxY8feyTIBAAAAAPeoP/74Q2XLls22v0Cf6b4dI0aMUHh4uHU5IyND58+fV8mSJWWxWOxYGaS/fhsUEBCgP/74Q56envYuB4UMxw/yimMIecUxhLzg+EFecQwVLIZhKCkpSf7+/jcdV6BDd6lSpeTo6Kj4+Hib9vj4ePn5+WW5jrOzs5ydnW3aihUrZlaJuE2enp78HwVuG8cP8opjCHnFMYS84PhBXnEMFRxeXl63HFOgH6Tm5OSkhg0bKjIy0tqWkZGhyMhIm8vNAQAAAAAoiAr0mW5JCg8PV1hYmBo1aqQmTZpo2rRpSklJUf/+/e1dGgAAAAAAN1XgQ3evXr2UkJCgUaNG6fTp06pXr55Wr14tX19fe5eG2+Ds7KzRo0dnugUAyAmOH+QVxxDyimMIecHxg7ziGCqcCvTTywEAAAAAKMwK9D3dAAAAAAAUZoRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6MYdM3PmTFWoUEEuLi5q2rSpfv31V3uXhEJk06ZN6ty5s/z9/WWxWLRy5Up7l4RCZOLEiWrcuLE8PDzk4+Ojrl276sCBA/YuC4XE7NmzVadOHXl6esrT01NBQUH6/vvv7V0WCrFJkybJYrFo6NCh9i4FhcSYMWNksVhsfqpXr27vspBDhG7cEUuXLlV4eLhGjx6t7du3q27dugoJCdGZM2fsXRoKiZSUFNWtW1czZ860dykohDZu3KghQ4Zo69atWrduna5du6aHH35YKSkp9i4NhUDZsmU1adIkxcTEKDo6Wm3btlWXLl20Z88ee5eGQmjbtm2aO3eu6tSpY+9SUMjcf//9OnXqlPVn8+bN9i4JOcQrw3BHNG3aVI0bN9aMGTMkSRkZGQoICNCLL76o119/3c7VobCxWCxasWKFunbtau9SUEglJCTIx8dHGzduVMuWLe1dDgqhEiVK6N///reeeeYZe5eCQiQ5OVkNGjTQrFmzNH78eNWrV0/Tpk2zd1koBMaMGaOVK1dq586d9i4Ft4Ez3TDd1atXFRMTo+DgYGubg4ODgoODtWXLFjtWBuBedenSJUl/BScgN9LT0/X5558rJSVFQUFB9i4HhcyQIUPUsWNHm38TATl16NAh+fv7q2LFiurbt6/i4uLsXRJyqIi9C8Dd7+zZs0pPT5evr69Nu6+vr/bv32+nqgDcqzIyMjR06FA1a9ZMtWrVsnc5KCR27dqloKAgpaamyt3dXStWrFDNmjXtXRYKkc8//1zbt2/Xtm3b7F0KCqGmTZsqIiJC1apV06lTpzR27Fi1aNFCu3fvloeHh73Lwy0QugEA95QhQ4Zo9+7d3AuHXKlWrZp27typS5cuafny5QoLC9PGjRsJ3siRP/74Q//617+0bt06ubi42LscFELt27e3/rlOnTpq2rSpypcvry+++ILbXAoBQjdMV6pUKTk6Oio+Pt6mPT4+Xn5+fnaqCsC96IUXXtCqVau0adMmlS1b1t7loBBxcnJS5cqVJUkNGzbUtm3bNH36dM2dO9fOlaEwiImJ0ZkzZ9SgQQNrW3p6ujZt2qQZM2YoLS1Njo6OdqwQhU2xYsVUtWpVHT582N6lIAe4pxumc3JyUsOGDRUZGWlty8jIUGRkJPfDAbgjDMPQCy+8oBUrVmj9+vUKDAy0d0ko5DIyMpSWlmbvMlBItGvXTrt27dLOnTutP40aNVLfvn21c+dOAjdyLTk5WUeOHFHp0qXtXQpygDPduCPCw8MVFhamRo0aqUmTJpo2bZpSUlLUv39/e5eGQiI5Odnmt7mxsbHauXOnSpQooXLlytmxMhQGQ4YM0ZIlS/T111/Lw8NDp0+fliR5eXnJ1dXVztWhoBsxYoTat2+vcuXKKSkpSUuWLNGGDRu0Zs0ae5eGQsLDwyPTMyTc3NxUsmRJni2BHHnllVfUuXNnlS9fXidPntTo0aPl6OioPn362Ls05AChG3dEr169lJCQoFGjRun06dOqV6+eVq9enenhakB2oqOj1aZNG+tyeHi4JCksLEwRERF2qgqFxezZsyVJrVu3tmmfN2+e+vXrd+cLQqFy5swZhYaG6tSpU/Ly8lKdOnW0Zs0aPfTQQ/YuDcA94sSJE+rTp4/OnTsnb29vNW/eXFu3bpW3t7e9S0MO8J5uAAAAAABMwj3dAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAADuqKioKE2fPl2GYdi7FAAATEfoBgAgCxERESpWrFi+ztm6dWsNHTo0V+uMGTNG9erVy9c67OnEiRPq2bOn6tevL4vFctvzREZGqkaNGkpPT8/H6jI7e/asfHx8dOLECVO3AwC4exG6AQD3lH79+slisWjSpEk27StXrrQJgb169dLBgwfvdHmmSEhI0KBBg1SuXDk5OzvLz89PISEh+vnnn+9oHVevXlXPnj01ZcoUtWzZMk9zDR8+XG+99ZYcHR2tbRs2bFCDBg3k7OysypUrKyIi4pbz3Dge/v7zyCOPWPtLlSql0NBQjR49Ok/1AgDuXUXsXQAAAHeai4uL3n33XT333HMqXrx4lmNcXV3l6up6hyszR48ePXT16lXNnz9fFStWVHx8vCIjI3Xu3Lk7WoeTk5N++eWXPM+zefNmHTlyRD169LC2xcbGqmPHjnr++ee1ePFiRUZGasCAASpdurRCQkJuOt8jjzyiefPmWZednZ1t+vv376+GDRvq3//+t0qUKJHn+gEA9xbOdAMA7jnBwcHy8/PTxIkTsx3z98vLDx48KIvFov3799uMef/991WpUiXr8u7du9W+fXu5u7vL19dXTz31lM6ePZur2iZNmiRfX195eHjomWeeUWpqaqYx//nPf1SjRg25uLioevXqmjVrVrbzXbx4UT/99JPeffddtWnTRuXLl1eTJk00YsQIPfroozbjBgwYIG9vb3l6eqpt27b67bffblrb66+/bnPpe1aXz3ft2lX9+vWzLleoUEHTpk2zLk+dOlW1a9eWm5ubAgICNHjwYCUnJ9/0M/r888/10EMPycXFxdo2Z84cBQYGasqUKapRo4ZeeOEFPfbYY3r//fdvOpck69n/Gz///EXM/fffL39/f61YseKWcwEA8E+EbgDAPcfR0VETJkzQhx9+mKN7datWrapGjRpp8eLFNu2LFy/WE088Iemv0Nq2bVvVr19f0dHRWr16teLj49WzZ88c1/XFF19ozJgxmjBhgqKjo1W6dOlMgXrx4sUaNWqU3nnnHe3bt08TJkzQyJEjNX/+/CzndHd3l7u7u1auXKm0tLRst/3444/rzJkz+v777xUTE6MGDRqoXbt2On/+fI5rux0ODg764IMPtGfPHs2fP1/r16/X8OHDb7rOTz/9pEaNGtm0bdmyRcHBwTZtISEh2rJlyy1r2LBhg3x8fFStWjUNGjQoyysAmjRpop9++ikHewQAgC1CNwDgntStWzfVq1cvx/fq9u3bV5999pl1+eDBg4qJiVHfvn0lSTNmzFD9+vU1YcIEVa9eXfXr19enn36qH3/8Mcf3hk+bNk3PPPOMnnnmGVWrVk3jx49XzZo1bcaMHj1aU6ZMUffu3RUYGKju3btr2LBhmjt3bpZzFilSRBEREZo/f76KFSumZs2a6Y033tDvv/9uHbN582b9+uuvWrZsmRo1aqQqVarovffeU7FixbR8+fIc13Y7hg4dqjZt2qhChQpq27atxo8fry+++OKm6xw/flz+/v42badPn5avr69Nm6+vrxITE3XlypVs53rkkUe0YMECRUZG6t1339XGjRvVvn37TA9o8/f31/Hjx3O5dwAAELoBAPewd999V/Pnz9e+fftuObZ37946duyYtm7dKumvM84NGjRQ9erVJUm//fabfvzxR+uZZXd3d2vfkSNHclTPvn371LRpU5u2oKAg659TUlJ05MgRPfPMMzbbGT9+/E230aNHD508eVLffPONHnnkEesDx248aOy3335TcnKySpYsaTNvbGysdd5b1Xa7fvjhB7Vr105lypSRh4eHnnrqKZ07d06XL1/Odp0rV67YXFqeE4sXL7bZtxtnrXv37q1HH31UtWvXVteuXbVq1Spt27ZNGzZssFnf1dX1pjUBAJAdHqQGALhntWzZUiEhIRoxYoTNfcdZ8fPzU9u2bbVkyRI98MADWrJkiQYNGmTtT05OVufOnfXuu+9mWrd06dL5Uu+Ne50//vjjTAH470/xzoqLi4seeughPfTQQxo5cqQGDBig0aNHq1+/fkpOTlbp0qUzBU1JuXptmoODQ6Z3b1+7di3b8ceOHVOnTp00aNAgvfPOOypRooQ2b96sZ555RlevXtV9992X5XqlSpXShQsXbNr8/PwUHx9v0xYfHy9PT0+5urrq0UcftfnMypQpk+XcFStWVKlSpXT48GG1a9fO2n7+/Hl5e3tnuy8AAGSH0A0AuKdNmjRJ9erVU7Vq1W45tm/fvho+fLj69Omjo0ePqnfv3ta+Bg0a6Msvv1SFChVUpMjt/ee1Ro0aioqKUmhoqLXtxpl16a/Lpf39/XX06FHrZe23q2bNmlq5cqW19tOnT6tIkSKqUKHCbdUmSd7e3jp16pR1OT09Xbt371abNm2ynDMmJkYZGRmaMmWKHBz+uvjuVpeWS1L9+vW1d+9em7agoCD997//tWlbt26d9Wy8h4eHPDw8bjn3iRMndO7cuUy/KNm9e7dat259y/UBAPgnLi8HANzTateurb59++qDDz645dju3bsrKSlJgwYNUps2bWzuKx4yZIjOnz+vPn36aNu2bTpy5IjWrFmj/v37Z7o/ODv/+te/9Omnn2revHk6ePCgRo8erT179tiMGTt2rCZOnKgPPvhABw8e1K5duzRv3jxNnTo1yznPnTuntm3batGiRfr9998VGxurZcuWafLkyerSpYukv57mHhQUpK5du2rt2rU6duyYfvnlF7355puKjo7OcW1t27bVd999p++++0779+/XoEGDdPHixWz3t3Llyrp27Zo+/PBDHT16VAsXLtScOXNu+TmFhIRo8+bNNm3PP/+8jh49quHDh2v//v2aNWuWvvjiCw0bNizbeZKTk/Xqq69q69atOnbsmCIjI9WlSxdVrlzZ5jVjly9fVkxMjB5++OFb1gYAwD8RugEA97xx48YpIyPjluM8PDzUuXNn/fbbb5nONPv7++vnn39Wenq6Hn74YdWuXVtDhw5VsWLFrGdxb6VXr14aOXKkhg8froYNG+r48eM2l7BL0oABA/Sf//xH8+bNU+3atdWqVStFREQoMDAwyznd3d3VtGlTvf/++2rZsqVq1aqlkSNH6tlnn9WMGTMkSRaLRf/973/VsmVL9e/fX1WrVlXv3r11/Phx68PJclLb008/rbCwMIWGhqpVq1aqWLFitme5Jalu3bqaOnWq3n33XdWqVUuLFy++6Wvcbujbt6/27NmjAwcOWNsCAwP13Xffad26dapbt66mTJmi//znPzd9R7ejo6N+//13Pfroo6pataqeeeYZNWzYUD/99JPNu7q//vprlStXTi1atLhlbQAA/JPF+OfNVwAAADkwZswYrVy5Ujt37rzj23711VeVmJiY7VPb89MDDzygl156yfp6OAAAcoMz3QAAoNB58803Vb58+RxdoZAXZ8+eVffu3dWnTx9TtwMAuHtxphsAANwWe57pBgCgsCB0AwAAAABgEi4vBwAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAk/wdOrcY5RM9dUwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_importance_kfold(X_train, y_train, params, n_splits=5, plot=True):\n",
        "    \"\"\"\n",
        "    Calcula la importancia promedio de features usando k-fold\n",
        "    \"\"\"\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    feature_importance_list = []\n",
        "\n",
        "    print(\"Calculando importancia de features con k-fold...\")\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
        "        X_fold_train = X_train.iloc[train_idx]\n",
        "        y_fold_train = y_train.iloc[train_idx]\n",
        "        X_fold_val = X_train.iloc[val_idx]\n",
        "        y_fold_val = y_train.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_fold_train, label=y_fold_train)\n",
        "        dvalid = lgb.Dataset(X_fold_val, label=y_fold_val, reference=dtrain)\n",
        "\n",
        "        bst = lgb.train(\n",
        "            params,\n",
        "            dtrain,\n",
        "            num_boost_round=1000,\n",
        "            valid_sets=[dvalid],\n",
        "            callbacks=[\n",
        "                lgb.early_stopping(stopping_rounds=50),\n",
        "                lgb.log_evaluation(period=0)  # Sin output\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Obtener importancia (gain es más robusto que split)\n",
        "        importance = bst.feature_importance(importance_type='gain')\n",
        "        feature_importance_list.append(importance)\n",
        "\n",
        "    # Promediar importancia entre folds\n",
        "    avg_importance = np.mean(feature_importance_list, axis=0)\n",
        "    std_importance = np.std(feature_importance_list, axis=0)\n",
        "\n",
        "     # Crear DataFrame\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': X_train.columns,\n",
        "        'importance': avg_importance,\n",
        "        'std': std_importance\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    if plot:\n",
        "        plt.figure(figsize=(10, max(6, len(X_train.columns) * 0.3)))\n",
        "        plt.barh(importance_df['feature'], importance_df['importance'])\n",
        "        plt.xlabel('Importancia (Gain)')\n",
        "        plt.title('Importancia de características - LightGBM')\n",
        "        plt.gca().invert_yaxis()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return importance_df"
      ],
      "metadata": {
        "id": "xYbKb4YMvQOJ"
      },
      "id": "xYbKb4YMvQOJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_with_without_features(X_train, y_train, params, importance_df,\n",
        "                                   threshold_percentile=20, n_splits=5):\n",
        "    \"\"\"\n",
        "    Compara el rendimiento del modelo con todas las features vs sin las de baja importancia\n",
        "    \"\"\"\n",
        "\n",
        "    # Identificar features de baja importancia\n",
        "    threshold = np.percentile(importance_df['importance'], threshold_percentile)\n",
        "    low_importance_features = importance_df[importance_df['importance'] <= threshold]['feature'].tolist()\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Features a eliminar (percentil {threshold_percentile}, importancia <= {threshold:.2f}):\")\n",
        "    print(f\"{'='*70}\")\n",
        "    for feat in low_importance_features:\n",
        "        imp = importance_df[importance_df['feature'] == feat]['importance'].values[0]\n",
        "        print(f\"  - {feat}: {imp:.4f}\")\n",
        "    print(f\"\\nTotal: {len(low_importance_features)} features de {len(X_train.columns)}\")\n",
        "\n",
        "    # Dataset sin features de baja importancia\n",
        "    X_train_reduced = X_train.drop(columns=low_importance_features)\n",
        "\n",
        "    # Entrenar ambos modelos con k-fold\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"MODELO CON TODAS LAS FEATURES\")\n",
        "    print(f\"{'='*70}\")\n",
        "    results_full = train_kfold(X_train, y_train, params, n_splits)\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"MODELO SIN FEATURES DE BAJA IMPORTANCIA\")\n",
        "    print(f\"{'='*70}\")\n",
        "    results_reduced = train_kfold(X_train_reduced, y_train, params, n_splits)\n",
        "\n",
        "    # Comparación\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"COMPARACIÓN DE RESULTADOS\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"{'Modelo':<30} {'MAE':>12} {'R²':>12} {'# Features':>12}\")\n",
        "    print(f\"{'-'*70}\")\n",
        "    print(f\"{'Con todas las features':<30} {results_full['mae_mean']:>12.4f} {results_full['r2_mean']:>12.4f} {len(X_train.columns):>12}\")\n",
        "    print(f\"{'Sin features baja import.':<30} {results_reduced['mae_mean']:>12.4f} {results_reduced['r2_mean']:>12.4f} {len(X_train_reduced.columns):>12}\")\n",
        "    print(f\"{'-'*70}\")\n",
        "\n",
        "    mae_diff = results_reduced['mae_mean'] - results_full['mae_mean']\n",
        "    r2_diff = results_reduced['r2_mean'] - results_full['r2_mean']\n",
        "\n",
        "    print(f\"{'Diferencia':<30} {mae_diff:>12.4f} {r2_diff:>12.4f}\")\n",
        "\n",
        "    # Recomendación\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"RECOMENDACIÓN\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    if abs(mae_diff) < 0.01 and abs(r2_diff) < 0.01:\n",
        "        print(\"✓ Las diferencias son mínimas (<1%). Puedes eliminar las features.\")\n",
        "        print(\"  Ventajas: Modelo más simple, menor tiempo de entrenamiento.\")\n",
        "        recommendation = \"reduce\"\n",
        "    elif mae_diff > 0:\n",
        "        print(\"✗ El modelo sin features tiene PEOR rendimiento.\")\n",
        "        print(f\"  MAE aumentó en {mae_diff:.4f}. NO se recomienda eliminar features.\")\n",
        "        recommendation = \"keep_all\"\n",
        "    else:\n",
        "        print(\"✓✓ ¡El modelo sin features es MEJOR! Elimina las features de baja importancia.\")\n",
        "        recommendation = \"reduce\"\n",
        "\n",
        "    return {\n",
        "        'low_importance_features': low_importance_features,\n",
        "        'X_train_reduced': X_train_reduced,\n",
        "        'results_full': results_full,\n",
        "        'results_reduced': results_reduced,\n",
        "        'recommendation': recommendation\n",
        "    }\n"
      ],
      "metadata": {
        "id": "OUoziNPsvbSB"
      },
      "id": "OUoziNPsvbSB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_kfold(X, y, params, n_splits=5):\n",
        "    \"\"\"Entrena modelo con k-fold y retorna métricas\"\"\"\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    mae_scores = []\n",
        "    r2_scores = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
        "        X_fold_train = X.iloc[train_idx]\n",
        "        y_fold_train = y.iloc[train_idx]\n",
        "        X_fold_val = X.iloc[val_idx]\n",
        "        y_fold_val = y.iloc[val_idx]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_fold_train, label=y_fold_train)\n",
        "        dvalid = lgb.Dataset(X_fold_val, label=y_fold_val, reference=dtrain)\n",
        "\n",
        "        bst = lgb.train(\n",
        "            params,\n",
        "            dtrain,\n",
        "            num_boost_round=5000,\n",
        "            valid_sets=[dvalid],\n",
        "            callbacks=[\n",
        "                lgb.early_stopping(stopping_rounds=100),\n",
        "                lgb.log_evaluation(period=0)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        y_pred = bst.predict(X_fold_val, num_iteration=bst.best_iteration)\n",
        "        mae = mean_absolute_error(y_fold_val, y_pred)\n",
        "        r2 = r2_score(y_fold_val, y_pred)\n",
        "\n",
        "        mae_scores.append(mae)\n",
        "        r2_scores.append(r2)\n",
        "\n",
        "        print(f\"Fold {fold}: MAE={mae:.4f}, R²={r2:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'mae_mean': np.mean(mae_scores),\n",
        "        'mae_std': np.std(mae_scores),\n",
        "        'r2_mean': np.mean(r2_scores),\n",
        "        'r2_std': np.std(r2_scores)\n",
        "    }"
      ],
      "metadata": {
        "id": "nRF_4h6Svh22"
      },
      "id": "nRF_4h6Svh22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVBKkXycvlT5"
      },
      "id": "yVBKkXycvlT5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eKhrm75N7Vnq",
      "metadata": {
        "id": "eKhrm75N7Vnq"
      },
      "outputs": [],
      "source": [
        "# rf_fast = RandomForestRegressor(\n",
        "#     n_estimators=100,\n",
        "#     min_samples_leaf=5,\n",
        "#     max_features='sqrt',\n",
        "#     n_jobs=-1,\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "# rf_fast.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uDi4iBloB-MT",
      "metadata": {
        "id": "uDi4iBloB-MT"
      },
      "outputs": [],
      "source": [
        "# importance_df = pd.DataFrame({\n",
        "#     'cols': X_train.columns,\n",
        "#     'imp': rf_fast.feature_importances_\n",
        "# }).sort_values('imp', ascending=False)\n",
        "\n",
        "# plt.figure(figsize=(10, 8))\n",
        "# importance_df.plot('cols', 'imp', 'barh', legend=False)\n",
        "# plt.title('Importancia de características con objetivo- Random Forest')\n",
        "# plt.xlabel('Importancia')\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WAmUhj48ugPO",
      "metadata": {
        "id": "WAmUhj48ugPO"
      },
      "outputs": [],
      "source": [
        "# importance_df = pd.DataFrame({\n",
        "#     'feature': X_train.columns,\n",
        "#     'importance': rf.feature_importances_\n",
        "# }).sort_values('importance', ascending=False)\n",
        "\n",
        "# # Mostrar distribución de importancia\n",
        "# print(\"Distribución de importancia:\")\n",
        "# print(importance_df['importance'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7rhJfwgku4j3",
      "metadata": {
        "id": "7rhJfwgku4j3"
      },
      "outputs": [],
      "source": [
        "# threshold_percentile = 0.95  # Mantener top 5% más importante\n",
        "# threshold_value = importance_df['importance'].quantile(threshold_percentile)\n",
        "\n",
        "# selected_features = importance_df[importance_df['importance'] >= threshold_value]['feature'].tolist()\n",
        "\n",
        "# print(f\"\\n🔧 FILTRANDO CARACTERÍSTICAS:\")\n",
        "# print(f\"Total original: {len(importance_df)} características\")\n",
        "# print(f\"Seleccionadas: {len(selected_features)} características\")\n",
        "# print(f\"Umbral de importancia: {threshold_value:.4f}\")\n",
        "\n",
        "# # Filtrar datasets\n",
        "# X_train_filtered = X_train[selected_features]\n",
        "# X_val_filtered = X_val[selected_features]\n",
        "\n",
        "# print(f\"\\nCaracterísticas eliminadas: {len(importance_df) - len(selected_features)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4e2e129",
      "metadata": {
        "id": "c4e2e129",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89db2a2-9dae-4d59-ad86-85d4ec2249e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos listos: 2,759,904 ejemplos, 22 características\n"
          ]
        }
      ],
      "source": [
        "if y_train is not None and not X_train.empty:\n",
        "    print(f\"Datos listos: {X_train.shape[0]:,} ejemplos, {X_train.shape[1]} características\")\n",
        "else:\n",
        "    print(\"Problema con los datos\")\n",
        "    if not train_data.empty:\n",
        "        print(\"Columnas disponibles:\", train_data.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Función para matriz de confusión\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# def plot_confusion_from_preds(y_true_list, y_pred_list, method='auto', threshold=None, bins=None,\n",
        "#                               normalize=False, show_custom_plot=True, save_path=None):\n",
        "\n",
        "#     import pandas as pd\n",
        "#     y_true = np.array(y_true_list).ravel()\n",
        "#     y_pred = np.array(y_pred_list).ravel()\n",
        "#     if len(y_true) != len(y_pred):\n",
        "#         raise ValueError(\"y_true y y_pred deben tener la misma longitud\")\n",
        "\n",
        "#     if bins is not None:\n",
        "#         y_true_bin = pd.cut(y_true, bins=bins, labels=False)\n",
        "#         y_pred_bin = pd.cut(y_pred, bins=bins, labels=False)\n",
        "#         labels = np.unique(np.concatenate([y_true_bin, y_pred_bin]))\n",
        "#     else:\n",
        "#         if threshold is None:\n",
        "#             if set(np.unique(y_true)).issubset({0,1}):\n",
        "#                 threshold = 0.5\n",
        "#             else:\n",
        "#                 threshold = np.median(y_true)\n",
        "#         y_true_bin = (y_true >= threshold).astype(int)\n",
        "#         y_pred_bin = (y_pred >= threshold).astype(int)\n",
        "#         labels = np.array([0,1])\n",
        "\n",
        "#     # Matrices\n",
        "#     cm_norm = confusion_matrix(y_true_bin, y_pred_bin, labels=labels, normalize='pred' if normalize else None)\n",
        "#     cm_raw = confusion_matrix(y_true_bin, y_pred_bin, labels=labels, normalize=None)\n",
        "\n",
        "#     # Reporte\n",
        "#     print(f\"Muestras: {len(y_true)} -- Método: {method} -- threshold: {threshold}\")\n",
        "#     try:\n",
        "#         print(\"\\nClassification report (sobre clases discretizadas):\\n\")\n",
        "#         print(classification_report(y_true_bin, y_pred_bin, zero_division=0))\n",
        "#     except Exception as e:\n",
        "#         print(\"No se pudo generar classification_report:\", e)\n",
        "\n",
        "#     if len(labels) == 2:\n",
        "#         tn, fp, fn, tp = cm_raw.ravel()\n",
        "#         acc = accuracy_score(y_true_bin, y_pred_bin)\n",
        "#         prec = precision_score(y_true_bin, y_pred_bin, zero_division=0)\n",
        "#         rec = recall_score(y_true_bin, y_pred_bin, zero_division=0)\n",
        "#         f1 = f1_score(y_true_bin, y_pred_bin, zero_division=0)\n",
        "#         print(f\"TP={tp}, FP={fp}, FN={fn}, TN={tn}\")\n",
        "#         print(f\"Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
        "#     else:\n",
        "#         print(\"Multiclase detectado. Mostrar conteos por clase en la matriz.\")\n",
        "\n",
        "#     # Heatmap\n",
        "#     plt.figure(figsize=(6,5))\n",
        "#     target_cm = cm_norm if (normalize and cm_norm is not None) else cm_raw\n",
        "#     fmt = '.2f' if normalize else 'd'\n",
        "#     sns.heatmap(target_cm, annot=True, fmt=fmt, xticklabels=labels, yticklabels=labels, cmap='Blues')\n",
        "#     plt.xlabel('Predicción')\n",
        "#     plt.ylabel('Real')\n",
        "#     plt.title(f'Matriz de confusión ({len(y_true)} muestras)')\n",
        "#     if save_path:\n",
        "#         plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
        "#         print(f\"Figura guardada en: {save_path}\")\n",
        "#     plt.show()\n",
        "\n",
        "#     if show_custom_plot and len(labels) == 2:\n",
        "#         tn, fp, fn, tp = cm_raw.ravel()\n",
        "#         def plot_custom_2x2(tp, fp, fn, tn, title='Matriz de confusión personalizada'):\n",
        "#             mat = np.array([[tp, fp],[fn, tn]])\n",
        "#             colors = np.array([['#3a7a2e', '#d22b2b'], ['#d22b2b', '#3a7a2e']])\n",
        "#             fig, ax = plt.subplots(figsize=(6,6))\n",
        "#             for i in range(2):\n",
        "#                 for j in range(2):\n",
        "#                     ax.add_patch(plt.Rectangle((j, 1-i), 1, 1, color=colors[i,j], ec='navy', lw=1))\n",
        "#                     if i==0 and j==0:\n",
        "#                         text = f\"Verdaderos\\nPositivos\\n\\n{mat[i,j]}\"\n",
        "#                     elif i==0 and j==1:\n",
        "#                         text = f\"Falsos\\nPositivos\\n\\n{mat[i,j]}\"\n",
        "#                     elif i==1 and j==0:\n",
        "#                         text = f\"Falsos\\nNegativos\\n\\n{mat[i,j]}\"\n",
        "#                     else:\n",
        "#                         text = f\"Verdaderos\\nNegativos\\n\\n{mat[i,j]}\"\n",
        "#                     ax.text(j+0.5, 1-i+0.5, text, ha='center', va='center', color='white', fontsize=14)\n",
        "#             ax.set_xlim(0,2); ax.set_ylim(0,2)\n",
        "#             ax.set_xticks([0.5, 1.5]); ax.set_xticklabels(['VALORES REALES\\nPositivo','VALORES REALES\\nNegativo'], fontsize=10)\n",
        "#             ax.set_yticks([1.5, 0.5]); ax.set_yticklabels(['VALORES PREDICCIÓN\\nPositivo','VALORES PREDICCIÓN\\nNegativo'], fontsize=10)\n",
        "#             ax.invert_yaxis()\n",
        "#             ax.set_title(title, pad=20)\n",
        "#             ax.axis('off')\n",
        "#             plt.show()\n",
        "#         plot_custom_2x2(tp=tp, fp=fp, fn=fn, tn=tn)\n",
        "\n",
        "#     return {'cm': cm_raw, 'cm_norm': cm_norm, 'labels': labels, 'y_true_bin': y_true_bin, 'y_pred_bin': y_pred_bin}\n",
        "\n",
        "# # Ejecución automática si detecta listas globales con nombres comunes\n",
        "# try:\n",
        "#     if 'all_y_true' in globals() and 'all_y_pred' in globals():\n",
        "#         print(\"Ejecutando plot_confusion_from_preds con all_y_true / all_y_pred del notebook...\")\n",
        "#         _ = plot_confusion_from_preds(all_y_true, all_y_pred, method='auto', threshold=None, bins=None, normalize=False, show_custom_plot=True)\n",
        "#     else:\n",
        "#         print(\"No se detectaron all_y_true/all_y_pred en globals(). Llama a plot_confusion_from_preds manualmente.\")\n",
        "# except Exception as e:\n",
        "#     print(\"Error al ejecutar la función automáticamente:\", e)\n"
      ],
      "metadata": {
        "id": "tlhDdV-KlhWq"
      },
      "id": "tlhDdV-KlhWq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zdWimo9okSFw",
      "metadata": {
        "id": "zdWimo9okSFw"
      },
      "outputs": [],
      "source": [
        "# print(unique_values)\n",
        "# print(y_train_full)\n",
        "# print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Entrenamiento de modelo LightGBM\n",
        "\n",
        "# # X_sub, X_val_sub, y_sub, y_val_sub = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# # dtrain = lgb.Dataset(X_sub, label=y_sub)\n",
        "# # dvalid = lgb.Dataset(X_val_sub, label=y_val_sub, reference=dtrain)\n",
        "\n",
        "# kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# params = {\n",
        "#     'objective': 'regression',\n",
        "#     'metric': 'mae',\n",
        "#     'boosting_type': 'gbdt',\n",
        "#     'learning_rate': 0.03,\n",
        "#     'num_leaves': 127,\n",
        "#     'max_depth': -1,\n",
        "#     'feature_fraction': 0.8,\n",
        "#     'bagging_fraction': 0.8,\n",
        "#     'bagging_freq': 5,\n",
        "#     'min_data_in_leaf': 50,\n",
        "#     'lambda_l1': 0.0,\n",
        "#     'lambda_l2': 1.0,\n",
        "#     'verbose': -1\n",
        "#     # 'objective':'regression',\n",
        "#     # 'metric':'mae',\n",
        "#     # 'learning_rate': 0.03,\n",
        "#     # 'num_leaves': 127,\n",
        "#     # 'max_depth': 12,\n",
        "#     # 'min_data_in_leaf': 50,\n",
        "#     # 'feature_fraction': 0.8,\n",
        "#     # 'bagging_fraction': 0.8,\n",
        "#     # 'verbose': -1\n",
        "\n",
        "# }\n",
        "# # dtrain_full = lgb.Dataset(X_train, label=y_train)\n",
        "\n",
        "# # params = {\n",
        "# #     'objective': 'regression',\n",
        "# #     'metric': 'l1',\n",
        "# #     'learning_rate': 0.01,\n",
        "# #     'num_leaves': 127,\n",
        "# #     'feature_fraction': 0.8,\n",
        "# #     'bagging_fraction': 0.8,\n",
        "# #     'bagging_freq': 5,\n",
        "# #     'min_data_in_leaf': 50,\n",
        "# #     'lambda_l2': 1.0,\n",
        "# #     'verbose': -1\n",
        "# # }\n",
        "# # bst_full = lgb.train(params, dtrain_full, num_boost_round=5000,\n",
        "# #                      callbacks=[lgb.early_stopping(200)])\n",
        "# # pred_full = bst_full.predict(X_test, num_iteration=bst_full.best_iteration)\n",
        "# # pred_full_clip = np.clip(pred_full, 0.0, 5.0)\n",
        "\n",
        "# # bst = lgb.train(\n",
        "# #     params,\n",
        "# #     dtrain,\n",
        "# #     num_boost_round=5000,\n",
        "# #     valid_sets=[dtrain, dvalid],\n",
        "# #     valid_names=['train','valid'],\n",
        "# #     callbacks=[\n",
        "# #         lgb.early_stopping(stopping_rounds=100),\n",
        "# #         lgb.log_evaluation(period=100)\n",
        "# #     ]\n",
        "# # )\n",
        "\n",
        "# # y_pred = bst.predict(X_val_sub, num_iteration=bst.best_iteration)\n",
        "# # print(\"MAE\", mean_absolute_error(y_val_sub, y_pred), \"R2\", r2_score(y_val_sub, y_pred))\n"
      ],
      "metadata": {
        "id": "iso0OAqtVOpm",
        "collapsed": true
      },
      "id": "iso0OAqtVOpm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'mae',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'learning_rate': 0.03,\n",
        "    'num_leaves': 127,\n",
        "    'max_depth': -1,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'min_data_in_leaf': 50,\n",
        "    'lambda_l1': 0.0,\n",
        "    'lambda_l2': 1.0,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "# 1. Calcular importancia\n",
        "importance_df = get_feature_importance_kfold(X_train, y_train, params, n_splits=5, plot=True)\n",
        "\n",
        "# 2. Comparar modelos (prueba con diferentes thresholds: 10, 20, 30)\n",
        "comparison = compare_with_without_features(\n",
        "    X_train, y_train, params, importance_df,\n",
        "    threshold_percentile=20,  # Elimina el 20% menos importante\n",
        "    n_splits=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8NP1dMkqvvvt",
        "outputId": "34202778-2325-4abc-c7c0-daea840a41fb"
      },
      "id": "8NP1dMkqvvvt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando importancia de features con k-fold...\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's l1: 0.467238\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's l1: 0.468122\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's l1: 0.467771\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's l1: 0.465221\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's l1: 0.465971\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x660 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Features a eliminar (percentil 20, importancia <= 272386.72):\n",
            "======================================================================\n",
            "  - WS50M_RANGE: 266801.2721\n",
            "  - WS50M: 216173.6284\n",
            "  - T2M: 191151.7175\n",
            "  - WS50M_MIN: 92469.4589\n",
            "  - WS10M_MIN: 82249.3797\n",
            "\n",
            "Total: 5 features de 22\n",
            "\n",
            "======================================================================\n",
            "MODELO CON TODAS LAS FEATURES\n",
            "======================================================================\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's l1: 0.364401\n",
            "Fold 1: MAE=0.3644, R²=0.8233\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's l1: 0.363132\n",
            "Fold 2: MAE=0.3631, R²=0.8242\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's l1: 0.364339\n",
            "Fold 3: MAE=0.3643, R²=0.8244\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's l1: 0.36421\n",
            "Fold 4: MAE=0.3642, R²=0.8244\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's l1: 0.364418\n",
            "Fold 5: MAE=0.3644, R²=0.8233\n",
            "\n",
            "======================================================================\n",
            "MODELO SIN FEATURES DE BAJA IMPORTANCIA\n",
            "======================================================================\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's l1: 0.361638\n",
            "Fold 1: MAE=0.3616, R²=0.8251\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's l1: 0.361244\n",
            "Fold 2: MAE=0.3612, R²=0.8255\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's l1: 0.360792\n",
            "Fold 3: MAE=0.3608, R²=0.8266\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's l1: 0.362215\n",
            "Fold 4: MAE=0.3622, R²=0.8257\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's l1: 0.360405\n",
            "Fold 5: MAE=0.3604, R²=0.8261\n",
            "\n",
            "======================================================================\n",
            "COMPARACIÓN DE RESULTADOS\n",
            "======================================================================\n",
            "Modelo                                  MAE           R²   # Features\n",
            "----------------------------------------------------------------------\n",
            "Con todas las features               0.3641       0.8239           22\n",
            "Sin features baja import.            0.3613       0.8258           17\n",
            "----------------------------------------------------------------------\n",
            "Diferencia                          -0.0028       0.0019\n",
            "\n",
            "======================================================================\n",
            "RECOMENDACIÓN\n",
            "======================================================================\n",
            "✓ Las diferencias son mínimas (<1%). Puedes eliminar las features.\n",
            "  Ventajas: Modelo más simple, menor tiempo de entrenamiento.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  print(\"\\n✓ Usa X_train_final y X_test_final para tu modelo final\")\n",
        "# else:\n",
        "#     print(\"\\n✓ Mantén todas las features (X_train y X_test originales)\")\n",
        "#     X_train_final = X_train\n",
        "#     X_test_final = X_test\n",
        "\n",
        "# # Guardar importancia en CSV\n",
        "# importance_df.to_csv('feature_importance_lgbm.csv', index=False)\n",
        "# print(\"\\n✓ Importancia guardada en 'feature_importance_lgbm.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "cNk7oMxev5kU",
        "outputId": "dc5b1485-8b01-45ef-d4bf-fdf7e99e8688"
      },
      "id": "cNk7oMxev5kU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-3970099576.py, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3970099576.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# models = []\n",
        "# mae_scores = []\n",
        "# r2_scores = []\n",
        "# oof_predictions = np.zeros(len(X_train))"
      ],
      "metadata": {
        "id": "dooX7MNXu5ee"
      },
      "id": "dooX7MNXu5ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "models = []\n",
        "mae_scores = []\n",
        "r2_scores = []\n",
        "oof_predictions = np.zeros(len(X_train))"
      ],
      "metadata": {
        "id": "5MHqabwRwa4s"
      },
      "id": "5MHqabwRwa4s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"Iniciando entrenamiento con {k_folds}-Fold Cross-Validation\\n\")\n",
        "\n",
        "# # Iteración sobre cada fold\n",
        "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
        "#     print(f\"{'='*60}\")\n",
        "#     print(f\"Fold {fold}/{k_folds}\")\n",
        "#     print(f\"{'='*60}\")\n",
        "\n",
        "#     # Dividir datos\n",
        "#     X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "#     y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "#     # Crear datasets de LightGBM\n",
        "#     dtrain = lgb.Dataset(X_fold_train, label=y_fold_train)\n",
        "#     dvalid = lgb.Dataset(X_fold_val, label=y_fold_val, reference=dtrain)\n",
        "\n",
        "#     # Entrenar modelo\n",
        "#     bst = lgb.train(\n",
        "#         params,\n",
        "#         dtrain,\n",
        "#         num_boost_round=5000,\n",
        "#         valid_sets=[dtrain, dvalid],\n",
        "#         valid_names=['train', 'valid'],\n",
        "#         callbacks=[\n",
        "#             lgb.early_stopping(stopping_rounds=100),\n",
        "#             lgb.log_evaluation(period=100)\n",
        "#         ]\n",
        "#     )\n",
        "\n",
        "#     # Predicciones en validación\n",
        "#     y_pred = bst.predict(X_fold_val, num_iteration=bst.best_iteration)\n",
        "\n",
        "#     # Guardar predicciones out-of-fold\n",
        "#     oof_predictions[val_idx] = y_pred\n",
        "\n",
        "#     # Calcular métricas\n",
        "#     mae = mean_absolute_error(y_fold_val, y_pred)\n",
        "#     r2 = r2_score(y_fold_val, y_pred)\n",
        "\n",
        "#     mae_scores.append(mae)\n",
        "#     r2_scores.append(r2)\n",
        "#     models.append(bst)\n",
        "\n",
        "#     print(f\"\\nFold {fold} - MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
        "#     print(f\"Best iteration: {bst.best_iteration}\\n\")\n"
      ],
      "metadata": {
        "id": "HZ9MMg7Lu8tw",
        "collapsed": true
      },
      "id": "HZ9MMg7Lu8tw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "models_full = []\n",
        "mae_scores_full = []\n",
        "r2_scores_full = []\n",
        "oof_predictions_full = np.zeros(len(X_train))\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Fold {fold}/{k_folds}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    X_fold_train = X_train.iloc[train_idx]\n",
        "    y_fold_train = y_train.iloc[train_idx]\n",
        "    X_fold_val = X_train.iloc[val_idx]\n",
        "    y_fold_val = y_train.iloc[val_idx]\n",
        "\n",
        "    dtrain = lgb.Dataset(X_fold_train, label=y_fold_train)\n",
        "    dvalid = lgb.Dataset(X_fold_val, label=y_fold_val, reference=dtrain)\n",
        "\n",
        "    bst = lgb.train(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=5000,\n",
        "        valid_sets=[dtrain, dvalid],\n",
        "        valid_names=['train', 'valid'],\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping_rounds=100),\n",
        "            lgb.log_evaluation(period=100)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    y_pred = bst.predict(X_fold_val, num_iteration=bst.best_iteration)\n",
        "    oof_predictions_full[val_idx] = y_pred\n",
        "\n",
        "    mae = mean_absolute_error(y_fold_val, y_pred)\n",
        "    r2 = r2_score(y_fold_val, y_pred)\n",
        "\n",
        "    mae_scores_full.append(mae)\n",
        "    r2_scores_full.append(r2)\n",
        "    models_full.append(bst)\n",
        "\n",
        "    print(f\"\\nFold {fold} - MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
        "    print(f\"Best iteration: {bst.best_iteration}\\n\")\n",
        "\n",
        "# Métricas finales modelo completo\n",
        "oof_mae_full = mean_absolute_error(y_train, oof_predictions_full)\n",
        "oof_r2_full = r2_score(y_train, oof_predictions_full)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7WbmHXGy-OV",
        "outputId": "fc620b08-f0ba-4c44-c389-c4b0e481c937"
      },
      "id": "o7WbmHXGy-OV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Fold 1/2\n",
            "============================================================\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttrain's l1: 0.68497\tvalid's l1: 0.687231\n",
            "[200]\ttrain's l1: 0.599516\tvalid's l1: 0.603048\n",
            "[300]\ttrain's l1: 0.558084\tvalid's l1: 0.562585\n",
            "[400]\ttrain's l1: 0.530605\tvalid's l1: 0.536129\n",
            "[500]\ttrain's l1: 0.511538\tvalid's l1: 0.517986\n",
            "[600]\ttrain's l1: 0.495685\tvalid's l1: 0.503023\n",
            "[700]\ttrain's l1: 0.484406\tvalid's l1: 0.492688\n",
            "[800]\ttrain's l1: 0.473506\tvalid's l1: 0.482631\n",
            "[900]\ttrain's l1: 0.464794\tvalid's l1: 0.474809\n",
            "[1000]\ttrain's l1: 0.456499\tvalid's l1: 0.467351\n",
            "[1100]\ttrain's l1: 0.449195\tvalid's l1: 0.460869\n",
            "[1200]\ttrain's l1: 0.443306\tvalid's l1: 0.455817\n",
            "[1300]\ttrain's l1: 0.436968\tvalid's l1: 0.450255\n",
            "[1400]\ttrain's l1: 0.431331\tvalid's l1: 0.445401\n",
            "[1500]\ttrain's l1: 0.426911\tvalid's l1: 0.441765\n",
            "[1600]\ttrain's l1: 0.422001\tvalid's l1: 0.437619\n",
            "[1700]\ttrain's l1: 0.417356\tvalid's l1: 0.433728\n",
            "[1800]\ttrain's l1: 0.41272\tvalid's l1: 0.429816\n",
            "[1900]\ttrain's l1: 0.408315\tvalid's l1: 0.426146\n",
            "[2000]\ttrain's l1: 0.404445\tvalid's l1: 0.422974\n",
            "[2100]\ttrain's l1: 0.40045\tvalid's l1: 0.419688\n",
            "[2200]\ttrain's l1: 0.397054\tvalid's l1: 0.416987\n",
            "[2300]\ttrain's l1: 0.393965\tvalid's l1: 0.414592\n",
            "[2400]\ttrain's l1: 0.390675\tvalid's l1: 0.411967\n",
            "[2500]\ttrain's l1: 0.388354\tvalid's l1: 0.410333\n",
            "[2600]\ttrain's l1: 0.38528\tvalid's l1: 0.407936\n",
            "[2700]\ttrain's l1: 0.382305\tvalid's l1: 0.405642\n",
            "[2800]\ttrain's l1: 0.379744\tvalid's l1: 0.403747\n",
            "[2900]\ttrain's l1: 0.377007\tvalid's l1: 0.401685\n",
            "[3000]\ttrain's l1: 0.374637\tvalid's l1: 0.399995\n",
            "[3100]\ttrain's l1: 0.372193\tvalid's l1: 0.39819\n",
            "[3200]\ttrain's l1: 0.369541\tvalid's l1: 0.396184\n",
            "[3300]\ttrain's l1: 0.367007\tvalid's l1: 0.3943\n",
            "[3400]\ttrain's l1: 0.364414\tvalid's l1: 0.392325\n",
            "[3500]\ttrain's l1: 0.362192\tvalid's l1: 0.39072\n",
            "[3600]\ttrain's l1: 0.359773\tvalid's l1: 0.38889\n",
            "[3700]\ttrain's l1: 0.357375\tvalid's l1: 0.38708\n",
            "[3800]\ttrain's l1: 0.355252\tvalid's l1: 0.385574\n",
            "[3900]\ttrain's l1: 0.353426\tvalid's l1: 0.384328\n",
            "[4000]\ttrain's l1: 0.351721\tvalid's l1: 0.383238\n",
            "[4100]\ttrain's l1: 0.349711\tvalid's l1: 0.381818\n",
            "[4200]\ttrain's l1: 0.34765\tvalid's l1: 0.380345\n",
            "[4300]\ttrain's l1: 0.345876\tvalid's l1: 0.379155\n",
            "[4400]\ttrain's l1: 0.344175\tvalid's l1: 0.378043\n",
            "[4500]\ttrain's l1: 0.34223\tvalid's l1: 0.376691\n",
            "[4600]\ttrain's l1: 0.34065\tvalid's l1: 0.375686\n",
            "[4700]\ttrain's l1: 0.338717\tvalid's l1: 0.374311\n",
            "[4800]\ttrain's l1: 0.337062\tvalid's l1: 0.373215\n",
            "[4900]\ttrain's l1: 0.335397\tvalid's l1: 0.372139\n",
            "[5000]\ttrain's l1: 0.333741\tvalid's l1: 0.371028\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttrain's l1: 0.333741\tvalid's l1: 0.371028\n",
            "\n",
            "Fold 1 - MAE: 0.3710, R²: 0.8163\n",
            "Best iteration: 5000\n",
            "\n",
            "============================================================\n",
            "Fold 2/2\n",
            "============================================================\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttrain's l1: 0.685566\tvalid's l1: 0.687176\n",
            "[200]\ttrain's l1: 0.597499\tvalid's l1: 0.600489\n",
            "[300]\ttrain's l1: 0.558514\tvalid's l1: 0.562642\n",
            "[400]\ttrain's l1: 0.531982\tvalid's l1: 0.537207\n",
            "[500]\ttrain's l1: 0.512546\tvalid's l1: 0.518791\n",
            "[600]\ttrain's l1: 0.497421\tvalid's l1: 0.504593\n",
            "[700]\ttrain's l1: 0.485056\tvalid's l1: 0.493165\n",
            "[800]\ttrain's l1: 0.474241\tvalid's l1: 0.483235\n",
            "[900]\ttrain's l1: 0.465804\tvalid's l1: 0.475688\n",
            "[1000]\ttrain's l1: 0.457512\tvalid's l1: 0.468251\n",
            "[1100]\ttrain's l1: 0.45051\tvalid's l1: 0.462113\n",
            "[1200]\ttrain's l1: 0.444344\tvalid's l1: 0.456763\n",
            "[1300]\ttrain's l1: 0.438666\tvalid's l1: 0.451884\n",
            "[1400]\ttrain's l1: 0.432859\tvalid's l1: 0.446888\n",
            "[1500]\ttrain's l1: 0.427609\tvalid's l1: 0.442469\n",
            "[1600]\ttrain's l1: 0.422537\tvalid's l1: 0.438184\n",
            "[1700]\ttrain's l1: 0.417988\tvalid's l1: 0.434407\n",
            "[1800]\ttrain's l1: 0.413834\tvalid's l1: 0.431044\n",
            "[1900]\ttrain's l1: 0.408785\tvalid's l1: 0.426749\n",
            "[2000]\ttrain's l1: 0.405484\tvalid's l1: 0.424181\n",
            "[2100]\ttrain's l1: 0.401252\tvalid's l1: 0.420702\n",
            "[2200]\ttrain's l1: 0.397774\tvalid's l1: 0.417968\n",
            "[2300]\ttrain's l1: 0.394581\tvalid's l1: 0.415482\n",
            "[2400]\ttrain's l1: 0.391597\tvalid's l1: 0.413176\n",
            "[2500]\ttrain's l1: 0.388417\tvalid's l1: 0.410688\n",
            "[2600]\ttrain's l1: 0.385677\tvalid's l1: 0.408639\n",
            "[2700]\ttrain's l1: 0.38308\tvalid's l1: 0.406725\n",
            "[2800]\ttrain's l1: 0.380466\tvalid's l1: 0.404772\n",
            "[2900]\ttrain's l1: 0.377662\tvalid's l1: 0.402657\n",
            "[3000]\ttrain's l1: 0.375206\tvalid's l1: 0.400898\n",
            "[3100]\ttrain's l1: 0.372804\tvalid's l1: 0.399131\n",
            "[3200]\ttrain's l1: 0.370267\tvalid's l1: 0.397246\n",
            "[3300]\ttrain's l1: 0.368026\tvalid's l1: 0.395611\n",
            "[3400]\ttrain's l1: 0.365745\tvalid's l1: 0.393964\n",
            "[3500]\ttrain's l1: 0.363282\tvalid's l1: 0.392134\n",
            "[3600]\ttrain's l1: 0.360921\tvalid's l1: 0.39039\n",
            "[3700]\ttrain's l1: 0.358835\tvalid's l1: 0.388935\n",
            "[3800]\ttrain's l1: 0.356484\tvalid's l1: 0.387174\n",
            "[3900]\ttrain's l1: 0.354404\tvalid's l1: 0.385668\n",
            "[4000]\ttrain's l1: 0.352358\tvalid's l1: 0.384217\n",
            "[4100]\ttrain's l1: 0.350181\tvalid's l1: 0.382647\n",
            "[4200]\ttrain's l1: 0.348294\tvalid's l1: 0.381327\n",
            "[4300]\ttrain's l1: 0.346413\tvalid's l1: 0.380038\n",
            "[4400]\ttrain's l1: 0.344766\tvalid's l1: 0.378983\n",
            "[4500]\ttrain's l1: 0.342891\tvalid's l1: 0.377693\n",
            "[4600]\ttrain's l1: 0.341318\tvalid's l1: 0.376671\n",
            "[4700]\ttrain's l1: 0.339613\tvalid's l1: 0.375529\n",
            "[4800]\ttrain's l1: 0.337662\tvalid's l1: 0.374152\n",
            "[4900]\ttrain's l1: 0.336225\tvalid's l1: 0.373299\n",
            "[5000]\ttrain's l1: 0.334555\tvalid's l1: 0.372193\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttrain's l1: 0.334555\tvalid's l1: 0.372193\n",
            "\n",
            "Fold 2 - MAE: 0.3722, R²: 0.8157\n",
            "Best iteration: 5000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n{'='*70}\")\n",
        "print(\"IDENTIFICANDO FEATURES DE BAJA IMPORTANCIA\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "threshold_percentile = 20  # Elimina el 20% menos importante\n",
        "threshold = np.percentile(importance_df['importance'], threshold_percentile)\n",
        "low_importance = importance_df[importance_df['importance'] <= threshold]\n",
        "features_to_remove = low_importance['feature'].tolist()\n",
        "\n",
        "print(f\"Threshold (percentil {threshold_percentile}): {threshold:.4f}\")\n",
        "print(f\"\\nFeatures a eliminar:\")\n",
        "for feat in features_to_remove:\n",
        "    imp = importance_df[importance_df['feature'] == feat]['importance'].values[0]\n",
        "    print(f\"  - {feat}: {imp:.4f}\")\n",
        "print(f\"\\nTotal: {len(features_to_remove)} de {len(X_train.columns)} features\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc9PNTJIzTe-",
        "outputId": "94d3456d-5519-4776-bbbe-2bfc51823699"
      },
      "id": "Qc9PNTJIzTe-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "IDENTIFICANDO FEATURES DE BAJA IMPORTANCIA\n",
            "======================================================================\n",
            "Threshold (percentil 20): 272386.7212\n",
            "\n",
            "Features a eliminar:\n",
            "  - WS50M_RANGE: 266801.2721\n",
            "  - WS50M: 216173.6284\n",
            "  - T2M: 191151.7175\n",
            "  - WS50M_MIN: 92469.4589\n",
            "  - WS10M_MIN: 82249.3797\n",
            "\n",
            "Total: 5 de 22 features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ENTRENAMIENTO K-FOLD - MODELO COMPLETO\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Features: {X_train.shape[1]}\")\n",
        "print(f\"Samples: {X_train.shape[0]}\\n\")\n",
        "\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "models_full = []\n",
        "mae_scores_full = []\n",
        "r2_scores_full = []\n",
        "oof_predictions_full = np.zeros(len(X_train))\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Fold {fold}/{n_splits}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    X_fold_train = X_train.iloc[train_idx]\n",
        "    y_fold_train = y_train.iloc[train_idx]\n",
        "    X_fold_val = X_train.iloc[val_idx]\n",
        "    y_fold_val = y_train.iloc[val_idx]\n",
        "\n",
        "    dtrain = lgb.Dataset(X_fold_train, label=y_fold_train)\n",
        "    dvalid = lgb.Dataset(X_fold_val, label=y_fold_val, reference=dtrain)\n",
        "\n",
        "    bst = lgb.train(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=5000,\n",
        "        valid_sets=[dtrain, dvalid],\n",
        "        valid_names=['train', 'valid'],\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping_rounds=100),\n",
        "            lgb.log_evaluation(period=100)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    y_pred = bst.predict(X_fold_val, num_iteration=bst.best_iteration)\n",
        "    oof_predictions_full[val_idx] = y_pred\n",
        "\n",
        "    mae = mean_absolute_error(y_fold_val, y_pred)\n",
        "    r2 = r2_score(y_fold_val, y_pred)\n",
        "\n",
        "    mae_scores_full.append(mae)\n",
        "    r2_scores_full.append(r2)\n",
        "    models_full.append(bst)\n",
        "\n",
        "    print(f\"\\nFold {fold} - MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
        "    print(f\"Best iteration: {bst.best_iteration}\\n\")\n",
        "\n",
        "# Métricas finales modelo completo\n",
        "oof_mae_full = mean_absolute_error(y_train, oof_predictions_full)\n",
        "oof_r2_full = r2_score(y_train, oof_predictions_full)\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(\"RESULTADOS - MODELO COMPLETO\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"MAE promedio: {np.mean(mae_scores_full):.4f} (+/- {np.std(mae_scores_full):.4f})\")\n",
        "print(f\"R² promedio:  {np.mean(r2_scores_full):.4f} (+/- {np.std(r2_scores_full):.4f})\")\n",
        "print(f\"\\nOut-of-Fold MAE: {oof_mae_full:.4f}\")\n",
        "print(f\"Out-of-Fold R²:  {oof_r2_full:.4f}\")"
      ],
      "metadata": {
        "id": "dXVsOiKmzj6Y"
      },
      "id": "dXVsOiKmzj6Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Resultados finales\n",
        "# print(f\"\\n{'='*60}\")\n",
        "# print(\"RESULTADOS FINALES\")\n",
        "# print(f\"{'='*60}\")\n",
        "# print(f\"MAE promedio: {np.mean(mae_scores):.4f} (+/- {np.std(mae_scores):.4f})\")\n",
        "# print(f\"R² promedio:  {np.mean(r2_scores):.4f} (+/- {np.std(r2_scores):.4f})\")\n",
        "\n",
        "# # Métricas con predicciones out-of-fold\n",
        "# oof_mae = mean_absolute_error(y_train, oof_predictions)\n",
        "# oof_r2 = r2_score(y_train, oof_predictions)\n",
        "# print(f\"\\nOut-of-Fold MAE: {oof_mae:.4f}\")\n",
        "# print(f\"Out-of-Fold R²:  {oof_r2:.4f}\")\n",
        "\n",
        "# print(\"\\nMétricas por fold:\")\n",
        "# for i, (mae, r2) in enumerate(zip(mae_scores, r2_scores), 1):\n",
        "#     print(f\"  Fold {i}: MAE={mae:.4f}, R²={r2:.4f}\")\n",
        "\n",
        "# # Función para hacer predicciones con ensemble (promedio de todos los modelos)\n",
        "# # def predict_ensemble(models, X):\n",
        "# #     \"\"\"Predice usando el promedio de todos los modelos\"\"\"\n",
        "# #     predictions = np.zeros((len(X), len(models)))\n",
        "# #     for i, model in enumerate(models):\n",
        "# #         predictions[:, i] = model.predict(X, num_iteration=model.best_iteration)\n",
        "# #     return predictions.mean(axis=1)\n",
        "\n",
        "# # Ejemplo de uso para predicción en test\n",
        "# # y_test_pred = predict_ensemble(models, X_test)\n",
        "\n",
        "# print(f\"\\n{len(models)} modelos entrenados y guardados en la lista 'models'\")"
      ],
      "metadata": {
        "id": "suOSi7SvvHj-"
      },
      "id": "suOSi7SvvHj-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"\\n{'='*60}\")\n",
        "# print(\"RESULTADOS FINALES\")\n",
        "# print(f\"{'='*60}\")\n",
        "# print(f\"MAE promedio: {np.mean(mae_scores):.4f} (+/- {np.std(mae_scores):.4f})\")\n",
        "# print(f\"R² promedio:  {np.mean(r2_scores):.4f} (+/- {np.std(r2_scores):.4f})\")\n",
        "\n",
        "# # OOF preds: asegúrate que 'oof_predictions' exista y tenga len == len(y_train)\n",
        "# oof_mae = mean_absolute_error(y_train, oof_predictions)\n",
        "# oof_r2 = r2_score(y_train, oof_predictions)\n",
        "# print(f\"\\nOut-of-Fold MAE: {oof_mae:.4f}\")\n",
        "# print(f\"Out-of-Fold R²:  {oof_r2:.4f}\")\n",
        "\n",
        "# print(\"\\nMétricas por fold:\")\n",
        "# for i, (mae, r2) in enumerate(zip(mae_scores, r2_scores), 1):\n",
        "#     print(f\"  Fold {i}: MAE={mae:.4f}, R²={r2:.4f}\")"
      ],
      "metadata": {
        "id": "d5JXe9jj42TW"
      },
      "id": "d5JXe9jj42TW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_ensemble(models, X):\n",
        "\n",
        "    preds = []\n",
        "    for m in models:\n",
        "\n",
        "        if isinstance(m, str):\n",
        "            booster = lgb.Booster(model_file=m)\n",
        "            it = getattr(booster, \"best_iteration\", None)\n",
        "            preds.append(booster.predict(X, num_iteration=it) if it else booster.predict(X))\n",
        "            continue\n",
        "\n",
        "        # Booster nativo\n",
        "        if isinstance(m, lgb.basic.Booster):\n",
        "            it = getattr(m, \"best_iteration\", None)\n",
        "            preds.append(m.predict(X, num_iteration=it) if it else m.predict(X))\n",
        "            continue\n",
        "\n",
        "        if isinstance(m, lgb.sklearn.LGBMRegressor):\n",
        "            it = getattr(m, \"best_iteration_\", None)\n",
        "            try:\n",
        "                preds.append(m.predict(X, num_iteration=it) if it is not None else m.predict(X))\n",
        "            except TypeError:\n",
        "                preds.append(m.predict(X))\n",
        "            continue\n",
        "\n",
        "        if hasattr(m, \"predict\"):\n",
        "            preds.append(m.predict(X))\n",
        "\n",
        "        else:\n",
        "            raise TypeError(f\"Tipo de modelo no soportado: {type(m)}\")\n",
        "\n",
        "    preds = np.vstack([p.ravel() for p in preds])\n",
        "    return preds.mean(axis=0)\n"
      ],
      "metadata": {
        "id": "2IGF18115BD_"
      },
      "id": "2IGF18115BD_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_pred = predict_ensemble(models_full, X_test)\n",
        "print(\"\\nMétricas ensemble en test:\")\n",
        "print(\"  MAE:\", mean_absolute_error(y_test, ensemble_pred))\n",
        "print(\"  R2: \", r2_score(y_test, ensemble_pred))"
      ],
      "metadata": {
        "id": "WXiilQ0-5F7h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b39c96c-0cb9-4c60-ad83-84e7980909b8"
      },
      "id": "WXiilQ0-5F7h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas ensemble en test:\n",
            "  MAE: 0.4313366275862136\n",
            "  R2:  -2.5950179460763816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_to_use = final_models if 'final_models' in globals() else models_full\n",
        "X_test_to_use = X_test_final if 'X_test_final' in globals() else X_test\n",
        "\n",
        "predictions_individual = []\n",
        "\n",
        "for i, model in enumerate(models_to_use, 1):\n",
        "        try:\n",
        "            pred = model.predict(X_test_to_use, num_iteration=model.best_iteration)\n",
        "            predictions_individual.append(pred)\n",
        "            print(f\"  Modelo {i}: {len(pred)} predicciones generadas\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ⚠️  Error en modelo {i}: {e}\")\n",
        "\n",
        "# Ensemble: promedio de todos los modelos\n",
        "predictions_matrix = np.vstack([p.ravel() for p in predictions_individual])\n",
        "y_pred_ensemble = predictions_matrix.mean(axis=0)\n",
        "\n",
        "print(f\"\\n✓ Predicciones ensemble generadas: {len(y_pred_ensemble)}\")\n",
        "\n",
        "y_pred_std = predictions_matrix.std(axis=0)\n",
        "\n",
        "# ==========================================\n",
        "# MÉTRICAS DE EVALUACIÓN\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MÉTRICAS DE EVALUACIÓN EN TEST SET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "y_test_array = y_test.values if hasattr(y_test, 'values') else y_test\n",
        "\n",
        "# Calcular métricas principales\n",
        "mae = mean_absolute_error(y_test_array, y_pred_ensemble)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_array, y_pred_ensemble))\n",
        "r2 = r2_score(y_test_array, y_pred_ensemble)\n",
        "\n",
        "# Métricas adicionales\n",
        "mse = mean_squared_error(y_test_array, y_pred_ensemble)\n",
        "\n",
        "# MAPE solo si no hay valores cero\n",
        "if np.all(y_test_array != 0):\n",
        "    try:\n",
        "        mape = mean_absolute_percentage_error(y_test_array, y_pred_ensemble)\n",
        "        mape_available = True\n",
        "    except:\n",
        "        mape_available = False\n",
        "else:\n",
        "    mape_available = False\n",
        "\n",
        "# Error residual\n",
        "residuals = y_test_array - y_pred_ensemble\n",
        "\n",
        "print(\"\\n📊 MÉTRICAS PRINCIPALES:\")\n",
        "print(f\"{'─'*70}\")\n",
        "print(f\"  MAE  (Mean Absolute Error):        {mae:.6f}\")\n",
        "print(f\"  RMSE (Root Mean Squared Error):    {rmse:.6f}\")\n",
        "print(f\"  R²   (Coefficient of Determination): {r2:.6f}\")\n",
        "print(f\"  MSE  (Mean Squared Error):         {mse:.6f}\")\n",
        "if mape_available:\n",
        "    print(f\"  MAPE (Mean Absolute % Error):      {mape:.2f}%\")\n",
        "\n",
        "print(f\"\\n📊 ESTADÍSTICAS DE RESIDUOS:\")\n",
        "print(f\"{'─'*70}\")\n",
        "print(f\"  Media de residuos:     {residuals.mean():.6f}\")\n",
        "print(f\"  Mediana de residuos:   {np.median(residuals):.6f}\")\n",
        "print(f\"  Std de residuos:       {residuals.std():.6f}\")\n",
        "print(f\"  Min error:             {residuals.min():.6f}\")\n",
        "print(f\"  Max error:             {residuals.max():.6f}\")\n",
        "\n",
        "print(f\"\\n📊 ESTADÍSTICAS DE PREDICCIONES:\")\n",
        "print(f\"{'─'*70}\")\n",
        "print(f\"  Min predicción:        {y_pred_ensemble.min():.6f}\")\n",
        "print(f\"  Max predicción:        {y_pred_ensemble.max():.6f}\")\n",
        "print(f\"  Media predicción:      {y_pred_ensemble.mean():.6f}\")\n",
        "print(f\"  Std predicción:        {y_pred_ensemble.std():.6f}\")\n",
        "\n",
        "print(f\"\\n📊 ESTADÍSTICAS DE VALORES REALES:\")\n",
        "print(f\"{'─'*70}\")\n",
        "print(f\"  Min real:              {y_test_array.min():.6f}\")\n",
        "print(f\"  Max real:              {y_test_array.max():.6f}\")\n",
        "print(f\"  Media real:            {y_test_array.mean():.6f}\")\n",
        "print(f\"  Std real:              {y_test_array.std():.6f}\")\n",
        "\n",
        "# Interpretación del R²\n",
        "print(f\"\\n💡 INTERPRETACIÓN:\")\n",
        "print(f\"{'─'*70}\")\n",
        "if r2 < 0:\n",
        "    print(\"  🔴 R² NEGATIVO: El modelo predice PEOR que usar la media.\")\n",
        "    print(\"     → Problema crítico: revisar datos, features o modelo.\")\n",
        "elif r2 < 0.3:\n",
        "    print(\"  🟡 R² BAJO (<0.3): Predicciones muy débiles.\")\n",
        "    print(\"     → El modelo captura menos del 30% de la varianza.\")\n",
        "elif r2 < 0.5:\n",
        "    print(\"  🟡 R² MODERADO (0.3-0.5): Predicciones aceptables pero mejorables.\")\n",
        "elif r2 < 0.7:\n",
        "    print(\"  🟢 R² BUENO (0.5-0.7): Predicciones buenas.\")\n",
        "elif r2 < 0.9:\n",
        "    print(\"  🟢 R² MUY BUENO (0.7-0.9): Excelentes predicciones.\")\n",
        "else:\n",
        "    print(\"  ⚠️  R² MUY ALTO (>0.9): Posible overfitting o data leakage.\")\n",
        "\n",
        "# Comparación con baseline\n",
        "baseline_pred = np.full(len(y_test_array), y_test_array.mean())\n",
        "mae_baseline = mean_absolute_error(y_test_array, baseline_pred)\n",
        "r2_baseline = r2_score(y_test_array, baseline_pred)\n",
        "\n",
        "print(f\"\\n📊 COMPARACIÓN CON BASELINE (predecir siempre la media):\")\n",
        "print(f\"{'─'*70}\")\n",
        "print(f\"  MAE Baseline:          {mae_baseline:.6f}\")\n",
        "print(f\"  MAE Modelo:            {mae:.6f}\")\n",
        "print(f\"  Mejora:                {((mae_baseline - mae) / mae_baseline * 100):.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1Pkp7ZrB3Vg",
        "outputId": "47547a08-85c4-466f-fe1c-89f20b998cb5"
      },
      "id": "q1Pkp7ZrB3Vg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Modelo 1: 2271948 predicciones generadas\n",
            "  Modelo 2: 2271948 predicciones generadas\n",
            "\n",
            "✓ Predicciones ensemble generadas: 2271948\n",
            "\n",
            "======================================================================\n",
            "MÉTRICAS DE EVALUACIÓN EN TEST SET\n",
            "======================================================================\n",
            "\n",
            "📊 MÉTRICAS PRINCIPALES:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "  MAE  (Mean Absolute Error):        0.431337\n",
            "  RMSE (Root Mean Squared Error):    0.662254\n",
            "  R²   (Coefficient of Determination): -2.595018\n",
            "  MSE  (Mean Squared Error):         0.438581\n",
            "\n",
            "📊 ESTADÍSTICAS DE RESIDUOS:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "  Media de residuos:     -0.093561\n",
            "  Mediana de residuos:   0.011779\n",
            "  Std de residuos:       0.655612\n",
            "  Min error:             -4.683695\n",
            "  Max error:             5.819235\n",
            "\n",
            "📊 ESTADÍSTICAS DE PREDICCIONES:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "  Min predicción:        -1.460683\n",
            "  Max predicción:        4.683695\n",
            "  Media predicción:      0.152953\n",
            "  Std predicción:        0.588551\n",
            "\n",
            "📊 ESTADÍSTICAS DE VALORES REALES:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "  Min real:              0.000000\n",
            "  Max real:              5.000000\n",
            "  Media real:            0.059393\n",
            "  Std real:              0.349280\n",
            "\n",
            "💡 INTERPRETACIÓN:\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "  🔴 R² NEGATIVO: El modelo predice PEOR que usar la media.\n",
            "     → Problema crítico: revisar datos, features o modelo.\n",
            "\n",
            "📊 COMPARACIÓN CON BASELINE (predecir siempre la media):\n",
            "──────────────────────────────────────────────────────────────────────\n",
            "  MAE Baseline:          0.113616\n",
            "  MAE Modelo:            0.431337\n",
            "  Mejora:                -279.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # 1) Comprobar dimensiones / columnas\n",
        "# print(\"X_test shape:\", X_test.shape)\n",
        "# if isinstance(X_train, pd.DataFrame) and isinstance(X_test, pd.DataFrame):\n",
        "#     print(\"Train cols == Test cols ?\", list(X_train.columns)==list(X_test.columns))\n",
        "#     # diferencias de columnas\n",
        "#     train_cols = set(X_train.columns)\n",
        "#     test_cols  = set(X_test.columns)\n",
        "#     print(\"Cols faltantes en test:\", train_cols - test_cols)\n",
        "#     print(\"Cols extra en test:\", test_cols - train_cols)\n",
        "# else:\n",
        "#     print(\"No dataframe; asegúrate que X_train/X_test tengan mismo orden de columnas.\")\n",
        "\n",
        "# # 2) Predicción por cada modelo — métricas individuales\n",
        "# per_model_metrics = []\n",
        "# per_model_preds = []\n",
        "# for i, m in enumerate(models):\n",
        "#     # cargar model si es ruta\n",
        "#     if isinstance(m, str):\n",
        "#         booster = lgb.Booster(model_file=m)\n",
        "#         it = getattr(booster, \"best_iteration\", None)\n",
        "#         preds = booster.predict(X_test, num_iteration=it) if it else booster.predict(X_test)\n",
        "#     elif isinstance(m, lgb.basic.Booster):\n",
        "#         it = getattr(m, \"best_iteration\", None)\n",
        "#         preds = m.predict(X_test, num_iteration=it) if it else m.predict(X_test)\n",
        "#     elif isinstance(m, lgb.sklearn.LGBMRegressor):\n",
        "#         it = getattr(m, \"best_iteration_\", None)\n",
        "#         try:\n",
        "#             preds = m.predict(X_test, num_iteration=it) if it else m.predict(X_test)\n",
        "#         except TypeError:\n",
        "#             preds = m.predict(X_test)\n",
        "#     else:\n",
        "#         preds = m.predict(X_test)  # fallback\n",
        "\n",
        "#     per_model_preds.append(preds)\n",
        "#     mae = mean_absolute_error(y_test, preds)\n",
        "#     r2  = r2_score(y_test, preds)\n",
        "#     per_model_metrics.append((mae, r2))\n",
        "#     print(f\"Model {i+1}: MAE={mae:.4f}, R2={r2:.4f}, preds min/max = {preds.min():.4f}/{preds.max():.4f}\")\n",
        "\n",
        "# # 3) Correlación entre predicciones (para ver si modelos son consistentes)\n",
        "# preds_mat = np.vstack(per_model_preds)  # shape (n_models, n_samples)\n",
        "# corr = np.corrcoef(preds_mat)\n",
        "# print(\"\\nCorrelación entre modelos (matriz):\")\n",
        "# print(np.round(corr,3))\n",
        "\n",
        "# # 4) Rango de target vs predicciones medias\n",
        "# ensemble_mean = preds_mat.mean(axis=0)\n",
        "# print(\"\\nTarget y preds rangos:\")\n",
        "# print(\" y_test min/max:\", y_test.min(), y_test.max())\n",
        "# print(\" ensemble min/max:\", ensemble_mean.min(), ensemble_mean.max())\n",
        "# print(\" ensemble MAE:\", mean_absolute_error(y_test, ensemble_mean))\n",
        "# print(\" ensemble R2 :\", r2_score(y_test, ensemble_mean))\n"
      ],
      "metadata": {
        "id": "kX-c0LFILk6j"
      },
      "id": "kX-c0LFILk6j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_raw = ensemble_mean  # tu ensemble promedio actual\n",
        "preds_inv = np.expm1(preds_raw)  # inverse de log1p\n",
        "\n",
        "print(\"MAE inv:\", mean_absolute_error(y_test, preds_inv))\n",
        "print(\"R2 inv:\", r2_score(y_test, preds_inv))"
      ],
      "metadata": {
        "id": "2xJZJhOlQ_He"
      },
      "id": "2xJZJhOlQ_He",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ensemble_mean: predicciones promediadas actuales (shape n_test,)\n",
        "preds_clip = np.clip(ensemble_mean, 0.0, 5.0)\n",
        "print(\"MAE clip:\", mean_absolute_error(y_test, preds_clip))\n",
        "print(\"R2 clip:\", r2_score(y_test, preds_clip))\n"
      ],
      "metadata": {
        "id": "IehPdivRZZlB"
      },
      "id": "IehPdivRZZlB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}