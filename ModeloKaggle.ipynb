{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Edd1enator/Tesis_Prediccion_Sequias/blob/main/ModeloKaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lF_U_TEGVEXF",
      "metadata": {
        "id": "lF_U_TEGVEXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab703960-6dcc-4d5f-c8f8-e1c0c9d67ced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hSelecting previously unselected package python3-numpy.\n",
            "(Reading database ... 125082 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-numpy_1%3a1.21.5-1ubuntu22.04.1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Selecting previously unselected package python3-gdal.\n",
            "Preparing to unpack .../python3-gdal_3.8.4+dfsg-1~jammy0_amd64.deb ...\n",
            "Unpacking python3-gdal (3.8.4+dfsg-1~jammy0) ...\n",
            "Selecting previously unselected package gdal-bin.\n",
            "Preparing to unpack .../gdal-bin_3.8.4+dfsg-1~jammy0_amd64.deb ...\n",
            "Unpacking gdal-bin (3.8.4+dfsg-1~jammy0) ...\n",
            "Setting up python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Setting up python3-gdal (3.8.4+dfsg-1~jammy0) ...\n",
            "Setting up gdal-bin (3.8.4+dfsg-1~jammy0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio geopandas tensorflow scikit-image tqdm matplotlib -q\n",
        "!apt install gdal-bin python3-gdal -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23837fdc",
      "metadata": {
        "id": "23837fdc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow import keras\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "from numpy import random\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import warnings\n",
        "\n",
        "np.set_printoptions(linewidth=130)\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "onptUn61C-Zp",
      "metadata": {
        "id": "onptUn61C-Zp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac69c35-1d22-4a79-99bc-fea85d3cdbe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurando GPUs...\n"
          ]
        }
      ],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    print(\"Configurando GPUs...\")\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)\n",
        "else:\n",
        "    print(\"No se detectaron GPUs, usando CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DUjLA3udVSs-",
      "metadata": {
        "id": "DUjLA3udVSs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ea5640-0331-4f88-cf74-45fb5d813a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU detectada: 1 dispositivos\n",
            "Configuración de GPU optimizada\n",
            "Versión de TensorFlow: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            print(f\"GPU detectada: {len(gpus)} dispositivos\")\n",
        "            print(\"Configuración de GPU optimizada\")\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Error configurando GPU: {e}\")\n",
        "    else:\n",
        "        print(\"No se detectó GPU\")\n",
        "\n",
        "    print(f\"Versión de TensorFlow: {tf.__version__}\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Error en la configuración de aceleración\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t4wLV7DwDiFn",
      "metadata": {
        "id": "t4wLV7DwDiFn"
      },
      "outputs": [],
      "source": [
        "base_path = \"/content/drive/MyDrive/Tesis/DataKaggle\"\n",
        "\n",
        "train_path = os.path.join(base_path, \"train_timeseries\")\n",
        "test_path = os.path.join(base_path, \"test_timeseries\")\n",
        "validation_path = os.path.join(base_path, \"validation_timeseries\")\n",
        "soil_data_path = os.path.join(base_path, \"soil_data.csv\")\n",
        "\n",
        "OUTPUT_DIR = \"/content/output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0181b893",
      "metadata": {
        "id": "0181b893"
      },
      "outputs": [],
      "source": [
        "# Configurar rutas según tu estructura de carpetas\n",
        "# base_path = \"/Users/eddiegiron/Desktop/archive\"\n",
        "\n",
        "# train_path = os.path.join(base_path, \"train_timeseries\")\n",
        "# test_path = os.path.join(base_path, \"test_timeseries\")\n",
        "# validation_path = os.path.join(base_path, \"validation_timeseries\")\n",
        "# soil_data_path = os.path.join(base_path, \"soil_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f_AplvsTZygX",
      "metadata": {
        "id": "f_AplvsTZygX"
      },
      "outputs": [],
      "source": [
        "batch_size = 1024\n",
        "epochs = 50\n",
        "random_state = 38\n",
        "k_folds = 5\n",
        "LEARNING_RATE = 3e-4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae_scores = []\n",
        "r2_scores = []\n",
        "models = []"
      ],
      "metadata": {
        "id": "hukoRQjg_-dI"
      },
      "id": "hukoRQjg_-dI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E6HpykRoDjiv",
      "metadata": {
        "id": "E6HpykRoDjiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffada4c8-2f72-4c88-b8a5-4627745cce47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a6575bf",
      "metadata": {
        "id": "8a6575bf"
      },
      "outputs": [],
      "source": [
        "# Función de carga de datos\n",
        "def carga_data(folder_path):\n",
        "    all_files = []\n",
        "\n",
        "    if os.path.exists(folder_path):\n",
        "        for file in os.listdir(folder_path):\n",
        "            if file.endswith('.csv'):\n",
        "                file_path = os.path.join(folder_path, file)\n",
        "                df = pd.read_csv(file_path)\n",
        "                df['source_file'] = file\n",
        "                all_files.append(df)\n",
        "\n",
        "        if all_files:\n",
        "            return pd.concat(all_files, ignore_index=True)\n",
        "        else:\n",
        "            print(f\"No se encontraron archivos CSV en {folder_path}\")\n",
        "            return pd.DataFrame()\n",
        "    else:\n",
        "        print(f\"La carpeta {folder_path} no existe\")\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ed46836",
      "metadata": {
        "id": "2ed46836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b060658-78fe-4bd4-c8a6-4177ee7636b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando datos de entrenamiento...\n",
            "Cargando datos de prueba...\n",
            "Cargando datos de validación...\n",
            "Cargando datos del suelo...\n"
          ]
        }
      ],
      "source": [
        "# Carga de datos para entorno\n",
        "print(\"Cargando datos de entrenamiento...\")\n",
        "train_data = carga_data(train_path)\n",
        "\n",
        "print(\"Cargando datos de prueba...\")\n",
        "test_data = carga_data(test_path)\n",
        "\n",
        "print(\"Cargando datos de validación...\")\n",
        "validation_data = carga_data(validation_path)\n",
        "\n",
        "print(\"Cargando datos del suelo...\")\n",
        "soil_data = pd.read_csv(soil_data_path) if os.path.exists(soil_data_path) else pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10e9aebd",
      "metadata": {
        "id": "10e9aebd"
      },
      "outputs": [],
      "source": [
        "# Limpieza de datos nulos en fips y date\n",
        "train_data = train_data.dropna(subset=['fips', 'date'])\n",
        "test_data = test_data.dropna(subset=['fips', 'date'])\n",
        "validation_data = validation_data.dropna(subset=['fips', 'date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4565b334",
      "metadata": {
        "id": "4565b334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6f52e9-70ac-4f34-a46c-37df0b6265ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ESTRUCTURA DE LOS DATOS ===\n",
            "Train data shape: (19300680, 22)\n",
            "Test data shape: (2271948, 22)\n",
            "Validation data shape: (2268840, 22)\n",
            "Soil data shape: (3109, 32)\n",
            "\n",
            "Columnas en train_data:\n",
            "['fips', 'date', 'PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET', 'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX', 'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN', 'WS50M_RANGE', 'score', 'source_file']\n",
            "\n",
            "Primeras filas de train_data:\n",
            "   fips        date  PRECTOT      PS   QV2M    T2M  T2MDEW  T2MWET  T2M_MAX  \\\n",
            "0  1001  2000-01-01     0.22  100.51   9.65  14.74   13.51   13.51    20.96   \n",
            "1  1001  2000-01-02     0.20  100.55  10.42  16.69   14.71   14.71    22.80   \n",
            "2  1001  2000-01-03     3.65  100.15  11.76  18.49   16.52   16.52    22.73   \n",
            "3  1001  2000-01-04    15.95  100.29   6.42  11.40    6.09    6.10    18.09   \n",
            "4  1001  2000-01-05     0.00  101.15   2.95   3.86   -3.29   -3.20    10.82   \n",
            "\n",
            "   T2M_MIN  ...  WS10M  WS10M_MAX  WS10M_MIN  WS10M_RANGE  WS50M  WS50M_MAX  \\\n",
            "0    11.46  ...   2.20       2.94       1.49         1.46   4.85       6.04   \n",
            "1    12.61  ...   2.52       3.43       1.83         1.60   5.33       6.13   \n",
            "2    15.32  ...   4.03       5.33       2.66         2.67   7.53       9.52   \n",
            "3     2.16  ...   3.84       5.67       2.08         3.59   6.73       9.31   \n",
            "4    -2.66  ...   1.60       2.50       0.52         1.98   2.94       4.85   \n",
            "\n",
            "   WS50M_MIN  WS50M_RANGE  score           source_file  \n",
            "0       3.23         2.81    NaN  train_timeseries.csv  \n",
            "1       3.72         2.41    NaN  train_timeseries.csv  \n",
            "2       5.87         3.66    NaN  train_timeseries.csv  \n",
            "3       3.74         5.58    1.0  train_timeseries.csv  \n",
            "4       0.65         4.19    NaN  train_timeseries.csv  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "print(\"=== ESTRUCTURA DE LOS DATOS ===\")\n",
        "print(f\"Train data shape: {train_data.shape}\")\n",
        "print(f\"Test data shape: {test_data.shape}\")\n",
        "print(f\"Validation data shape: {validation_data.shape}\")\n",
        "print(f\"Soil data shape: {soil_data.shape}\")\n",
        "\n",
        "if not train_data.empty:\n",
        "    print(\"\\nColumnas en train_data:\")\n",
        "    print(train_data.columns.tolist())\n",
        "    print(\"\\nPrimeras filas de train_data:\")\n",
        "    print(train_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e130aa6e",
      "metadata": {
        "id": "e130aa6e"
      },
      "outputs": [],
      "source": [
        "def visualizar_dataset(df, name):\n",
        "    \"\"\"Analiza un dataset mostrando información básica\"\"\"\n",
        "    if df.empty:\n",
        "        print(f\"{name}: Dataset vacío\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n=== ANÁLISIS DE {name.upper()} ===\")\n",
        "    print(f\"Dimensiones: {df.shape}\")\n",
        "    print(f\"Columnas: {df.columns.tolist()}\")\n",
        "    print(f\"Tipos de datos:\")\n",
        "    print(df.dtypes)\n",
        "    print(f\"Valores nulos:\")\n",
        "    print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "158cbdf6",
      "metadata": {
        "id": "158cbdf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c8e497-1e9e-410e-b5a8-485b45c78d8e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ANÁLISIS DE TRAIN_DATA ===\n",
            "Dimensiones: (19300680, 22)\n",
            "Columnas: ['fips', 'date', 'PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET', 'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX', 'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN', 'WS50M_RANGE', 'score', 'source_file']\n",
            "Tipos de datos:\n",
            "fips             int64\n",
            "date            object\n",
            "PRECTOT        float64\n",
            "PS             float64\n",
            "QV2M           float64\n",
            "T2M            float64\n",
            "T2MDEW         float64\n",
            "T2MWET         float64\n",
            "T2M_MAX        float64\n",
            "T2M_MIN        float64\n",
            "T2M_RANGE      float64\n",
            "TS             float64\n",
            "WS10M          float64\n",
            "WS10M_MAX      float64\n",
            "WS10M_MIN      float64\n",
            "WS10M_RANGE    float64\n",
            "WS50M          float64\n",
            "WS50M_MAX      float64\n",
            "WS50M_MIN      float64\n",
            "WS50M_RANGE    float64\n",
            "score          float64\n",
            "source_file     object\n",
            "dtype: object\n",
            "Valores nulos:\n",
            "fips                  0\n",
            "date                  0\n",
            "PRECTOT               0\n",
            "PS                    0\n",
            "QV2M                  0\n",
            "T2M                   0\n",
            "T2MDEW                0\n",
            "T2MWET                0\n",
            "T2M_MAX               0\n",
            "T2M_MIN               0\n",
            "T2M_RANGE             0\n",
            "TS                    0\n",
            "WS10M                 0\n",
            "WS10M_MAX             0\n",
            "WS10M_MIN             0\n",
            "WS10M_RANGE           0\n",
            "WS50M                 0\n",
            "WS50M_MAX             0\n",
            "WS50M_MIN             0\n",
            "WS50M_RANGE           0\n",
            "score          16543884\n",
            "source_file           0\n",
            "dtype: int64\n",
            "\n",
            "=== ANÁLISIS DE SOIL_DATA ===\n",
            "Dimensiones: (3109, 32)\n",
            "Columnas: ['fips', 'lat', 'lon', 'elevation', 'slope1', 'slope2', 'slope3', 'slope4', 'slope5', 'slope6', 'slope7', 'slope8', 'aspectN', 'aspectE', 'aspectS', 'aspectW', 'aspectUnknown', 'WAT_LAND', 'NVG_LAND', 'URB_LAND', 'GRS_LAND', 'FOR_LAND', 'CULTRF_LAND', 'CULTIR_LAND', 'CULT_LAND', 'SQ1', 'SQ2', 'SQ3', 'SQ4', 'SQ5', 'SQ6', 'SQ7']\n",
            "Tipos de datos:\n",
            "fips               int64\n",
            "lat              float64\n",
            "lon              float64\n",
            "elevation          int64\n",
            "slope1           float64\n",
            "slope2           float64\n",
            "slope3           float64\n",
            "slope4           float64\n",
            "slope5           float64\n",
            "slope6           float64\n",
            "slope7           float64\n",
            "slope8           float64\n",
            "aspectN          float64\n",
            "aspectE          float64\n",
            "aspectS          float64\n",
            "aspectW          float64\n",
            "aspectUnknown    float64\n",
            "WAT_LAND         float64\n",
            "NVG_LAND         float64\n",
            "URB_LAND         float64\n",
            "GRS_LAND         float64\n",
            "FOR_LAND         float64\n",
            "CULTRF_LAND      float64\n",
            "CULTIR_LAND      float64\n",
            "CULT_LAND        float64\n",
            "SQ1                int64\n",
            "SQ2                int64\n",
            "SQ3                int64\n",
            "SQ4                int64\n",
            "SQ5                int64\n",
            "SQ6                int64\n",
            "SQ7                int64\n",
            "dtype: object\n",
            "Valores nulos:\n",
            "fips             0\n",
            "lat              0\n",
            "lon              0\n",
            "elevation        0\n",
            "slope1           0\n",
            "slope2           0\n",
            "slope3           0\n",
            "slope4           0\n",
            "slope5           0\n",
            "slope6           0\n",
            "slope7           0\n",
            "slope8           0\n",
            "aspectN          0\n",
            "aspectE          0\n",
            "aspectS          0\n",
            "aspectW          0\n",
            "aspectUnknown    0\n",
            "WAT_LAND         0\n",
            "NVG_LAND         0\n",
            "URB_LAND         0\n",
            "GRS_LAND         0\n",
            "FOR_LAND         0\n",
            "CULTRF_LAND      0\n",
            "CULTIR_LAND      0\n",
            "CULT_LAND        0\n",
            "SQ1              0\n",
            "SQ2              0\n",
            "SQ3              0\n",
            "SQ4              0\n",
            "SQ5              0\n",
            "SQ6              0\n",
            "SQ7              0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "visualizar_dataset(train_data, \"train_data\")\n",
        "visualizar_dataset(soil_data, \"soil_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68b23274",
      "metadata": {
        "id": "68b23274"
      },
      "outputs": [],
      "source": [
        "def buscar_columna_objetivo(df):\n",
        "    \"\"\"Busca columnas relacionadas con sequía\"\"\"\n",
        "    drought_keywords = ['drought', 'sequia', 'dry', 'aridity', 'water_stress', 'index']\n",
        "    target_cols = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_lower = col.lower()\n",
        "        for keyword in drought_keywords:\n",
        "            if keyword in col_lower:\n",
        "                target_cols.append(col)\n",
        "                break\n",
        "    return target_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e77b58e1",
      "metadata": {
        "id": "e77b58e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea323b3b-ab33-4c63-e45f-10f5ba89c337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas objetivo potenciales: []\n",
            "Columnas numéricas disponibles: ['fips', 'PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET', 'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX', 'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN', 'WS50M_RANGE', 'score']\n",
            "Usando 'score' como columna objetivo por defecto\n"
          ]
        }
      ],
      "source": [
        "target_columns = buscar_columna_objetivo(train_data)\n",
        "print(\"Columnas objetivo potenciales:\", target_columns)\n",
        "\n",
        "if not target_columns and not train_data.empty:\n",
        "    numeric_cols = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    print(\"Columnas numéricas disponibles:\", numeric_cols)\n",
        "    if numeric_cols:\n",
        "        target_columns = [numeric_cols[-1]]\n",
        "        print(f\"Usando '{target_columns[0]}' como columna objetivo por defecto\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"✅ Configuración actualizada - Ahora puedes ver más registros\")\n",
        "\n",
        "# Probar de nuevo\n",
        "train_data.score.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q8ySFibrwfG3",
        "outputId": "0d1bbc39-783b-4fd4-fa68-076782bce49d",
        "collapsed": true
      },
      "id": "Q8ySFibrwfG3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuración actualizada - Ahora puedes ver más registros\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        NaN\n",
              "1        NaN\n",
              "2        NaN\n",
              "3     1.0000\n",
              "4        NaN\n",
              "5        NaN\n",
              "6        NaN\n",
              "7        NaN\n",
              "8        NaN\n",
              "9        NaN\n",
              "10    2.0000\n",
              "11       NaN\n",
              "12       NaN\n",
              "13       NaN\n",
              "14       NaN\n",
              "15       NaN\n",
              "16       NaN\n",
              "17    2.0000\n",
              "18       NaN\n",
              "19       NaN\n",
              "20       NaN\n",
              "21       NaN\n",
              "22       NaN\n",
              "23       NaN\n",
              "24    2.0000\n",
              "25       NaN\n",
              "26       NaN\n",
              "27       NaN\n",
              "28       NaN\n",
              "29       NaN\n",
              "30       NaN\n",
              "31    1.0000\n",
              "32       NaN\n",
              "33       NaN\n",
              "34       NaN\n",
              "35       NaN\n",
              "36       NaN\n",
              "37       NaN\n",
              "38    1.0000\n",
              "39       NaN\n",
              "40       NaN\n",
              "41       NaN\n",
              "42       NaN\n",
              "43       NaN\n",
              "44       NaN\n",
              "45    1.0000\n",
              "46       NaN\n",
              "47       NaN\n",
              "48       NaN\n",
              "49       NaN\n",
              "50       NaN\n",
              "51       NaN\n",
              "52    1.0000\n",
              "53       NaN\n",
              "54       NaN\n",
              "55       NaN\n",
              "56       NaN\n",
              "57       NaN\n",
              "58       NaN\n",
              "59    1.0000\n",
              "60       NaN\n",
              "61       NaN\n",
              "62       NaN\n",
              "63       NaN\n",
              "64       NaN\n",
              "65       NaN\n",
              "66    1.0000\n",
              "67       NaN\n",
              "68       NaN\n",
              "69       NaN\n",
              "70       NaN\n",
              "71       NaN\n",
              "72       NaN\n",
              "73    1.4905\n",
              "74       NaN\n",
              "75       NaN\n",
              "76       NaN\n",
              "77       NaN\n",
              "78       NaN\n",
              "79       NaN\n",
              "80    1.5019\n",
              "81       NaN\n",
              "82       NaN\n",
              "83       NaN\n",
              "84       NaN\n",
              "85       NaN\n",
              "86       NaN\n",
              "87    1.2818\n",
              "88       NaN\n",
              "89       NaN\n",
              "90       NaN\n",
              "91       NaN\n",
              "92       NaN\n",
              "93       NaN\n",
              "94    1.0000\n",
              "95       NaN\n",
              "96       NaN\n",
              "97       NaN\n",
              "98       NaN\n",
              "99       NaN\n",
              "Name: score, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>1.4905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>1.5019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>1.2818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tUH4ZnYNyQm2",
      "metadata": {
        "id": "tUH4ZnYNyQm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1ac44f-b171-4cb0-977b-9085c69bfe3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos cargados: (19300680, 22)\n",
            "date_col: date target_col: score\n"
          ]
        }
      ],
      "source": [
        "date_col = None\n",
        "for c in ['date','fecha','timestamp','time']:\n",
        "    if c in train_data.columns:\n",
        "        date_col = c\n",
        "        break\n",
        "if date_col is None:\n",
        "    raise ValueError(\"No encontré columna de fecha; asigna date_col manualmente.\")\n",
        "\n",
        "target_col = None\n",
        "for c in train_data.columns:\n",
        "    if 'score' in c.lower():\n",
        "        target_col = c\n",
        "        break\n",
        "if target_col is None:\n",
        "    raise ValueError(\"No encontré columna objetivo que contenga 'score' en su nombre.\")\n",
        "\n",
        "# normalizar fecha y ordenar\n",
        "train_data[date_col] = pd.to_datetime(train_data[date_col], errors='coerce').dt.normalize()\n",
        "train_data = train_data.dropna(subset=[date_col])\n",
        "train_data = train_data.sort_values([ 'fips', date_col ]).reset_index(drop=True)\n",
        "\n",
        "print(\"Datos cargados:\", train_data.shape)\n",
        "print(\"date_col:\", date_col, \"target_col:\", target_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5Obg1H9_aGtJ",
      "metadata": {
        "id": "5Obg1H9_aGtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c16b59-708a-4812-b005-5f311b1b75dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weekly_df shape: (2759904, 21)\n",
            "   fips       date  score\n",
            "0  1001 2000-01-04    1.0\n",
            "1  1001 2000-01-11    2.0\n",
            "2  1001 2000-01-18    2.0\n",
            "3  1001 2000-01-25    2.0\n",
            "4  1001 2000-02-01    1.0\n",
            "5  1001 2000-02-08    1.0\n",
            "6  1001 2000-02-15    1.0\n",
            "7  1001 2000-02-22    1.0\n",
            "8  1001 2000-02-29    1.0\n",
            "9  1001 2000-03-07    1.0\n"
          ]
        }
      ],
      "source": [
        "weekly_list = []\n",
        "grouped = train_data.groupby('fips')\n",
        "\n",
        "for fid, g in grouped:\n",
        "    g = g.copy()\n",
        "    g[date_col] = pd.to_datetime(g[date_col], errors='coerce').dt.normalize()\n",
        "    g = g.set_index(date_col).sort_index()\n",
        "\n",
        "    numeric_cols = g.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    numeric_cols = [c for c in numeric_cols if c != target_col]\n",
        "\n",
        "    # construir series diarias promedio\n",
        "    daily = g[numeric_cols].resample('D').mean()\n",
        "\n",
        "    # agregar semanalmente con etiqueta el martes\n",
        "    weekly = daily.resample('W-TUE').mean()\n",
        "\n",
        "    score_s = g[[target_col]].dropna().groupby(level=0).first()\n",
        "\n",
        "    wk = weekly.join(score_s, how='left')\n",
        "\n",
        "    wk = wk.reset_index().rename(columns={'index': date_col})\n",
        "    wk['fips'] = fid\n",
        "    weekly_list.append(wk)\n",
        "\n",
        "weekly_df = pd.concat(weekly_list, ignore_index=True)\n",
        "weekly_df = weekly_df.rename(columns={date_col: 'date'})\n",
        "\n",
        "print(\"weekly_df shape:\", weekly_df.shape)\n",
        "print(weekly_df[[ 'fips', 'date', target_col ]].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P6Md37fO-QAK",
      "metadata": {
        "id": "P6Md37fO-QAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6a55958-1b69-413f-a9c0-50645a32d4e1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        date  fips   PRECTOT          PS      QV2M        T2M     T2MDEW     T2MWET    T2M_MAX    T2M_MIN  T2M_RANGE         TS     WS10M  WS10M_MAX  WS10M_MIN  WS10M_RANGE     WS50M  WS50M_MAX  WS50M_MIN  WS50M_RANGE  score\n",
            "0 2000-01-04  1001  5.005000  100.375000  9.562500  15.330000  12.707500  12.710000  21.145000  10.387500  10.752500  15.242500  3.147500   4.342500   2.015000     2.330000  6.110000   7.750000   4.140000     3.615000    1.0\n",
            "1 2000-01-11  1001  5.684286  100.665714  5.951429   9.192857   4.908571   4.934286  15.732857   3.071429  12.662857   8.558571  2.200000   3.305714   1.238571     2.065714  4.418571   6.588571   2.280000     4.307143    2.0\n",
            "2 2000-01-18  1001  0.832857  101.275714  6.692857  10.118571   6.711429   6.735714  16.931429   3.757143  13.177143   9.975714  2.352857   3.257143   1.490000     1.767143  4.870000   6.508571   2.812857     3.692857    2.0\n",
            "3 2000-01-25  1001  3.641429  100.187143  4.220000   4.458571  -0.224286  -0.132857  10.217143  -1.282857  11.498571   4.508571  2.932857   4.090000   1.814286     2.275714  5.270000   7.174286   3.575714     3.600000    2.0\n",
            "4 2000-02-01  1001  3.617143  100.992857  3.178571   0.764286  -2.791429  -2.714286   6.275714  -3.271429   9.547143   0.781429  2.362857   3.354286   1.318571     2.037143  4.372857   6.177143   2.580000     3.594286    1.0\n",
            "5 2000-02-08  1001  0.000000  101.054286  3.545714   4.377143  -1.231429  -1.180000  12.318571  -2.164286  14.480000   3.640000  2.075714   3.034286   1.051429     1.982857  3.812857   5.880000   1.654286     4.227143    1.0\n",
            "6 2000-02-15  1001  1.708571  100.215714  8.087143  13.325714  10.057143  10.061429  20.042857   6.375714  13.668571  12.987143  2.444286   3.491429   1.431429     2.061429  4.887143   7.050000   2.547143     4.504286    1.0\n",
            "7 2000-02-22  1001  0.917143  100.998571  7.101429  12.237143   7.655714   7.668571  19.608571   5.337143  14.271429  12.130000  2.418571   3.192857   1.682857     1.512857  4.714286   6.535714   3.157143     3.380000    1.0\n",
            "8 2000-02-29  1001  3.852857  100.828571  7.628571  14.057143   9.621429   9.625714  21.797143   7.042857  14.752857  14.005714  2.662857   3.820000   1.730000     2.091429  5.345714   6.948571   3.407143     3.541429    1.0\n",
            "9 2000-03-07  1001  1.347143  100.318571  7.094286  14.390000   8.392857   8.401429  22.034286   7.078571  14.955714  13.580000  2.137143   3.078571   1.241429     1.835714  4.095714   5.971429   2.384286     3.585714    1.0\n"
          ]
        }
      ],
      "source": [
        "print(weekly_df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def round_score_series(s):\n",
        "\n",
        "    # Variable para almacenar valores score con NaN\n",
        "    nan_mask = s.isna()\n",
        "\n",
        "    rounded = np.floor(s.values + 0.5).astype(int)\n",
        "    rounded = np.clip(rounded, 0, 5)\n",
        "\n",
        "    result = pd.Series(rounded, index=s.index, dtype=float)\n",
        "\n",
        "    # restaurar valores NaN\n",
        "    result[nan_mask] = np.nan\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "Y72F4jNeFH4r"
      },
      "id": "Y72F4jNeFH4r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_temp = []\n",
        "df_temp = weekly_df.copy()\n",
        "df_temp['score'] = round_score_series(df_temp['score'])\n",
        "print(df_temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LptJr-X7FQ0u",
        "outputId": "ddf0f587-59f9-4e06-e9ab-f3e3bc78ff62",
        "collapsed": true
      },
      "id": "LptJr-X7FQ0u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              date   fips   PRECTOT          PS      QV2M        T2M     T2MDEW     T2MWET    T2M_MAX    T2M_MIN  T2M_RANGE         TS     WS10M  WS10M_MAX  WS10M_MIN  WS10M_RANGE     WS50M  WS50M_MAX  WS50M_MIN  WS50M_RANGE  score\n",
            "0       2000-01-04   1001  5.005000  100.375000  9.562500  15.330000  12.707500  12.710000  21.145000  10.387500  10.752500  15.242500  3.147500   4.342500   2.015000     2.330000  6.110000   7.750000   4.140000     3.615000    1.0\n",
            "1       2000-01-11   1001  5.684286  100.665714  5.951429   9.192857   4.908571   4.934286  15.732857   3.071429  12.662857   8.558571  2.200000   3.305714   1.238571     2.065714  4.418571   6.588571   2.280000     4.307143    2.0\n",
            "2       2000-01-18   1001  0.832857  101.275714  6.692857  10.118571   6.711429   6.735714  16.931429   3.757143  13.177143   9.975714  2.352857   3.257143   1.490000     1.767143  4.870000   6.508571   2.812857     3.692857    2.0\n",
            "3       2000-01-25   1001  3.641429  100.187143  4.220000   4.458571  -0.224286  -0.132857  10.217143  -1.282857  11.498571   4.508571  2.932857   4.090000   1.814286     2.275714  5.270000   7.174286   3.575714     3.600000    2.0\n",
            "4       2000-02-01   1001  3.617143  100.992857  3.178571   0.764286  -2.791429  -2.714286   6.275714  -3.271429   9.547143   0.781429  2.362857   3.354286   1.318571     2.037143  4.372857   6.177143   2.580000     3.594286    1.0\n",
            "...            ...    ...       ...         ...       ...        ...        ...        ...        ...        ...        ...        ...       ...        ...        ...          ...       ...        ...        ...          ...    ...\n",
            "2759899 2016-12-06  56043  0.471429   82.668571  1.991429  -5.320000 -11.062857 -10.812857  -0.422857  -9.621429   9.200000  -5.887143  3.517143   5.534286   1.837143     3.694286  5.210000   7.768571   2.905714     4.862857    0.0\n",
            "2759900 2016-12-13  56043  0.350000   82.865714  1.884286  -7.621429 -12.220000 -11.961429  -2.532857 -11.791429   9.260000  -8.364286  3.370000   5.521429   1.435714     4.085714  5.080000   7.635714   2.311429     5.322857    0.0\n",
            "2759901 2016-12-20  56043  0.812857   82.752857  1.757143  -9.688571 -13.777143 -13.368571  -3.805714 -15.451429  11.642857 -10.667143  3.735714   5.688571   1.648571     4.038571  5.287143   7.750000   2.740000     5.008571    0.0\n",
            "2759902 2016-12-27  56043  0.751429   82.667143  2.022857  -6.534286 -11.001429 -10.767143   0.274286 -11.805714  12.081429  -8.218571  4.237143   6.014286   2.238571     3.775714  6.342857   8.890000   3.630000     5.258571    0.0\n",
            "2759903 2017-01-03  56043  0.420000   82.940000  1.845000  -6.792500 -11.695000 -11.505000   0.185000 -11.635000  11.820000  -8.787500  4.520000   7.120000   2.135000     4.987500  6.782500   9.985000   3.590000     6.395000    NaN\n",
            "\n",
            "[2759904 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"✅ Configuración actualizada - Ahora puedes ver más registros\")\n",
        "\n",
        "# Probar de nuevo\n",
        "df_temp.score.head(100)\n",
        "nulos_score = df_temp['score'].isna().sum()\n",
        "print(nulos_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaVwZXLaFz74",
        "outputId": "a5f54cf9-d81b-428b-e2aa-518a5fc3380f"
      },
      "id": "jaVwZXLaFz74",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuración actualizada - Ahora puedes ver más registros\n",
            "3108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"✅ Configuración actualizada - Ahora puedes ver más registros\")\n",
        "\n",
        "# Probar de nuevo\n",
        "df_temp.score.tail(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "JLfD-NVn__P-",
        "outputId": "ce21faf6-0ff3-4f8e-d0ef-1b207438d75f"
      },
      "id": "JLfD-NVn__P-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuración actualizada - Ahora puedes ver más registros\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2759804    0.0\n",
              "2759805    0.0\n",
              "2759806    0.0\n",
              "2759807    0.0\n",
              "2759808    0.0\n",
              "2759809    0.0\n",
              "2759810    0.0\n",
              "2759811    0.0\n",
              "2759812    0.0\n",
              "2759813    0.0\n",
              "2759814    0.0\n",
              "2759815    0.0\n",
              "2759816    0.0\n",
              "2759817    0.0\n",
              "2759818    0.0\n",
              "2759819    0.0\n",
              "2759820    0.0\n",
              "2759821    0.0\n",
              "2759822    0.0\n",
              "2759823    0.0\n",
              "2759824    0.0\n",
              "2759825    0.0\n",
              "2759826    0.0\n",
              "2759827    0.0\n",
              "2759828    0.0\n",
              "2759829    0.0\n",
              "2759830    0.0\n",
              "2759831    0.0\n",
              "2759832    0.0\n",
              "2759833    0.0\n",
              "2759834    0.0\n",
              "2759835    0.0\n",
              "2759836    0.0\n",
              "2759837    0.0\n",
              "2759838    0.0\n",
              "2759839    0.0\n",
              "2759840    0.0\n",
              "2759841    0.0\n",
              "2759842    1.0\n",
              "2759843    1.0\n",
              "2759844    1.0\n",
              "2759845    1.0\n",
              "2759846    1.0\n",
              "2759847    1.0\n",
              "2759848    1.0\n",
              "2759849    1.0\n",
              "2759850    1.0\n",
              "2759851    1.0\n",
              "2759852    2.0\n",
              "2759853    2.0\n",
              "2759854    2.0\n",
              "2759855    2.0\n",
              "2759856    2.0\n",
              "2759857    2.0\n",
              "2759858    2.0\n",
              "2759859    2.0\n",
              "2759860    2.0\n",
              "2759861    2.0\n",
              "2759862    2.0\n",
              "2759863    2.0\n",
              "2759864    2.0\n",
              "2759865    2.0\n",
              "2759866    1.0\n",
              "2759867    1.0\n",
              "2759868    1.0\n",
              "2759869    1.0\n",
              "2759870    1.0\n",
              "2759871    1.0\n",
              "2759872    1.0\n",
              "2759873    1.0\n",
              "2759874    1.0\n",
              "2759875    1.0\n",
              "2759876    1.0\n",
              "2759877    1.0\n",
              "2759878    1.0\n",
              "2759879    1.0\n",
              "2759880    2.0\n",
              "2759881    2.0\n",
              "2759882    2.0\n",
              "2759883    2.0\n",
              "2759884    2.0\n",
              "2759885    2.0\n",
              "2759886    2.0\n",
              "2759887    1.0\n",
              "2759888    1.0\n",
              "2759889    1.0\n",
              "2759890    0.0\n",
              "2759891    0.0\n",
              "2759892    0.0\n",
              "2759893    0.0\n",
              "2759894    0.0\n",
              "2759895    0.0\n",
              "2759896    0.0\n",
              "2759897    0.0\n",
              "2759898    0.0\n",
              "2759899    0.0\n",
              "2759900    0.0\n",
              "2759901    0.0\n",
              "2759902    0.0\n",
              "2759903    NaN\n",
              "Name: score, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2759804</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759805</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759806</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759807</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759808</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759809</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759810</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759811</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759812</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759813</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759814</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759815</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759816</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759817</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759818</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759819</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759820</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759821</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759822</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759823</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759824</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759825</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759826</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759827</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759828</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759829</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759830</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759831</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759832</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759833</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759834</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759835</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759836</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759837</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759838</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759839</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759840</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759841</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759842</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759843</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759844</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759845</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759846</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759847</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759848</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759849</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759850</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759851</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759852</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759853</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759854</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759855</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759856</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759857</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759858</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759859</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759860</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759861</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759862</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759863</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759864</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759865</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759866</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759867</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759868</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759869</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759870</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759871</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759872</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759873</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759874</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759875</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759876</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759877</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759878</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759879</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759880</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759881</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759882</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759883</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759884</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759885</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759886</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759887</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759888</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759889</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759890</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759891</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759892</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759893</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759894</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759895</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759896</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759897</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759898</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759899</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759900</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759901</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759902</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759903</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68dfd35d",
      "metadata": {
        "id": "68dfd35d"
      },
      "outputs": [],
      "source": [
        "# Función de preprocesamiento\n",
        "def preprocess_data(df, target_col=None):\n",
        "    if df.empty:\n",
        "        return df, None, None\n",
        "\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    date_columns = ['date', 'fecha', 'time', 'timestamp']\n",
        "    for date_col in date_columns:\n",
        "        if date_col in df_processed.columns:\n",
        "            df_processed[date_col] = pd.to_datetime(df_processed[date_col], errors='coerce')\n",
        "            df_processed['year'] = df_processed[date_col].dt.year\n",
        "            df_processed['month'] = df_processed[date_col].dt.month\n",
        "            df_processed['day'] = df_processed[date_col].dt.day\n",
        "            break\n",
        "\n",
        "    # Manejo de valores nulos\n",
        "    numeric_cols = df_processed.select_dtypes(include=[np.number]).columns\n",
        "    for col in numeric_cols:\n",
        "        if df_processed[col].isnull().sum() > 0:\n",
        "            df_processed[col].fillna(df_processed[col].median(), inplace=True)\n",
        "\n",
        "    no_numeric_cols = df_processed.select_dtypes(exclude=[np.number]).columns\n",
        "    features_to_drop = [col for col in no_numeric_cols if col != target_col]\n",
        "    df_processed = df_processed.drop(columns=features_to_drop)\n",
        "\n",
        "    if target_col and target_col in df_processed.columns:\n",
        "        X = df_processed.drop(columns=[target_col])\n",
        "        y = df_processed[target_col]\n",
        "        return X, y, df_processed\n",
        "    else:\n",
        "        return df_processed, None, df_processed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6193169a",
      "metadata": {
        "id": "6193169a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f37220c-c7a6-4f7d-efa9-1593237695e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando 'score' como columna objetivo\n",
            "Preprocesando datos...\n"
          ]
        }
      ],
      "source": [
        "# Preprocesar datos\n",
        "\n",
        "columna_objetivo = buscar_columna_objetivo(df_temp)\n",
        "# columna_objetivo = buscar_columna_objetivo(train_data)\n",
        "columna_objetivo = columna_objetivo[0] if columna_objetivo else None\n",
        "\n",
        "if not columna_objetivo and not df_temp.empty:\n",
        "    numeric_cols = df_temp.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if numeric_cols:\n",
        "        columna_objetivo = numeric_cols[-1]\n",
        "        print(f\"Usando '{columna_objetivo}' como columna objetivo\")\n",
        "\n",
        "# if not columna_objetivo and not train_data.empty:\n",
        "#     numeric_cols = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "#     if numeric_cols:\n",
        "#         columna_objetivo = numeric_cols[-1]\n",
        "#         print(f\"Usando '{columna_objetivo}' como columna objetivo\")\n",
        "\n",
        "print(\"Preprocesando datos...\")\n",
        "X_train, y_train, train_processed = preprocess_data(df_temp, columna_objetivo)\n",
        "# X_train, y_train, train_processed = preprocess_data(train_data, columna_objetivo)\n",
        "X_test, y_test, test_processed = preprocess_data(test_data, columna_objetivo)\n",
        "X_val, y_val, val_processed = preprocess_data(validation_data, columna_objetivo)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mPBK_mhwLHJ",
        "outputId": "fa172914-35b4-4933-ca4f-47e3156c33c2"
      },
      "id": "_mPBK_mhwLHJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0          0.0\n",
            "1          0.0\n",
            "2          2.0\n",
            "3          0.0\n",
            "4          0.0\n",
            "          ... \n",
            "2268835    0.0\n",
            "2268836    0.0\n",
            "2268837    0.0\n",
            "2268838    0.0\n",
            "2268839    0.0\n",
            "Name: score, Length: 2268840, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eKhrm75N7Vnq",
      "metadata": {
        "id": "eKhrm75N7Vnq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "9a37af34-f19c-4c98-f9a5-1430164ec3f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_features='sqrt', min_samples_leaf=5, n_jobs=-1,\n",
              "                      random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_features=&#x27;sqrt&#x27;, min_samples_leaf=5, n_jobs=-1,\n",
              "                      random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_features=&#x27;sqrt&#x27;, min_samples_leaf=5, n_jobs=-1,\n",
              "                      random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "rf_fast = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    min_samples_leaf=5,\n",
        "    max_features='sqrt',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_fast.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uDi4iBloB-MT",
      "metadata": {
        "id": "uDi4iBloB-MT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "b5ee287f-db60-4168-f96a-54c0a31bcc64"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "importance_df = pd.DataFrame({\n",
        "    'cols': X_train.columns,\n",
        "    'imp': rf_fast.feature_importances_\n",
        "}).sort_values('imp', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "importance_df.plot('cols', 'imp', 'barh', legend=False)\n",
        "plt.title('Importancia de características con objetivo- Random Forest')\n",
        "plt.xlabel('Importancia')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WAmUhj48ugPO",
      "metadata": {
        "id": "WAmUhj48ugPO"
      },
      "outputs": [],
      "source": [
        "# importance_df = pd.DataFrame({\n",
        "#     'feature': X_train.columns,\n",
        "#     'importance': rf.feature_importances_\n",
        "# }).sort_values('importance', ascending=False)\n",
        "\n",
        "# # Mostrar distribución de importancia\n",
        "# print(\"Distribución de importancia:\")\n",
        "# print(importance_df['importance'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7rhJfwgku4j3",
      "metadata": {
        "id": "7rhJfwgku4j3"
      },
      "outputs": [],
      "source": [
        "# threshold_percentile = 0.95  # Mantener top 5% más importante\n",
        "# threshold_value = importance_df['importance'].quantile(threshold_percentile)\n",
        "\n",
        "# selected_features = importance_df[importance_df['importance'] >= threshold_value]['feature'].tolist()\n",
        "\n",
        "# print(f\"\\n🔧 FILTRANDO CARACTERÍSTICAS:\")\n",
        "# print(f\"Total original: {len(importance_df)} características\")\n",
        "# print(f\"Seleccionadas: {len(selected_features)} características\")\n",
        "# print(f\"Umbral de importancia: {threshold_value:.4f}\")\n",
        "\n",
        "# # Filtrar datasets\n",
        "# X_train_filtered = X_train[selected_features]\n",
        "# X_val_filtered = X_val[selected_features]\n",
        "\n",
        "# print(f\"\\nCaracterísticas eliminadas: {len(importance_df) - len(selected_features)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4e2e129",
      "metadata": {
        "id": "c4e2e129",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad94815b-9e40-4f33-d108-3247211a208f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos listos: 2,759,904 ejemplos, 22 características\n"
          ]
        }
      ],
      "source": [
        "if y_train is not None and not X_train.empty:\n",
        "    print(f\"Datos listos: {X_train.shape[0]:,} ejemplos, {X_train.shape[1]} características\")\n",
        "else:\n",
        "    print(\"Problema con los datos\")\n",
        "    if not train_data.empty:\n",
        "        print(\"Columnas disponibles:\", train_data.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t4RgNPMXrF32",
      "metadata": {
        "id": "t4RgNPMXrF32"
      },
      "outputs": [],
      "source": [
        "# # Construir modelo de red neuronal\n",
        "# def build_model(input_dim, learning_rate=LEARNING_RATE):\n",
        "#     model = keras.Sequential([\n",
        "#         # Capa de entrada con regularización\n",
        "#         layers.Dense(512, activation='relu', input_shape=(input_dim,),\n",
        "#                     kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
        "#         layers.BatchNormalization(),\n",
        "#         layers.Dropout(0.3),\n",
        "\n",
        "#         # Capas ocultas\n",
        "#         layers.Dense(256, activation='relu',\n",
        "#                     kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
        "#         layers.BatchNormalization(),\n",
        "#         layers.Dropout(0.3),\n",
        "\n",
        "#         layers.Dense(128, activation='relu'),\n",
        "#         layers.Dropout(0.2),\n",
        "\n",
        "#         layers.Dense(64, activation='relu'),\n",
        "#         layers.Dropout(0.2),\n",
        "\n",
        "#         # Capa de salida\n",
        "#         layers.Dense(1, activation='linear')\n",
        "#     ])\n",
        "\n",
        "#     optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "#     model.compile(\n",
        "#         optimizer=optimizer,\n",
        "#         loss='mse',\n",
        "#         metrics=['mae', 'mse']\n",
        "#     )\n",
        "\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "090878ca",
      "metadata": {
        "id": "090878ca"
      },
      "outputs": [],
      "source": [
        "# # Entrenamiento de modelo\n",
        "# if y_train is not None and not X_train.empty and not y_train.isnull().all():\n",
        "\n",
        "#     # Escalado para redes neuronales\n",
        "#     scaler = StandardScaler()\n",
        "#     X_train_scaled = scaler.fit_transform(X_train)\n",
        "#     X_test_scaled = scaler.transform(X_test) if not X_test.empty else None\n",
        "#     X_val_scaled = scaler.transform(X_val) if not X_val.empty else None\n",
        "\n",
        "#     # Convertir a tensores TensorFlow para mejor rendimiento GPU\n",
        "#     train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train.values))\n",
        "#     train_dataset = train_dataset.batch(1024).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "#     if X_val_scaled is not None and y_val is not None:\n",
        "#         val_dataset = tf.data.Dataset.from_tensor_slices((X_val_scaled, y_val.values))\n",
        "#         val_dataset = val_dataset.batch(1024).prefetch(tf.data.AUTOTUNE)\n",
        "#     else:\n",
        "#         val_dataset = None\n",
        "\n",
        "#     # Construcción del modelo\n",
        "#     input_dim = X_train_scaled.shape[1]\n",
        "#     model = build_model(input_dim)\n",
        "\n",
        "#     print(\"Arquitectura del modelo:\")\n",
        "#     model.summary()\n",
        "\n",
        "#     # Callbacks para entrenamiento eficiente\n",
        "#     callbacks = [\n",
        "#         EarlyStopping(patience=15, restore_best_weights=True, verbose=1),\n",
        "#         ReduceLROnPlateau(factor=0.5, patience=10, verbose=1),\n",
        "#         keras.callbacks.TensorBoard(log_dir='./logs', profile_batch=0)\n",
        "#     ]\n",
        "\n",
        "#     # Entrenamiento\n",
        "#     print(\"Entrenando con GPU...\")\n",
        "\n",
        "#     history = model.fit(\n",
        "#         train_dataset,\n",
        "#         epochs=epochs,\n",
        "#         validation_data=val_dataset,\n",
        "#         callbacks=callbacks,\n",
        "#         verbose=1\n",
        "#     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fqAoXOIhLpc",
      "metadata": {
        "id": "5fqAoXOIhLpc"
      },
      "outputs": [],
      "source": [
        "# # Listas para almacenar resultados\n",
        "# fold_no = 1\n",
        "# acc_per_fold = []\n",
        "# loss_per_fold = []\n",
        "# precision_per_fold = []\n",
        "# recall_per_fold = []\n",
        "# f1_per_fold = []\n",
        "# mae_per_fold = []\n",
        "# r2_per_fold = []\n",
        "# histories = []\n",
        "# best_models = []\n",
        "# training_times = []\n",
        "\n",
        "# all_y_true = []\n",
        "# all_y_pred = []\n",
        "# all_y_pred_binary = []\n",
        "\n",
        "# # Preparar datos completos\n",
        "# X_train_full = X_train.values if hasattr(X_train, 'values') else X_train\n",
        "# y_train_full = y_train.values if hasattr(y_train, 'values') else y_train\n",
        "\n",
        "# # Configurar KFold\n",
        "# kf = KFold(n_splits=k_folds, shuffle=True, random_state=random_state)\n",
        "\n",
        "# # ------------------ BLOQUE K-FOLD REEMPLAZO (Pegar en lugar del existente) ------------------\n",
        "\n",
        "# # Asegurar OUTPUT_DIR existe\n",
        "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# # Listas ya inicializadas arriba: acc_per_fold, mae_per_fold, r2_per_fold, histories, best_models, training_times, all_y_true, all_y_pred, all_y_pred_binary\n",
        "\n",
        "# for train_index, val_index in kf.split(X_train_full, y_train_full):\n",
        "#     print(f\"\\n Entrenando Fold #{fold_no}...\")\n",
        "#     start_time = time.time()\n",
        "\n",
        "#     # Obtener datos de entrenamiento y validación para este fold\n",
        "#     X_train_fold, X_val_fold = X_train_full[train_index], X_train_full[val_index]\n",
        "#     y_train_fold, y_val_fold = y_train_full[train_index], y_train_full[val_index]\n",
        "\n",
        "#     print(f\"   Muestras entrenamiento: {len(X_train_fold):,}\")\n",
        "#     print(f\"   Muestras validación: {len(X_val_fold):,}\")\n",
        "\n",
        "#     # Escalado por fold (IMPORTANTE para evitar data leakage)\n",
        "#     scaler_fold = StandardScaler()\n",
        "#     X_train_scaled_fold = scaler_fold.fit_transform(X_train_fold)\n",
        "#     X_val_scaled_fold = scaler_fold.transform(X_val_fold)\n",
        "\n",
        "#     # Crear datasets optimizados para GPU\n",
        "#     train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled_fold, y_train_fold))\n",
        "#     train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "#     val_dataset = tf.data.Dataset.from_tensor_slices((X_val_scaled_fold, y_val_fold))\n",
        "#     val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "#     # Crear modelo usando la función build_model (centralizada)\n",
        "#     input_dim = X_train_scaled_fold.shape[1]\n",
        "#     model_fold = build_model(input_dim=input_dim, learning_rate=LEARNING_RATE)\n",
        "\n",
        "#     # Callbacks para este fold - GUARDADO DE PESOS (save_weights_only=True)\n",
        "#     checkpoint_path = os.path.join(OUTPUT_DIR, f'best_weights_fold_{fold_no}.weights.h5')\n",
        "#     callbacks = [\n",
        "#         tf.keras.callbacks.ModelCheckpoint(\n",
        "#             checkpoint_path,\n",
        "#             monitor='val_mae',           # optimizar MAE por ser tu métrica objetivo\n",
        "#             save_best_only=True,\n",
        "#             save_weights_only=True,\n",
        "#             mode='min',\n",
        "#             verbose=1\n",
        "#         ),\n",
        "#         tf.keras.callbacks.EarlyStopping(\n",
        "#             monitor='val_mae',\n",
        "#             patience=12,\n",
        "#             restore_best_weights=True,\n",
        "#             verbose=1\n",
        "#         ),\n",
        "#         tf.keras.callbacks.ReduceLROnPlateau(\n",
        "#             monitor='val_mae',\n",
        "#             factor=0.5,\n",
        "#             patience=6,\n",
        "#             min_lr=1e-6,\n",
        "#             verbose=1\n",
        "#         )\n",
        "#     ]\n",
        "\n",
        "#     # Entrenamiento del fold\n",
        "#     print(f\"   Iniciando entrenamiento ({epochs} épocas máx)...\")\n",
        "#     history = model_fold.fit(\n",
        "#         train_dataset,\n",
        "#         epochs=epochs,\n",
        "#         validation_data=val_dataset,\n",
        "#         callbacks=callbacks,\n",
        "#         verbose=1\n",
        "#     )\n",
        "\n",
        "#     # Guardar historial\n",
        "#     histories.append(history.history)\n",
        "\n",
        "#     # Cargar los mejores pesos guardados por ModelCheckpoint (si existen)\n",
        "#     if os.path.exists(checkpoint_path):\n",
        "#         try:\n",
        "#             model_fold.load_weights(checkpoint_path)\n",
        "#             print(f\"   Pesos cargados desde {checkpoint_path}\")\n",
        "#         except Exception as e:\n",
        "#             print(\"   Warning: fallo al cargar pesos con load_weights:\", e)\n",
        "\n",
        "#     # Evaluación sobre el conjunto de validación del fold\n",
        "#     print(f\"   Evaluando Fold #{fold_no}...\")\n",
        "#     # .evaluate devuelve [loss, mae, mse] si tu model.metrics definidas así\n",
        "#     val_metrics = model_fold.evaluate(X_val_scaled_fold, y_val_fold, verbose=0)\n",
        "#     # Intenta mapear métricas devueltas (loss, mae, mse) — si la firma cambia, ajusta índices\n",
        "#     try:\n",
        "#         val_loss = float(val_metrics[0])\n",
        "#         val_mae = float(val_metrics[1]) if len(val_metrics) > 1 else mean_absolute_error(y_val_fold, model_fold.predict(X_val_scaled_fold).ravel())\n",
        "#     except Exception:\n",
        "#         val_loss = float(val_metrics)\n",
        "#         val_mae = mean_absolute_error(y_val_fold, model_fold.predict(X_val_scaled_fold).ravel())\n",
        "\n",
        "#     # Predicciones para métricas adicionales\n",
        "#     y_val_pred = model_fold.predict(X_val_scaled_fold, verbose=0).flatten()\n",
        "\n",
        "#     # Acumular predicciones y etiquetas reales (como listas)\n",
        "#     all_y_true.extend(np.array(y_val_fold).ravel().tolist())\n",
        "#     all_y_pred.extend(y_val_pred.ravel().tolist())\n",
        "\n",
        "#     # Calcular métricas sklearn\n",
        "#     from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "#     val_mae_sk = mean_absolute_error(y_val_fold, y_val_pred)\n",
        "#     val_mse_sk = mean_squared_error(y_val_fold, y_val_pred)\n",
        "#     val_r2 = r2_score(y_val_fold, y_val_pred)\n",
        "\n",
        "#     # Determinar si es clasificación binaria (usando unique en y_train_full)\n",
        "#     unique_values = np.unique(y_train_full)\n",
        "#     if len(unique_values) == 2 and np.max(unique_values) == 1 and np.min(unique_values) == 0:\n",
        "#         # Clasificación binaria: convertir por umbral (0.5)\n",
        "#         from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "#         y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
        "#         all_y_pred_binary.extend(y_val_pred_binary.tolist())\n",
        "\n",
        "#         val_acc = accuracy_score(y_val_fold, y_val_pred_binary)\n",
        "#         val_precision = precision_score(y_val_fold, y_val_pred_binary, average='binary', zero_division=0)\n",
        "#         val_recall = recall_score(y_val_fold, y_val_pred_binary, average='binary', zero_division=0)\n",
        "#         val_f1 = f1_score(y_val_fold, y_val_pred_binary, average='binary', zero_division=0)\n",
        "#     else:\n",
        "#         # Regresión - usar R² como \"acc\" placeholder para reporting (como hacías antes)\n",
        "#         val_acc = val_r2\n",
        "#         val_precision = val_r2\n",
        "#         val_recall = val_r2\n",
        "#         val_f1 = val_r2\n",
        "\n",
        "#     # Medir tiempo\n",
        "#     training_time = time.time() - start_time\n",
        "#     training_times.append(training_time)\n",
        "\n",
        "#     # Mostrar resultados\n",
        "#     print(f\"\\n    Resultados Fold #{fold_no}:\")\n",
        "#     print(f\"      Tiempo entrenamiento: {training_time:.2f}s\")\n",
        "#     print(f\"      Loss (reported): {val_loss:.4f}\")\n",
        "#     print(f\"      MAE (sklearn): {val_mae_sk:.4f}\")\n",
        "#     print(f\"      R²: {val_r2:.4f}\")\n",
        "\n",
        "#     if len(unique_values) == 2:\n",
        "#         print(f\"      Accuracy: {val_acc:.4f}\")\n",
        "#         print(f\"      Precision: {val_precision:.4f}\")\n",
        "#         print(f\"      Recall: {val_recall:.4f}\")\n",
        "#         print(f\"      F1-Score: {val_f1:.4f}\")\n",
        "\n",
        "#     # Guardar resultados en listas\n",
        "#     acc_per_fold.append(val_acc)\n",
        "#     loss_per_fold.append(val_loss)\n",
        "#     precision_per_fold.append(val_precision)\n",
        "#     recall_per_fold.append(val_recall)\n",
        "#     f1_per_fold.append(val_f1)\n",
        "#     mae_per_fold.append(val_mae_sk)\n",
        "#     r2_per_fold.append(val_r2)\n",
        "\n",
        "#     # Guardar la ruta de los mejores pesos de este fold (no el objeto modelo)\n",
        "#     best_models.append(checkpoint_path)\n",
        "\n",
        "#     # Guardar el scaler de este fold\n",
        "#     import joblib\n",
        "#     joblib.dump(scaler_fold, os.path.join(OUTPUT_DIR, f'scaler_fold_{fold_no}.pkl'))\n",
        "\n",
        "#     # Limpieza de memoria\n",
        "#     del model_fold, scaler_fold\n",
        "#     tf.keras.backend.clear_session()\n",
        "#     import gc\n",
        "#     gc.collect()\n",
        "\n",
        "#     fold_no += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Función para matriz de confusión\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# def plot_confusion_from_preds(y_true_list, y_pred_list, method='auto', threshold=None, bins=None,\n",
        "#                               normalize=False, show_custom_plot=True, save_path=None):\n",
        "\n",
        "#     import pandas as pd\n",
        "#     y_true = np.array(y_true_list).ravel()\n",
        "#     y_pred = np.array(y_pred_list).ravel()\n",
        "#     if len(y_true) != len(y_pred):\n",
        "#         raise ValueError(\"y_true y y_pred deben tener la misma longitud\")\n",
        "\n",
        "#     if bins is not None:\n",
        "#         y_true_bin = pd.cut(y_true, bins=bins, labels=False)\n",
        "#         y_pred_bin = pd.cut(y_pred, bins=bins, labels=False)\n",
        "#         labels = np.unique(np.concatenate([y_true_bin, y_pred_bin]))\n",
        "#     else:\n",
        "#         if threshold is None:\n",
        "#             if set(np.unique(y_true)).issubset({0,1}):\n",
        "#                 threshold = 0.5\n",
        "#             else:\n",
        "#                 threshold = np.median(y_true)\n",
        "#         y_true_bin = (y_true >= threshold).astype(int)\n",
        "#         y_pred_bin = (y_pred >= threshold).astype(int)\n",
        "#         labels = np.array([0,1])\n",
        "\n",
        "#     # Matrices\n",
        "#     cm_norm = confusion_matrix(y_true_bin, y_pred_bin, labels=labels, normalize='pred' if normalize else None)\n",
        "#     cm_raw = confusion_matrix(y_true_bin, y_pred_bin, labels=labels, normalize=None)\n",
        "\n",
        "#     # Reporte\n",
        "#     print(f\"Muestras: {len(y_true)} -- Método: {method} -- threshold: {threshold}\")\n",
        "#     try:\n",
        "#         print(\"\\nClassification report (sobre clases discretizadas):\\n\")\n",
        "#         print(classification_report(y_true_bin, y_pred_bin, zero_division=0))\n",
        "#     except Exception as e:\n",
        "#         print(\"No se pudo generar classification_report:\", e)\n",
        "\n",
        "#     if len(labels) == 2:\n",
        "#         tn, fp, fn, tp = cm_raw.ravel()\n",
        "#         acc = accuracy_score(y_true_bin, y_pred_bin)\n",
        "#         prec = precision_score(y_true_bin, y_pred_bin, zero_division=0)\n",
        "#         rec = recall_score(y_true_bin, y_pred_bin, zero_division=0)\n",
        "#         f1 = f1_score(y_true_bin, y_pred_bin, zero_division=0)\n",
        "#         print(f\"TP={tp}, FP={fp}, FN={fn}, TN={tn}\")\n",
        "#         print(f\"Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
        "#     else:\n",
        "#         print(\"Multiclase detectado. Mostrar conteos por clase en la matriz.\")\n",
        "\n",
        "#     # Heatmap\n",
        "#     plt.figure(figsize=(6,5))\n",
        "#     target_cm = cm_norm if (normalize and cm_norm is not None) else cm_raw\n",
        "#     fmt = '.2f' if normalize else 'd'\n",
        "#     sns.heatmap(target_cm, annot=True, fmt=fmt, xticklabels=labels, yticklabels=labels, cmap='Blues')\n",
        "#     plt.xlabel('Predicción')\n",
        "#     plt.ylabel('Real')\n",
        "#     plt.title(f'Matriz de confusión ({len(y_true)} muestras)')\n",
        "#     if save_path:\n",
        "#         plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
        "#         print(f\"Figura guardada en: {save_path}\")\n",
        "#     plt.show()\n",
        "\n",
        "#     if show_custom_plot and len(labels) == 2:\n",
        "#         tn, fp, fn, tp = cm_raw.ravel()\n",
        "#         def plot_custom_2x2(tp, fp, fn, tn, title='Matriz de confusión personalizada'):\n",
        "#             mat = np.array([[tp, fp],[fn, tn]])\n",
        "#             colors = np.array([['#3a7a2e', '#d22b2b'], ['#d22b2b', '#3a7a2e']])\n",
        "#             fig, ax = plt.subplots(figsize=(6,6))\n",
        "#             for i in range(2):\n",
        "#                 for j in range(2):\n",
        "#                     ax.add_patch(plt.Rectangle((j, 1-i), 1, 1, color=colors[i,j], ec='navy', lw=1))\n",
        "#                     if i==0 and j==0:\n",
        "#                         text = f\"Verdaderos\\nPositivos\\n\\n{mat[i,j]}\"\n",
        "#                     elif i==0 and j==1:\n",
        "#                         text = f\"Falsos\\nPositivos\\n\\n{mat[i,j]}\"\n",
        "#                     elif i==1 and j==0:\n",
        "#                         text = f\"Falsos\\nNegativos\\n\\n{mat[i,j]}\"\n",
        "#                     else:\n",
        "#                         text = f\"Verdaderos\\nNegativos\\n\\n{mat[i,j]}\"\n",
        "#                     ax.text(j+0.5, 1-i+0.5, text, ha='center', va='center', color='white', fontsize=14)\n",
        "#             ax.set_xlim(0,2); ax.set_ylim(0,2)\n",
        "#             ax.set_xticks([0.5, 1.5]); ax.set_xticklabels(['VALORES REALES\\nPositivo','VALORES REALES\\nNegativo'], fontsize=10)\n",
        "#             ax.set_yticks([1.5, 0.5]); ax.set_yticklabels(['VALORES PREDICCIÓN\\nPositivo','VALORES PREDICCIÓN\\nNegativo'], fontsize=10)\n",
        "#             ax.invert_yaxis()\n",
        "#             ax.set_title(title, pad=20)\n",
        "#             ax.axis('off')\n",
        "#             plt.show()\n",
        "#         plot_custom_2x2(tp=tp, fp=fp, fn=fn, tn=tn)\n",
        "\n",
        "#     return {'cm': cm_raw, 'cm_norm': cm_norm, 'labels': labels, 'y_true_bin': y_true_bin, 'y_pred_bin': y_pred_bin}\n",
        "\n",
        "# # Ejecución automática si detecta listas globales con nombres comunes\n",
        "# try:\n",
        "#     if 'all_y_true' in globals() and 'all_y_pred' in globals():\n",
        "#         print(\"Ejecutando plot_confusion_from_preds con all_y_true / all_y_pred del notebook...\")\n",
        "#         _ = plot_confusion_from_preds(all_y_true, all_y_pred, method='auto', threshold=None, bins=None, normalize=False, show_custom_plot=True)\n",
        "#     else:\n",
        "#         print(\"No se detectaron all_y_true/all_y_pred en globals(). Llama a plot_confusion_from_preds manualmente.\")\n",
        "# except Exception as e:\n",
        "#     print(\"Error al ejecutar la función automáticamente:\", e)\n"
      ],
      "metadata": {
        "id": "tlhDdV-KlhWq"
      },
      "id": "tlhDdV-KlhWq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zdWimo9okSFw",
      "metadata": {
        "id": "zdWimo9okSFw"
      },
      "outputs": [],
      "source": [
        "# print(unique_values)\n",
        "# print(y_train_full)\n",
        "# print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JaLGSqbdjcjz",
      "metadata": {
        "id": "JaLGSqbdjcjz"
      },
      "outputs": [],
      "source": [
        "# print(\"\\n\" + \"=\"*70)\n",
        "# print(\" RESUMEN FINAL K-FOLD CROSS VALIDATION\")\n",
        "# print(\"=\"*70)\n",
        "\n",
        "# print(f\" Precisión/R² promedio: {np.mean(acc_per_fold):.4f} (+/- {np.std(acc_per_fold):.4f})\")\n",
        "# print(f\" Loss promedio: {np.mean(loss_per_fold):.4f} (+/- {np.std(loss_per_fold):.4f})\")\n",
        "# print(f\" MAE promedio: {np.mean(mae_per_fold):.4f} (+/- {np.std(mae_per_fold):.4f})\")\n",
        "# print(f\" R² promedio: {np.mean(r2_per_fold):.4f} (+/- {np.std(r2_per_fold):.4f})\")\n",
        "# print(f\" Tiempo promedio por fold: {np.mean(training_times):.2f}s\")\n",
        "\n",
        "# if len(np.unique(y_train_full)) == 2:\n",
        "#     print(f\" Precision promedio: {np.mean(precision_per_fold):.4f} (+/- {np.std(precision_per_fold):.4f})\")\n",
        "#     print(f\" Recall promedio: {np.mean(recall_per_fold):.4f} (+/- {np.std(recall_per_fold):.4f})\")\n",
        "#     print(f\" F1-Score promedio: {np.mean(f1_per_fold):.4f} (+/- {np.std(f1_per_fold):.4f})\")\n",
        "\n",
        "# print(f\"\\n Métricas por Fold:\")\n",
        "# for i, (acc, loss, mae, r2) in enumerate(zip(acc_per_fold, loss_per_fold, mae_per_fold, r2_per_fold), 1):\n",
        "#     if len(np.unique(y_train_full)) == 2:\n",
        "#         prec = precision_per_fold[i-1]\n",
        "#         rec = recall_per_fold[i-1]\n",
        "#         f1 = f1_per_fold[i-1]\n",
        "#         print(f\"  Fold {i}: Acc={acc:.4f}, Loss={loss:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}\")\n",
        "#     else:\n",
        "#         print(f\"  Fold {i}: R²={r2:.4f}, Loss={loss:.4f}, MAE={mae:.4f}\")\n",
        "\n",
        "# # Análisis de estabilidad\n",
        "# acc_std = np.std(acc_per_fold)\n",
        "# print(f\"\\n ANÁLISIS DE ESTABILIDAD:\")\n",
        "# print(f\"   Desviación estándar entre folds: {acc_std:.4f}\")\n",
        "\n",
        "# if acc_std < 0.02:\n",
        "#     print(\"   Modelo muy estable - Excelente consistencia entre folds\")\n",
        "# elif acc_std < 0.05:\n",
        "#     print(\"   Modelo estable - Buena consistencia\")\n",
        "# elif acc_std < 0.1:\n",
        "#     print(\"    Modelo moderadamente estable\")\n",
        "# else:\n",
        "#     print(\"    Modelo muestra alta variabilidad - Revisar datos/arquitectura\")\n",
        "\n",
        "# # MATRIZ DE CONFUSIÓN AGREGADA (si es clasificación binaria)\n",
        "# if len(np.unique(y_train_full)) == 2 and len(y_true_agg) > 0:\n",
        "#     try:\n",
        "#         y_true_all = np.concatenate(y_true_agg)\n",
        "#         y_pred_all = np.concatenate(y_pred_agg)\n",
        "#         cm_all = confusion_matrix(y_true_all, y_pred_all)\n",
        "#         print(\"\\nMatriz de confusión agregada (todos los folds):\")\n",
        "#         print(cm_all)\n",
        "\n",
        "#         try:\n",
        "#             plt.figure(figsize=(6,5))\n",
        "#             sns.heatmap(cm_all, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "#             plt.title('Confusion Matrix - All Folds')\n",
        "#             plt.xlabel('Predicted')\n",
        "#             plt.ylabel('Actual')\n",
        "#             plt.tight_layout()\n",
        "#             plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_all_folds.png'))\n",
        "#             plt.close()\n",
        "#             print(f\"  Matriz agregada guardada en: {os.path.join(OUTPUT_DIR, 'confusion_all_folds.png')}\")\n",
        "#         except Exception as e:\n",
        "#             print(f\"  No se pudo generar el gráfico de la matriz agregada: {e}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"  Error calculando matriz de confusión agregada: {e}\")\n",
        "\n",
        "# # Guardar resultados en variables globales para uso posterior\n",
        "# kfold_results = {\n",
        "#     'acc_scores': acc_per_fold,\n",
        "#     'loss_scores': loss_per_fold,\n",
        "#     'precision_scores': precision_per_fold,\n",
        "#     'recall_scores': recall_per_fold,\n",
        "#     'f1_scores': f1_per_fold,\n",
        "#     'mae_scores': mae_per_fold,\n",
        "#     'r2_scores': r2_per_fold,\n",
        "#     'histories': histories,\n",
        "#     'best_models': best_models,\n",
        "#     'training_times': training_times\n",
        "# }\n",
        "\n",
        "# print(f\"\\n K-Fold completado exitosamente!\")\n",
        "# print(f\" Modelos guardados en: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento de modelo LightGBM\n",
        "\n",
        "# X_sub, X_val_sub, y_sub, y_val_sub = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# dtrain = lgb.Dataset(X_sub, label=y_sub)\n",
        "# dvalid = lgb.Dataset(X_val_sub, label=y_val_sub, reference=dtrain)\n",
        "\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'mae',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'learning_rate': 0.03,\n",
        "    'num_leaves': 127,\n",
        "    'max_depth': -1,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'min_data_in_leaf': 50,\n",
        "    'lambda_l1': 0.0,\n",
        "    'lambda_l2': 1.0,\n",
        "    'verbose': -1\n",
        "    # 'objective':'regression',\n",
        "    # 'metric':'mae',\n",
        "    # 'learning_rate': 0.03,\n",
        "    # 'num_leaves': 127,\n",
        "    # 'max_depth': 12,\n",
        "    # 'min_data_in_leaf': 50,\n",
        "    # 'feature_fraction': 0.8,\n",
        "    # 'bagging_fraction': 0.8,\n",
        "    # 'verbose': -1\n",
        "\n",
        "}\n",
        "\n",
        "# bst = lgb.train(\n",
        "#     params,\n",
        "#     dtrain,\n",
        "#     num_boost_round=5000,\n",
        "#     valid_sets=[dtrain, dvalid],\n",
        "#     valid_names=['train','valid'],\n",
        "#     callbacks=[\n",
        "#         lgb.early_stopping(stopping_rounds=100),\n",
        "#         lgb.log_evaluation(period=100)\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# y_pred = bst.predict(X_val_sub, num_iteration=bst.best_iteration)\n",
        "# print(\"MAE\", mean_absolute_error(y_val_sub, y_pred), \"R2\", r2_score(y_val_sub, y_pred))\n"
      ],
      "metadata": {
        "id": "iso0OAqtVOpm",
        "collapsed": true
      },
      "id": "iso0OAqtVOpm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = []\n",
        "mae_scores = []\n",
        "r2_scores = []\n",
        "oof_predictions = np.zeros(len(X_train))"
      ],
      "metadata": {
        "id": "dooX7MNXu5ee"
      },
      "id": "dooX7MNXu5ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Iniciando entrenamiento con {k_folds}-Fold Cross-Validation\\n\")\n",
        "\n",
        "# Iteración sobre cada fold\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Fold {fold}/{k_folds}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Dividir datos\n",
        "    X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    # Crear datasets de LightGBM\n",
        "    dtrain = lgb.Dataset(X_fold_train, label=y_fold_train)\n",
        "    dvalid = lgb.Dataset(X_fold_val, label=y_fold_val, reference=dtrain)\n",
        "\n",
        "    # Entrenar modelo\n",
        "    bst = lgb.train(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=5000,\n",
        "        valid_sets=[dtrain, dvalid],\n",
        "        valid_names=['train', 'valid'],\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping_rounds=100),\n",
        "            lgb.log_evaluation(period=100)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Predicciones en validación\n",
        "    y_pred = bst.predict(X_fold_val, num_iteration=bst.best_iteration)\n",
        "\n",
        "    # Guardar predicciones out-of-fold\n",
        "    oof_predictions[val_idx] = y_pred\n",
        "\n",
        "    # Calcular métricas\n",
        "    mae = mean_absolute_error(y_fold_val, y_pred)\n",
        "    r2 = r2_score(y_fold_val, y_pred)\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    r2_scores.append(r2)\n",
        "    models.append(bst)\n",
        "\n",
        "    print(f\"\\nFold {fold} - MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
        "    print(f\"Best iteration: {bst.best_iteration}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ9MMg7Lu8tw",
        "outputId": "4fd83098-02ba-4516-c4d2-6668ffdbbe1f"
      },
      "id": "HZ9MMg7Lu8tw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando entrenamiento con 5-Fold Cross-Validation\n",
            "\n",
            "============================================================\n",
            "Fold 1/5\n",
            "============================================================\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttrain's l1: 0.686579\tvalid's l1: 0.688271\n",
            "[200]\ttrain's l1: 0.59947\tvalid's l1: 0.602109\n",
            "[300]\ttrain's l1: 0.558775\tvalid's l1: 0.562049\n",
            "[400]\ttrain's l1: 0.532848\tvalid's l1: 0.536759\n",
            "[500]\ttrain's l1: 0.51358\tvalid's l1: 0.518132\n",
            "[600]\ttrain's l1: 0.498675\tvalid's l1: 0.503874\n",
            "[700]\ttrain's l1: 0.486883\tvalid's l1: 0.492668\n",
            "[800]\ttrain's l1: 0.476906\tvalid's l1: 0.483191\n",
            "[900]\ttrain's l1: 0.467963\tvalid's l1: 0.47484\n",
            "[1000]\ttrain's l1: 0.459862\tvalid's l1: 0.467238\n",
            "[1100]\ttrain's l1: 0.452947\tvalid's l1: 0.460864\n",
            "[1200]\ttrain's l1: 0.44649\tvalid's l1: 0.454921\n",
            "[1300]\ttrain's l1: 0.440312\tvalid's l1: 0.449258\n",
            "[1400]\ttrain's l1: 0.434639\tvalid's l1: 0.444036\n",
            "[1500]\ttrain's l1: 0.429604\tvalid's l1: 0.439505\n",
            "[1600]\ttrain's l1: 0.425245\tvalid's l1: 0.435635\n",
            "[1700]\ttrain's l1: 0.420538\tvalid's l1: 0.431385\n",
            "[1800]\ttrain's l1: 0.416301\tvalid's l1: 0.427624\n",
            "[1900]\ttrain's l1: 0.412192\tvalid's l1: 0.423983\n",
            "[2000]\ttrain's l1: 0.408496\tvalid's l1: 0.420738\n",
            "[2100]\ttrain's l1: 0.405185\tvalid's l1: 0.417889\n",
            "[2200]\ttrain's l1: 0.401793\tvalid's l1: 0.414946\n",
            "[2300]\ttrain's l1: 0.398521\tvalid's l1: 0.412126\n",
            "[2400]\ttrain's l1: 0.395535\tvalid's l1: 0.409586\n",
            "[2500]\ttrain's l1: 0.39281\tvalid's l1: 0.407328\n",
            "[2600]\ttrain's l1: 0.389971\tvalid's l1: 0.40494\n",
            "[2700]\ttrain's l1: 0.387417\tvalid's l1: 0.402838\n",
            "[2800]\ttrain's l1: 0.384305\tvalid's l1: 0.400177\n",
            "[2900]\ttrain's l1: 0.381471\tvalid's l1: 0.397788\n",
            "[3000]\ttrain's l1: 0.378829\tvalid's l1: 0.395538\n",
            "[3100]\ttrain's l1: 0.37647\tvalid's l1: 0.393597\n",
            "[3200]\ttrain's l1: 0.373958\tvalid's l1: 0.391484\n",
            "[3300]\ttrain's l1: 0.371522\tvalid's l1: 0.389448\n",
            "[3400]\ttrain's l1: 0.369243\tvalid's l1: 0.387558\n",
            "[3500]\ttrain's l1: 0.366914\tvalid's l1: 0.385606\n",
            "[3600]\ttrain's l1: 0.36457\tvalid's l1: 0.383687\n",
            "[3700]\ttrain's l1: 0.362606\tvalid's l1: 0.382126\n",
            "[3800]\ttrain's l1: 0.360473\tvalid's l1: 0.380384\n",
            "[3900]\ttrain's l1: 0.358481\tvalid's l1: 0.378769\n",
            "[4000]\ttrain's l1: 0.356489\tvalid's l1: 0.377147\n",
            "[4100]\ttrain's l1: 0.354686\tvalid's l1: 0.375721\n",
            "[4200]\ttrain's l1: 0.353102\tvalid's l1: 0.374521\n",
            "[4300]\ttrain's l1: 0.351242\tvalid's l1: 0.37303\n",
            "[4400]\ttrain's l1: 0.349459\tvalid's l1: 0.371629\n",
            "[4500]\ttrain's l1: 0.347871\tvalid's l1: 0.370415\n",
            "[4600]\ttrain's l1: 0.346429\tvalid's l1: 0.369362\n",
            "[4700]\ttrain's l1: 0.344984\tvalid's l1: 0.36828\n",
            "[4800]\ttrain's l1: 0.34321\tvalid's l1: 0.366865\n",
            "[4900]\ttrain's l1: 0.341698\tvalid's l1: 0.365715\n",
            "[5000]\ttrain's l1: 0.340021\tvalid's l1: 0.364401\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttrain's l1: 0.340021\tvalid's l1: 0.364401\n",
            "\n",
            "Fold 1 - MAE: 0.3644, R²: 0.8233\n",
            "Best iteration: 5000\n",
            "\n",
            "============================================================\n",
            "Fold 2/5\n",
            "============================================================\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttrain's l1: 0.684421\tvalid's l1: 0.685673\n",
            "[200]\ttrain's l1: 0.596704\tvalid's l1: 0.599024\n",
            "[300]\ttrain's l1: 0.557487\tvalid's l1: 0.5604\n",
            "[400]\ttrain's l1: 0.532388\tvalid's l1: 0.535957\n",
            "[500]\ttrain's l1: 0.513316\tvalid's l1: 0.517503\n",
            "[600]\ttrain's l1: 0.498452\tvalid's l1: 0.503242\n",
            "[700]\ttrain's l1: 0.486867\tvalid's l1: 0.492243\n",
            "[800]\ttrain's l1: 0.476818\tvalid's l1: 0.4828\n",
            "[900]\ttrain's l1: 0.468568\tvalid's l1: 0.475132\n",
            "[1000]\ttrain's l1: 0.461039\tvalid's l1: 0.468122\n",
            "[1100]\ttrain's l1: 0.453887\tvalid's l1: 0.461479\n",
            "[1200]\ttrain's l1: 0.447734\tvalid's l1: 0.455842\n",
            "[1300]\ttrain's l1: 0.441752\tvalid's l1: 0.45037\n",
            "[1400]\ttrain's l1: 0.435746\tvalid's l1: 0.444882\n",
            "[1500]\ttrain's l1: 0.430349\tvalid's l1: 0.439965\n",
            "[1600]\ttrain's l1: 0.425211\tvalid's l1: 0.435303\n",
            "[1700]\ttrain's l1: 0.420939\tvalid's l1: 0.431493\n",
            "[1800]\ttrain's l1: 0.416791\tvalid's l1: 0.427837\n",
            "[1900]\ttrain's l1: 0.412449\tvalid's l1: 0.423954\n",
            "[2000]\ttrain's l1: 0.408844\tvalid's l1: 0.420828\n",
            "[2100]\ttrain's l1: 0.405223\tvalid's l1: 0.417651\n",
            "[2200]\ttrain's l1: 0.401544\tvalid's l1: 0.414417\n",
            "[2300]\ttrain's l1: 0.398386\tvalid's l1: 0.411728\n",
            "[2400]\ttrain's l1: 0.395405\tvalid's l1: 0.409212\n",
            "[2500]\ttrain's l1: 0.392307\tvalid's l1: 0.406559\n",
            "[2600]\ttrain's l1: 0.389483\tvalid's l1: 0.404172\n",
            "[2700]\ttrain's l1: 0.386596\tvalid's l1: 0.401706\n",
            "[2800]\ttrain's l1: 0.383859\tvalid's l1: 0.399378\n",
            "[2900]\ttrain's l1: 0.381315\tvalid's l1: 0.397258\n",
            "[3000]\ttrain's l1: 0.378408\tvalid's l1: 0.39479\n",
            "[3100]\ttrain's l1: 0.375994\tvalid's l1: 0.392781\n",
            "[3200]\ttrain's l1: 0.373338\tvalid's l1: 0.39051\n",
            "[3300]\ttrain's l1: 0.371119\tvalid's l1: 0.388706\n",
            "[3400]\ttrain's l1: 0.369098\tvalid's l1: 0.387064\n",
            "[3500]\ttrain's l1: 0.366747\tvalid's l1: 0.385109\n",
            "[3600]\ttrain's l1: 0.364528\tvalid's l1: 0.383304\n",
            "[3700]\ttrain's l1: 0.362559\tvalid's l1: 0.381742\n",
            "[3800]\ttrain's l1: 0.360324\tvalid's l1: 0.379892\n",
            "[3900]\ttrain's l1: 0.358422\tvalid's l1: 0.378371\n",
            "[4000]\ttrain's l1: 0.356391\tvalid's l1: 0.376726\n",
            "[4100]\ttrain's l1: 0.354575\tvalid's l1: 0.37529\n",
            "[4200]\ttrain's l1: 0.352329\tvalid's l1: 0.373394\n",
            "[4300]\ttrain's l1: 0.35063\tvalid's l1: 0.372089\n",
            "[4400]\ttrain's l1: 0.348921\tvalid's l1: 0.370733\n",
            "[4500]\ttrain's l1: 0.34729\tvalid's l1: 0.369491\n",
            "[4600]\ttrain's l1: 0.345658\tvalid's l1: 0.368185\n",
            "[4700]\ttrain's l1: 0.343887\tvalid's l1: 0.366783\n",
            "[4800]\ttrain's l1: 0.342322\tvalid's l1: 0.365582\n",
            "[4900]\ttrain's l1: 0.340918\tvalid's l1: 0.364551\n",
            "[5000]\ttrain's l1: 0.339165\tvalid's l1: 0.363132\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttrain's l1: 0.339165\tvalid's l1: 0.363132\n",
            "\n",
            "Fold 2 - MAE: 0.3631, R²: 0.8242\n",
            "Best iteration: 5000\n",
            "\n",
            "============================================================\n",
            "Fold 3/5\n",
            "============================================================\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttrain's l1: 0.684245\tvalid's l1: 0.686613\n",
            "[200]\ttrain's l1: 0.598334\tvalid's l1: 0.601273\n",
            "[300]\ttrain's l1: 0.557363\tvalid's l1: 0.560884\n",
            "[400]\ttrain's l1: 0.531274\tvalid's l1: 0.535302\n",
            "[500]\ttrain's l1: 0.511925\tvalid's l1: 0.516557\n",
            "[600]\ttrain's l1: 0.497072\tvalid's l1: 0.502308\n",
            "[700]\ttrain's l1: 0.486423\tvalid's l1: 0.49225\n",
            "[800]\ttrain's l1: 0.47644\tvalid's l1: 0.482847\n",
            "[900]\ttrain's l1: 0.468016\tvalid's l1: 0.474976\n",
            "[1000]\ttrain's l1: 0.460262\tvalid's l1: 0.467771\n",
            "[1100]\ttrain's l1: 0.45272\tvalid's l1: 0.46073\n",
            "[1200]\ttrain's l1: 0.446757\tvalid's l1: 0.455308\n",
            "[1300]\ttrain's l1: 0.440963\tvalid's l1: 0.450016\n",
            "[1400]\ttrain's l1: 0.4355\tvalid's l1: 0.445053\n",
            "[1500]\ttrain's l1: 0.430394\tvalid's l1: 0.440451\n",
            "[1600]\ttrain's l1: 0.425605\tvalid's l1: 0.436115\n",
            "[1700]\ttrain's l1: 0.421167\tvalid's l1: 0.432154\n",
            "[1800]\ttrain's l1: 0.416998\tvalid's l1: 0.428462\n",
            "[1900]\ttrain's l1: 0.41312\tvalid's l1: 0.425097\n",
            "[2000]\ttrain's l1: 0.409556\tvalid's l1: 0.421988\n",
            "[2100]\ttrain's l1: 0.406046\tvalid's l1: 0.418928\n",
            "[2200]\ttrain's l1: 0.402799\tvalid's l1: 0.416124\n",
            "[2300]\ttrain's l1: 0.399262\tvalid's l1: 0.413014\n",
            "[2400]\ttrain's l1: 0.395815\tvalid's l1: 0.409998\n",
            "[2500]\ttrain's l1: 0.392906\tvalid's l1: 0.407541\n",
            "[2600]\ttrain's l1: 0.390359\tvalid's l1: 0.405423\n",
            "[2700]\ttrain's l1: 0.38763\tvalid's l1: 0.403129\n",
            "[2800]\ttrain's l1: 0.384694\tvalid's l1: 0.400609\n",
            "[2900]\ttrain's l1: 0.382112\tvalid's l1: 0.398446\n",
            "[3000]\ttrain's l1: 0.37963\tvalid's l1: 0.396381\n",
            "[3100]\ttrain's l1: 0.377108\tvalid's l1: 0.394265\n",
            "[3200]\ttrain's l1: 0.374654\tvalid's l1: 0.392223\n",
            "[3300]\ttrain's l1: 0.372117\tvalid's l1: 0.390096\n",
            "[3400]\ttrain's l1: 0.370003\tvalid's l1: 0.388392\n",
            "[3500]\ttrain's l1: 0.367864\tvalid's l1: 0.386647\n",
            "[3600]\ttrain's l1: 0.365681\tvalid's l1: 0.384871\n",
            "[3700]\ttrain's l1: 0.363492\tvalid's l1: 0.383088\n",
            "[3800]\ttrain's l1: 0.36154\tvalid's l1: 0.381518\n",
            "[3900]\ttrain's l1: 0.359327\tvalid's l1: 0.37968\n",
            "[4000]\ttrain's l1: 0.357325\tvalid's l1: 0.378055\n",
            "[4100]\ttrain's l1: 0.355342\tvalid's l1: 0.376451\n",
            "[4200]\ttrain's l1: 0.353426\tvalid's l1: 0.374917\n",
            "[4300]\ttrain's l1: 0.351638\tvalid's l1: 0.373513\n",
            "[4400]\ttrain's l1: 0.349921\tvalid's l1: 0.372166\n",
            "[4500]\ttrain's l1: 0.348099\tvalid's l1: 0.370706\n",
            "[4600]\ttrain's l1: 0.346435\tvalid's l1: 0.369398\n",
            "[4700]\ttrain's l1: 0.34484\tvalid's l1: 0.368162\n",
            "[4800]\ttrain's l1: 0.343287\tvalid's l1: 0.366955\n",
            "[4900]\ttrain's l1: 0.341745\tvalid's l1: 0.365787\n",
            "[5000]\ttrain's l1: 0.339931\tvalid's l1: 0.364339\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttrain's l1: 0.339931\tvalid's l1: 0.364339\n",
            "\n",
            "Fold 3 - MAE: 0.3643, R²: 0.8244\n",
            "Best iteration: 5000\n",
            "\n",
            "============================================================\n",
            "Fold 4/5\n",
            "============================================================\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttrain's l1: 0.687424\tvalid's l1: 0.68897\n",
            "[200]\ttrain's l1: 0.595463\tvalid's l1: 0.597855\n",
            "[300]\ttrain's l1: 0.556127\tvalid's l1: 0.559246\n",
            "[400]\ttrain's l1: 0.530209\tvalid's l1: 0.533892\n",
            "[500]\ttrain's l1: 0.511774\tvalid's l1: 0.516044\n",
            "[600]\ttrain's l1: 0.497118\tvalid's l1: 0.501898\n",
            "[700]\ttrain's l1: 0.48594\tvalid's l1: 0.491357\n",
            "[800]\ttrain's l1: 0.475092\tvalid's l1: 0.48104\n",
            "[900]\ttrain's l1: 0.466696\tvalid's l1: 0.473185\n",
            "[1000]\ttrain's l1: 0.458195\tvalid's l1: 0.465221\n",
            "[1100]\ttrain's l1: 0.451309\tvalid's l1: 0.458842\n",
            "[1200]\ttrain's l1: 0.44516\tvalid's l1: 0.453219\n",
            "[1300]\ttrain's l1: 0.439173\tvalid's l1: 0.447755\n",
            "[1400]\ttrain's l1: 0.433999\tvalid's l1: 0.443088\n",
            "[1500]\ttrain's l1: 0.429305\tvalid's l1: 0.438901\n",
            "[1600]\ttrain's l1: 0.424229\tvalid's l1: 0.434304\n",
            "[1700]\ttrain's l1: 0.420013\tvalid's l1: 0.430583\n",
            "[1800]\ttrain's l1: 0.41571\tvalid's l1: 0.426807\n",
            "[1900]\ttrain's l1: 0.411492\tvalid's l1: 0.423054\n",
            "[2000]\ttrain's l1: 0.407769\tvalid's l1: 0.419838\n",
            "[2100]\ttrain's l1: 0.404077\tvalid's l1: 0.416566\n",
            "[2200]\ttrain's l1: 0.400599\tvalid's l1: 0.413578\n",
            "[2300]\ttrain's l1: 0.397577\tvalid's l1: 0.411004\n",
            "[2400]\ttrain's l1: 0.394327\tvalid's l1: 0.40819\n",
            "[2500]\ttrain's l1: 0.391068\tvalid's l1: 0.4054\n",
            "[2600]\ttrain's l1: 0.387998\tvalid's l1: 0.402772\n",
            "[2700]\ttrain's l1: 0.385245\tvalid's l1: 0.400466\n",
            "[2800]\ttrain's l1: 0.382837\tvalid's l1: 0.39852\n",
            "[2900]\ttrain's l1: 0.380138\tvalid's l1: 0.396254\n",
            "[3000]\ttrain's l1: 0.377686\tvalid's l1: 0.394253\n",
            "[3100]\ttrain's l1: 0.37517\tvalid's l1: 0.392166\n",
            "[3200]\ttrain's l1: 0.372848\tvalid's l1: 0.39027\n",
            "[3300]\ttrain's l1: 0.370458\tvalid's l1: 0.388261\n",
            "[3400]\ttrain's l1: 0.368317\tvalid's l1: 0.386563\n",
            "[3500]\ttrain's l1: 0.366359\tvalid's l1: 0.385004\n",
            "[3600]\ttrain's l1: 0.364205\tvalid's l1: 0.383251\n",
            "[3700]\ttrain's l1: 0.36202\tvalid's l1: 0.381446\n",
            "[3800]\ttrain's l1: 0.360245\tvalid's l1: 0.380056\n",
            "[3900]\ttrain's l1: 0.358125\tvalid's l1: 0.378329\n",
            "[4000]\ttrain's l1: 0.356345\tvalid's l1: 0.376954\n",
            "[4100]\ttrain's l1: 0.354448\tvalid's l1: 0.375455\n",
            "[4200]\ttrain's l1: 0.352774\tvalid's l1: 0.374147\n",
            "[4300]\ttrain's l1: 0.35109\tvalid's l1: 0.372844\n",
            "[4400]\ttrain's l1: 0.349386\tvalid's l1: 0.371512\n",
            "[4500]\ttrain's l1: 0.347649\tvalid's l1: 0.370154\n",
            "[4600]\ttrain's l1: 0.345997\tvalid's l1: 0.368877\n",
            "[4700]\ttrain's l1: 0.344426\tvalid's l1: 0.367668\n",
            "[4800]\ttrain's l1: 0.34287\tvalid's l1: 0.366479\n",
            "[4900]\ttrain's l1: 0.341354\tvalid's l1: 0.365324\n",
            "[5000]\ttrain's l1: 0.339871\tvalid's l1: 0.36421\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttrain's l1: 0.339871\tvalid's l1: 0.36421\n",
            "\n",
            "Fold 4 - MAE: 0.3642, R²: 0.8244\n",
            "Best iteration: 5000\n",
            "\n",
            "============================================================\n",
            "Fold 5/5\n",
            "============================================================\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttrain's l1: 0.685224\tvalid's l1: 0.68482\n",
            "[200]\ttrain's l1: 0.597479\tvalid's l1: 0.598155\n",
            "[300]\ttrain's l1: 0.557173\tvalid's l1: 0.558818\n",
            "[400]\ttrain's l1: 0.532157\tvalid's l1: 0.534592\n",
            "[500]\ttrain's l1: 0.513131\tvalid's l1: 0.516342\n",
            "[600]\ttrain's l1: 0.497667\tvalid's l1: 0.501521\n",
            "[700]\ttrain's l1: 0.48693\tvalid's l1: 0.491425\n",
            "[800]\ttrain's l1: 0.476938\tvalid's l1: 0.482047\n",
            "[900]\ttrain's l1: 0.468372\tvalid's l1: 0.474036\n",
            "[1000]\ttrain's l1: 0.459709\tvalid's l1: 0.465971\n",
            "[1100]\ttrain's l1: 0.452939\tvalid's l1: 0.459793\n",
            "[1200]\ttrain's l1: 0.44658\tvalid's l1: 0.453994\n",
            "[1300]\ttrain's l1: 0.440666\tvalid's l1: 0.448604\n",
            "[1400]\ttrain's l1: 0.435033\tvalid's l1: 0.443473\n",
            "[1500]\ttrain's l1: 0.42988\tvalid's l1: 0.438859\n",
            "[1600]\ttrain's l1: 0.425395\tvalid's l1: 0.434865\n",
            "[1700]\ttrain's l1: 0.42126\tvalid's l1: 0.431218\n",
            "[1800]\ttrain's l1: 0.416812\tvalid's l1: 0.427314\n",
            "[1900]\ttrain's l1: 0.412711\tvalid's l1: 0.423739\n",
            "[2000]\ttrain's l1: 0.408879\tvalid's l1: 0.420405\n",
            "[2100]\ttrain's l1: 0.405263\tvalid's l1: 0.417287\n",
            "[2200]\ttrain's l1: 0.401811\tvalid's l1: 0.414289\n",
            "[2300]\ttrain's l1: 0.398762\tvalid's l1: 0.411712\n",
            "[2400]\ttrain's l1: 0.395642\tvalid's l1: 0.409049\n",
            "[2500]\ttrain's l1: 0.392749\tvalid's l1: 0.406629\n",
            "[2600]\ttrain's l1: 0.389702\tvalid's l1: 0.404052\n",
            "[2700]\ttrain's l1: 0.387246\tvalid's l1: 0.402057\n",
            "[2800]\ttrain's l1: 0.38432\tvalid's l1: 0.399579\n",
            "[2900]\ttrain's l1: 0.381659\tvalid's l1: 0.397367\n",
            "[3000]\ttrain's l1: 0.379113\tvalid's l1: 0.395246\n",
            "[3100]\ttrain's l1: 0.376882\tvalid's l1: 0.393447\n",
            "[3200]\ttrain's l1: 0.374468\tvalid's l1: 0.391467\n",
            "[3300]\ttrain's l1: 0.372331\tvalid's l1: 0.389741\n",
            "[3400]\ttrain's l1: 0.369958\tvalid's l1: 0.387793\n",
            "[3500]\ttrain's l1: 0.367603\tvalid's l1: 0.385831\n",
            "[3600]\ttrain's l1: 0.36549\tvalid's l1: 0.384151\n",
            "[3700]\ttrain's l1: 0.363201\tvalid's l1: 0.382285\n",
            "[3800]\ttrain's l1: 0.36142\tvalid's l1: 0.380904\n",
            "[3900]\ttrain's l1: 0.35954\tvalid's l1: 0.379421\n",
            "[4000]\ttrain's l1: 0.357751\tvalid's l1: 0.378032\n",
            "[4100]\ttrain's l1: 0.355675\tvalid's l1: 0.376329\n",
            "[4200]\ttrain's l1: 0.353602\tvalid's l1: 0.37467\n",
            "[4300]\ttrain's l1: 0.351988\tvalid's l1: 0.373442\n",
            "[4400]\ttrain's l1: 0.350117\tvalid's l1: 0.371978\n",
            "[4500]\ttrain's l1: 0.34859\tvalid's l1: 0.370862\n",
            "[4600]\ttrain's l1: 0.346872\tvalid's l1: 0.36953\n",
            "[4700]\ttrain's l1: 0.3451\tvalid's l1: 0.368125\n",
            "[4800]\ttrain's l1: 0.343473\tvalid's l1: 0.366865\n",
            "[4900]\ttrain's l1: 0.341776\tvalid's l1: 0.36553\n",
            "[5000]\ttrain's l1: 0.340277\tvalid's l1: 0.364418\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttrain's l1: 0.340277\tvalid's l1: 0.364418\n",
            "\n",
            "Fold 5 - MAE: 0.3644, R²: 0.8233\n",
            "Best iteration: 5000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultados finales\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"RESULTADOS FINALES\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"MAE promedio: {np.mean(mae_scores):.4f} (+/- {np.std(mae_scores):.4f})\")\n",
        "print(f\"R² promedio:  {np.mean(r2_scores):.4f} (+/- {np.std(r2_scores):.4f})\")\n",
        "\n",
        "# Métricas con predicciones out-of-fold\n",
        "oof_mae = mean_absolute_error(y_train, oof_predictions)\n",
        "oof_r2 = r2_score(y_train, oof_predictions)\n",
        "print(f\"\\nOut-of-Fold MAE: {oof_mae:.4f}\")\n",
        "print(f\"Out-of-Fold R²:  {oof_r2:.4f}\")\n",
        "\n",
        "print(\"\\nMétricas por fold:\")\n",
        "for i, (mae, r2) in enumerate(zip(mae_scores, r2_scores), 1):\n",
        "    print(f\"  Fold {i}: MAE={mae:.4f}, R²={r2:.4f}\")\n",
        "\n",
        "# Función para hacer predicciones con ensemble (promedio de todos los modelos)\n",
        "def predict_ensemble(models, X):\n",
        "    \"\"\"Predice usando el promedio de todos los modelos\"\"\"\n",
        "    predictions = np.zeros((len(X), len(models)))\n",
        "    for i, model in enumerate(models):\n",
        "        predictions[:, i] = model.predict(X, num_iteration=model.best_iteration)\n",
        "    return predictions.mean(axis=1)\n",
        "\n",
        "# Ejemplo de uso para predicción en test\n",
        "# y_test_pred = predict_ensemble(models, X_test)\n",
        "\n",
        "print(f\"\\n{len(models)} modelos entrenados y guardados en la lista 'models'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suOSi7SvvHj-",
        "outputId": "6b5167f7-0c60-4c53-8f95-a61cac8876b7"
      },
      "id": "suOSi7SvvHj-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "RESULTADOS FINALES\n",
            "============================================================\n",
            "MAE promedio: 0.3641 (+/- 0.0005)\n",
            "R² promedio:  0.8239 (+/- 0.0005)\n",
            "\n",
            "Out-of-Fold MAE: 0.3641\n",
            "Out-of-Fold R²:  0.8239\n",
            "\n",
            "Métricas por fold:\n",
            "  Fold 1: MAE=0.3644, R²=0.8233\n",
            "  Fold 2: MAE=0.3631, R²=0.8242\n",
            "  Fold 3: MAE=0.3643, R²=0.8244\n",
            "  Fold 4: MAE=0.3642, R²=0.8244\n",
            "  Fold 5: MAE=0.3644, R²=0.8233\n",
            "\n",
            "5 modelos entrenados y guardados en la lista 'models'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}